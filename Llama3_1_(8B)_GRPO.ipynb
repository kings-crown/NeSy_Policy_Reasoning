{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ5x6xlUqG4N"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ⭐ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxKlbfLhqG4P"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf7gq1YJqG4Q"
      },
      "source": [
        "**Read our [blog post](https://unsloth.ai/blog/r1-reasoning) for guidance on how to train reasoning models.**\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xpcb5j3qG4Q"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "dljpflJKqG4R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting en-core-web-sm@ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting libcudf-cu12@ https://pypi.nvidia.com/libcudf-cu12/libcudf_cu12-24.12.0-py3-none-manylinux_2_28_x86_64.whl\n",
            "  Downloading https://pypi.nvidia.com/libcudf-cu12/libcudf_cu12-24.12.0-py3-none-manylinux_2_28_x86_64.whl (457.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m457.8/457.8 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting nx-cugraph-cu12@ https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-24.12.0-py3-none-any.whl\n",
            "  Downloading https://pypi.nvidia.com/nx-cugraph-cu12/nx_cugraph_cu12-24.12.0-py3-none-any.whl (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m143.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pylibcudf-cu12@ https://pypi.nvidia.com/pylibcudf-cu12/pylibcudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\n",
            "  Downloading https://pypi.nvidia.com/pylibcudf-cu12/pylibcudf_cu12-24.12.0-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (37.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting torch@ https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
            "  Using cached https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl (908.3 MB)\n",
            "Collecting torchaudio@ https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
            "  Using cached https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "Collecting torchvision@ https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp311-cp311-linux_x86_64.whl\n",
            "  Using cached https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "Collecting absl-py==1.4.0\n",
            "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
            "Collecting accelerate==1.3.0\n",
            "  Using cached accelerate-1.3.0-py3-none-any.whl (336 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs==2.4.6 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.4.6)\n",
            "Collecting aiohttp==3.11.12\n",
            "  Using cached aiohttp-3.11.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "Requirement already satisfied: aiosignal==1.3.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (1.3.2)\n",
            "Requirement already satisfied: airportsdata==20250224 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (20250224)\n",
            "Collecting alabaster==1.0.0\n",
            "  Using cached alabaster-1.0.0-py3-none-any.whl (13 kB)\n",
            "Collecting albucore==0.0.23\n",
            "  Using cached albucore-0.0.23-py3-none-any.whl (14 kB)\n",
            "Collecting albumentations==2.0.4\n",
            "  Using cached albumentations-2.0.4-py3-none-any.whl (289 kB)\n",
            "Collecting ale-py==0.10.2\n",
            "  Using cached ale_py-0.10.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "Collecting altair==5.5.0\n",
            "  Using cached altair-5.5.0-py3-none-any.whl (731 kB)\n",
            "Requirement already satisfied: annotated-types==0.7.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 12)) (0.7.0)\n",
            "Collecting anyio==3.7.1\n",
            "  Using cached anyio-3.7.1-py3-none-any.whl (80 kB)\n",
            "Collecting argon2-cffi==23.1.0\n",
            "  Using cached argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
            "Collecting argon2-cffi-bindings==21.2.0\n",
            "  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)\n",
            "Collecting array_record==0.6.0\n",
            "  Using cached array_record-0.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "Collecting arviz==0.20.0\n",
            "  Using cached arviz-0.20.0-py3-none-any.whl (1.7 MB)\n",
            "Requirement already satisfied: astor==0.8.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 18)) (0.8.1)\n",
            "Collecting astropy==7.0.1\n",
            "  Using cached astropy-7.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.3 MB)\n",
            "Collecting astropy-iers-data==0.2025.2.17.0.34.13\n",
            "  Using cached astropy_iers_data-0.2025.2.17.0.34.13-py3-none-any.whl (1.9 MB)\n",
            "Collecting astunparse==1.6.3\n",
            "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting atpublic==4.1.0\n",
            "  Using cached atpublic-4.1.0-py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: attrs==25.1.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 23)) (25.1.0)\n",
            "Collecting audioread==3.0.1\n",
            "  Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
            "Collecting autograd==1.7.0\n",
            "  Using cached autograd-1.7.0-py3-none-any.whl (52 kB)\n",
            "Collecting babel==2.17.0\n",
            "  Using cached babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
            "Collecting backcall==0.2.0\n",
            "  Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: beautifulsoup4==4.13.3 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 28)) (4.13.3)\n",
            "Collecting betterproto==2.0.0b6\n",
            "  Using cached betterproto-2.0.0b6-py3-none-any.whl (64 kB)\n",
            "Collecting bigframes==1.37.0\n",
            "  Using cached bigframes-1.37.0-py2.py3-none-any.whl (1.2 MB)\n",
            "Collecting bigquery-magics==0.6.0\n",
            "  Using cached bigquery_magics-0.6.0-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: bitsandbytes==0.45.3 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 32)) (0.45.3)\n",
            "Requirement already satisfied: blake3==1.0.4 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 33)) (1.0.4)\n",
            "Collecting bleach==6.2.0\n",
            "  Using cached bleach-6.2.0-py3-none-any.whl (163 kB)\n",
            "Collecting blinker==1.9.0\n",
            "  Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
            "Collecting blis==0.7.11\n",
            "  Using cached blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "Collecting blosc2==3.1.1\n",
            "  Using cached blosc2-3.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "Collecting bokeh==3.6.3\n",
            "  Using cached bokeh-3.6.3-py3-none-any.whl (6.9 MB)\n",
            "Collecting Bottleneck==1.4.2\n",
            "  Using cached Bottleneck-1.4.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (360 kB)\n",
            "Collecting bqplot==0.12.44\n",
            "  Using cached bqplot-0.12.44-py2.py3-none-any.whl (1.2 MB)\n",
            "Collecting branca==0.8.1\n",
            "  Using cached branca-0.8.1-py3-none-any.whl (26 kB)\n",
            "Collecting CacheControl==0.14.2\n",
            "  Using cached cachecontrol-0.14.2-py3-none-any.whl (21 kB)\n",
            "Collecting cachetools==5.5.1\n",
            "  Using cached cachetools-5.5.1-py3-none-any.whl (9.5 kB)\n",
            "Collecting catalogue==2.0.10\n",
            "  Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: certifi==2025.1.31 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 45)) (2025.1.31)\n",
            "Collecting cffi==1.17.1\n",
            "  Using cached cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (467 kB)\n",
            "Collecting chardet==5.2.0\n",
            "  Using cached chardet-5.2.0-py3-none-any.whl (199 kB)\n",
            "Requirement already satisfied: charset-normalizer==3.4.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 48)) (3.4.1)\n",
            "Collecting chex==0.1.88\n",
            "  Using cached chex-0.1.88-py3-none-any.whl (99 kB)\n",
            "Collecting clarabel==0.10.0\n",
            "  Using cached clarabel-0.10.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "Requirement already satisfied: click==8.1.8 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 51)) (8.1.8)\n",
            "Collecting cloudpathlib==0.20.0\n",
            "  Using cached cloudpathlib-0.20.0-py3-none-any.whl (52 kB)\n",
            "Requirement already satisfied: cloudpickle==3.1.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 53)) (3.1.1)\n",
            "Collecting cmake==3.31.4\n",
            "  Using cached cmake-3.31.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.8 MB)\n",
            "Collecting cmdstanpy==1.2.5\n",
            "  Using cached cmdstanpy-1.2.5-py3-none-any.whl (94 kB)\n",
            "Collecting colorcet==3.1.0\n",
            "  Using cached colorcet-3.1.0-py3-none-any.whl (260 kB)\n",
            "Collecting colorlover==0.3.0\n",
            "  Using cached colorlover-0.3.0-py3-none-any.whl (8.9 kB)\n",
            "Collecting colour==0.1.5\n",
            "  Using cached colour-0.1.5-py2.py3-none-any.whl (23 kB)\n",
            "Collecting community==1.0.0b1\n",
            "  Using cached community-1.0.0b1.tar.gz (2.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: compressed-tensors==0.9.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 60)) (0.9.1)\n",
            "Collecting confection==0.1.5\n",
            "  Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
            "Collecting cons==0.4.6\n",
            "  Using cached cons-0.4.6.tar.gz (26 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting contourpy==1.3.1\n",
            "  Using cached contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (326 kB)\n",
            "Collecting cramjam==2.9.1\n",
            "  Using cached cramjam-2.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "Collecting cryptography==43.0.3\n",
            "  Using cached cryptography-43.0.3-cp39-abi3-manylinux_2_28_x86_64.whl (4.0 MB)\n",
            "Collecting cuda-python==12.6.0\n",
            "  Using cached cuda_python-12.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.0 MB)\n",
            "Collecting cufflinks==0.17.3\n",
            "  Using cached cufflinks-0.17.3.tar.gz (81 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: cupy-cuda12x==13.3.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 69)) (13.3.0)\n",
            "Requirement already satisfied: cut-cross-entropy==25.1.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 70)) (25.1.1)\n",
            "Collecting cvxopt==1.3.2\n",
            "  Using cached cvxopt-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.6 MB)\n",
            "Collecting cvxpy==1.6.0\n",
            "  Using cached cvxpy-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting cycler==0.12.1\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Collecting cymem==2.0.11\n",
            "  Using cached cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (218 kB)\n",
            "Collecting Cython==3.0.12\n",
            "  Using cached Cython-3.0.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "Collecting dask==2024.10.0\n",
            "  Using cached dask-2024.10.0-py3-none-any.whl (1.3 MB)\n",
            "Collecting datascience==0.17.6\n",
            "  Using cached datascience-0.17.6-py3-none-any.whl (732 kB)\n",
            "Requirement already satisfied: datasets==3.3.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 79)) (3.3.2)\n",
            "Collecting db-dtypes==1.4.1\n",
            "  Using cached db_dtypes-1.4.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting dbus-python==1.2.18\n",
            "  Using cached dbus-python-1.2.18.tar.gz (578 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting debugpy==1.8.0\n",
            "  Using cached debugpy-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Collecting decorator==4.4.2\n",
            "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
            "Collecting defusedxml==0.7.1\n",
            "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
            "Collecting Deprecated==1.2.18\n",
            "  Using cached Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: depyf==0.18.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 86)) (0.18.0)\n",
            "Requirement already satisfied: diffusers==0.32.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 87)) (0.32.2)\n",
            "Requirement already satisfied: dill==0.3.8 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 88)) (0.3.8)\n",
            "Requirement already satisfied: diskcache==5.6.3 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 89)) (5.6.3)\n",
            "Requirement already satisfied: distro==1.9.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 90)) (1.9.0)\n",
            "Collecting dlib==19.24.2\n",
            "  Using cached dlib-19.24.2.tar.gz (11.8 MB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting dm-tree==0.1.9\n",
            "  Using cached dm_tree-0.1.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
            "Requirement already satisfied: dnspython==2.7.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 93)) (2.7.0)\n",
            "Collecting docker-pycreds==0.4.0\n",
            "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: docstring_parser==0.16 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 95)) (0.16)\n",
            "Collecting docutils==0.21.2\n",
            "  Using cached docutils-0.21.2-py3-none-any.whl (587 kB)\n",
            "Collecting dopamine_rl==4.1.2\n",
            "  Using cached dopamine_rl-4.1.2-py3-none-any.whl (290 kB)\n",
            "Collecting duckdb==1.1.3\n",
            "  Using cached duckdb-1.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.1 MB)\n",
            "Collecting earthengine-api==1.5.3\n",
            "  Using cached earthengine_api-1.5.3-py3-none-any.whl (459 kB)\n",
            "Collecting easydict==1.13\n",
            "  Using cached easydict-1.13-py3-none-any.whl (6.8 kB)\n",
            "Collecting editdistance==0.8.1\n",
            "  Using cached editdistance-0.8.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (412 kB)\n",
            "Collecting eerepr==0.1.1\n",
            "  Using cached eerepr-0.1.1-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: einops==0.8.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 103)) (0.8.1)\n",
            "Requirement already satisfied: email_validator==2.2.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 104)) (2.2.0)\n",
            "Collecting entrypoints==0.4\n",
            "  Using cached entrypoints-0.4-py3-none-any.whl (5.3 kB)\n",
            "Collecting et_xmlfile==2.0.0\n",
            "  Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
            "Collecting etils==1.12.0\n",
            "  Using cached etils-1.12.0-py3-none-any.whl (166 kB)\n",
            "Collecting etuples==0.3.9\n",
            "  Using cached etuples-0.3.9.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting Farama-Notifications==0.0.4\n",
            "  Using cached Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting fastai==2.7.18\n",
            "  Using cached fastai-2.7.18-py3-none-any.whl (234 kB)\n",
            "Requirement already satisfied: fastapi==0.115.8 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 112)) (0.115.8)\n",
            "Requirement already satisfied: fastapi-cli==0.0.7 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 113)) (0.0.7)\n",
            "Collecting fastcore==1.7.29\n",
            "  Using cached fastcore-1.7.29-py3-none-any.whl (84 kB)\n",
            "Collecting fastdownload==0.0.7\n",
            "  Using cached fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
            "Collecting fastjsonschema==2.21.1\n",
            "  Using cached fastjsonschema-2.21.1-py3-none-any.whl (23 kB)\n",
            "Collecting fastprogress==1.0.3\n",
            "  Using cached fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: fastrlock==0.8.3 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 118)) (0.8.3)\n",
            "Requirement already satisfied: filelock==3.17.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 119)) (3.17.0)\n",
            "Collecting firebase-admin==6.6.0\n",
            "  Using cached firebase_admin-6.6.0-py3-none-any.whl (127 kB)\n",
            "Collecting Flask==3.1.0\n",
            "  Using cached flask-3.1.0-py3-none-any.whl (102 kB)\n",
            "Collecting flatbuffers==25.2.10\n",
            "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Collecting flax==0.10.3\n",
            "  Using cached flax-0.10.3-py3-none-any.whl (435 kB)\n",
            "Collecting folium==0.19.4\n",
            "  Using cached folium-0.19.4-py2.py3-none-any.whl (110 kB)\n",
            "Collecting fonttools==4.56.0\n",
            "  Using cached fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "Collecting frozendict==2.4.6\n",
            "  Using cached frozendict-2.4.6-py311-none-any.whl (16 kB)\n",
            "Requirement already satisfied: frozenlist==1.5.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 127)) (1.5.0)\n",
            "Collecting fsspec==2024.10.0\n",
            "  Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
            "Collecting future==1.0.0\n",
            "  Using cached future-1.0.0-py3-none-any.whl (491 kB)\n",
            "Collecting gast==0.6.0\n",
            "  Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Collecting gcsfs==2024.10.0\n",
            "  Using cached gcsfs-2024.10.0-py2.py3-none-any.whl (34 kB)\n",
            "Collecting gdown==5.2.0\n",
            "  Using cached gdown-5.2.0-py3-none-any.whl (18 kB)\n",
            "Collecting geemap==0.35.1\n",
            "  Using cached geemap-0.35.1-py2.py3-none-any.whl (2.3 MB)\n",
            "Collecting gensim==4.3.3\n",
            "  Using cached gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "Collecting geocoder==1.38.1\n",
            "  Using cached geocoder-1.38.1-py2.py3-none-any.whl (98 kB)\n",
            "Collecting geographiclib==2.0\n",
            "  Using cached geographiclib-2.0-py3-none-any.whl (40 kB)\n",
            "Collecting geopandas==1.0.1\n",
            "  Using cached geopandas-1.0.1-py3-none-any.whl (323 kB)\n",
            "Collecting geopy==2.4.1\n",
            "  Using cached geopy-2.4.1-py3-none-any.whl (125 kB)\n",
            "Requirement already satisfied: gguf==0.10.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 140)) (0.10.0)\n",
            "Collecting gin-config==0.5.0\n",
            "  Using cached gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
            "Collecting gitdb==4.0.12\n",
            "  Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "Collecting GitPython==3.1.44\n",
            "  Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
            "Collecting glob2==0.7\n",
            "  Using cached glob2-0.7.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting google==2.0.3\n",
            "  Using cached google-2.0.3-py2.py3-none-any.whl (45 kB)\n",
            "Collecting google-ai-generativelanguage==0.6.15\n",
            "  Using cached google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "Collecting google-api-core==2.24.1\n",
            "  Using cached google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
            "Collecting google-api-python-client==2.160.0\n",
            "  Using cached google_api_python_client-2.160.0-py2.py3-none-any.whl (12.8 MB)\n",
            "Collecting google-auth==2.27.0\n",
            "  Using cached google_auth-2.27.0-py2.py3-none-any.whl (186 kB)\n",
            "Collecting google-auth-httplib2==0.2.0\n",
            "  Using cached google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Collecting google-auth-oauthlib==1.2.1\n",
            "  Using cached google_auth_oauthlib-1.2.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting google-cloud-aiplatform==1.79.0\n",
            "  Using cached google_cloud_aiplatform-1.79.0-py2.py3-none-any.whl (7.1 MB)\n",
            "Collecting google-cloud-bigquery==3.29.0\n",
            "  Using cached google_cloud_bigquery-3.29.0-py2.py3-none-any.whl (244 kB)\n",
            "Collecting google-cloud-bigquery-connection==1.18.0\n",
            "  Using cached google_cloud_bigquery_connection-1.18.0-py2.py3-none-any.whl (66 kB)\n",
            "Collecting google-cloud-bigquery-storage==2.28.0\n",
            "  Using cached google_cloud_bigquery_storage-2.28.0-py2.py3-none-any.whl (251 kB)\n",
            "Collecting google-cloud-bigtable==2.28.1\n",
            "  Using cached google_cloud_bigtable-2.28.1-py2.py3-none-any.whl (445 kB)\n",
            "Collecting google-cloud-core==2.4.1\n",
            "  Using cached google_cloud_core-2.4.1-py2.py3-none-any.whl (29 kB)\n",
            "Collecting google-cloud-dataproc==5.17.0\n",
            "  Using cached google_cloud_dataproc-5.17.0-py2.py3-none-any.whl (478 kB)\n",
            "Collecting google-cloud-datastore==2.20.2\n",
            "  Using cached google_cloud_datastore-2.20.2-py2.py3-none-any.whl (197 kB)\n",
            "Collecting google-cloud-firestore==2.20.0\n",
            "  Using cached google_cloud_firestore-2.20.0-py2.py3-none-any.whl (337 kB)\n",
            "Collecting google-cloud-functions==1.19.0\n",
            "  Using cached google_cloud_functions-1.19.0-py2.py3-none-any.whl (149 kB)\n",
            "Collecting google-cloud-iam==2.18.0\n",
            "  Using cached google_cloud_iam-2.18.0-py2.py3-none-any.whl (228 kB)\n",
            "Collecting google-cloud-language==2.16.0\n",
            "  Using cached google_cloud_language-2.16.0-py2.py3-none-any.whl (163 kB)\n",
            "Collecting google-cloud-pubsub==2.25.0\n",
            "  Using cached google_cloud_pubsub-2.25.0-py2.py3-none-any.whl (287 kB)\n",
            "Collecting google-cloud-resource-manager==1.14.0\n",
            "  Using cached google_cloud_resource_manager-1.14.0-py2.py3-none-any.whl (384 kB)\n",
            "Collecting google-cloud-spanner==3.51.0\n",
            "  Using cached google_cloud_spanner-3.51.0-py2.py3-none-any.whl (432 kB)\n",
            "Collecting google-cloud-storage==2.19.0\n",
            "  Using cached google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
            "Collecting google-cloud-translate==3.19.0\n",
            "  Using cached google_cloud_translate-3.19.0-py2.py3-none-any.whl (192 kB)\n",
            "Collecting google-crc32c==1.6.0\n",
            "  Using cached google_crc32c-1.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
            "Collecting google-genai==0.8.0\n",
            "  Using cached google_genai-0.8.0-py3-none-any.whl (125 kB)\n",
            "Collecting google-generativeai==0.8.4\n",
            "  Using cached google_generativeai-0.8.4-py3-none-any.whl (175 kB)\n",
            "Collecting google-pasta==0.2.0\n",
            "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "Collecting google-resumable-media==2.7.2\n",
            "  Using cached google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
            "Collecting google-spark-connect==0.5.2\n",
            "  Using cached google_spark_connect-0.5.2-py2.py3-none-any.whl (18 kB)\n",
            "Collecting googleapis-common-protos==1.67.0\n",
            "  Using cached googleapis_common_protos-1.67.0-py2.py3-none-any.whl (164 kB)\n",
            "Collecting googledrivedownloader==1.1.0\n",
            "  Using cached googledrivedownloader-1.1.0-py3-none-any.whl (4.5 kB)\n",
            "Collecting graphviz==0.20.3\n",
            "  Using cached graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
            "Collecting greenlet==3.1.1\n",
            "  Using cached greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (602 kB)\n",
            "Collecting grpc-google-iam-v1==0.14.0\n",
            "  Using cached grpc_google_iam_v1-0.14.0-py2.py3-none-any.whl (27 kB)\n",
            "Collecting grpc-interceptor==0.15.4\n",
            "  Using cached grpc_interceptor-0.15.4-py3-none-any.whl (20 kB)\n",
            "Collecting grpcio==1.70.0\n",
            "  Using cached grpcio-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
            "Collecting grpcio-status==1.62.3\n",
            "  Using cached grpcio_status-1.62.3-py3-none-any.whl (14 kB)\n",
            "Collecting grpclib==0.4.7\n",
            "  Using cached grpclib-0.4.7.tar.gz (61 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting gspread==6.1.4\n",
            "  Using cached gspread-6.1.4-py3-none-any.whl (57 kB)\n",
            "Collecting gspread-dataframe==4.0.0\n",
            "  Using cached gspread_dataframe-4.0.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting gym==0.25.2\n",
            "  Using cached gym-0.25.2.tar.gz (734 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting gym-notices==0.0.8\n",
            "  Using cached gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
            "Collecting gymnasium==1.0.0\n",
            "  Using cached gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "Requirement already satisfied: h11==0.14.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 190)) (0.14.0)\n",
            "Collecting h2==4.2.0\n",
            "  Using cached h2-4.2.0-py3-none-any.whl (60 kB)\n",
            "Collecting h5netcdf==1.5.0\n",
            "  Using cached h5netcdf-1.5.0-py3-none-any.whl (49 kB)\n",
            "Collecting h5py==3.12.1\n",
            "  Using cached h5py-3.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
            "Requirement already satisfied: hf_transfer==0.1.9 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 194)) (0.1.9)\n",
            "Collecting highspy==1.9.0\n",
            "  Using cached highspy-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "Collecting holidays==0.67\n",
            "  Using cached holidays-0.67-py3-none-any.whl (820 kB)\n",
            "Collecting holoviews==1.20.1\n",
            "  Using cached holoviews-1.20.1-py3-none-any.whl (5.0 MB)\n",
            "Collecting hpack==4.1.0\n",
            "  Using cached hpack-4.1.0-py3-none-any.whl (34 kB)\n",
            "Collecting html5lib==1.1\n",
            "  Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
            "Requirement already satisfied: httpcore==1.0.7 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 200)) (1.0.7)\n",
            "Collecting httpimport==1.4.0\n",
            "  Using cached httpimport-1.4.0-py2.py3-none-any.whl (17 kB)\n",
            "Collecting httplib2==0.22.0\n",
            "  Using cached httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "Requirement already satisfied: httptools==0.6.4 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 203)) (0.6.4)\n",
            "Requirement already satisfied: httpx==0.28.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 204)) (0.28.1)\n",
            "Collecting huggingface-hub==0.28.1\n",
            "  Using cached huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
            "Collecting humanize==4.11.0\n",
            "  Using cached humanize-4.11.0-py3-none-any.whl (128 kB)\n",
            "Collecting hyperframe==6.1.0\n",
            "  Using cached hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
            "Collecting hyperopt==0.2.7\n",
            "  Using cached hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
            "Collecting ibis-framework==9.2.0\n",
            "  Using cached ibis_framework-9.2.0-py3-none-any.whl (1.9 MB)\n",
            "Requirement already satisfied: idna==3.10 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 210)) (3.10)\n",
            "Collecting imageio==2.37.0\n",
            "  Using cached imageio-2.37.0-py3-none-any.whl (315 kB)\n",
            "Collecting imageio-ffmpeg==0.6.0\n",
            "  Using cached imageio_ffmpeg-0.6.0-py3-none-manylinux2014_x86_64.whl (29.5 MB)\n",
            "Collecting imagesize==1.4.1\n",
            "  Using cached imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
            "Collecting imbalanced-learn==0.13.0\n",
            "  Using cached imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
            "Collecting imgaug==0.4.0\n",
            "  Using cached imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "Collecting immutabledict==4.2.1\n",
            "  Using cached immutabledict-4.2.1-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: importlib_metadata==8.6.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 217)) (8.6.1)\n",
            "Collecting importlib_resources==6.5.2\n",
            "  Using cached importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
            "Collecting imutils==0.5.4\n",
            "  Using cached imutils-0.5.4.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting inflect==7.5.0\n",
            "  Using cached inflect-7.5.0-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: iniconfig==2.0.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 221)) (2.0.0)\n",
            "Collecting intel-cmplr-lib-ur==2025.0.4\n",
            "  Using cached intel_cmplr_lib_ur-2025.0.4-py2.py3-none-manylinux_2_28_x86_64.whl (25.2 MB)\n",
            "Collecting intel-openmp==2025.0.4\n",
            "  Using cached intel_openmp-2025.0.4-py2.py3-none-manylinux_2_28_x86_64.whl (30.1 MB)\n",
            "Requirement already satisfied: interegular==0.3.3 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 224)) (0.3.3)\n",
            "Collecting ipyevents==2.0.2\n",
            "  Using cached ipyevents-2.0.2-py3-none-any.whl (101 kB)\n",
            "Collecting ipyfilechooser==0.6.0\n",
            "  Using cached ipyfilechooser-0.6.0-py3-none-any.whl (11 kB)\n",
            "Collecting ipykernel==6.17.1\n",
            "  Using cached ipykernel-6.17.1-py3-none-any.whl (138 kB)\n",
            "Collecting ipyleaflet==0.19.2\n",
            "  Using cached ipyleaflet-0.19.2-py3-none-any.whl (31 kB)\n",
            "Collecting ipyparallel==8.8.0\n",
            "  Using cached ipyparallel-8.8.0-py3-none-any.whl (293 kB)\n",
            "Collecting ipython==7.34.0\n",
            "  Using cached ipython-7.34.0-py3-none-any.whl (793 kB)\n",
            "Collecting ipython-genutils==0.2.0\n",
            "  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting ipython-sql==0.5.0\n",
            "  Using cached ipython_sql-0.5.0-py3-none-any.whl (20 kB)\n",
            "Collecting ipytree==0.2.2\n",
            "  Using cached ipytree-0.2.2-py2.py3-none-any.whl (1.3 MB)\n",
            "Collecting ipywidgets==7.7.1\n",
            "  Using cached ipywidgets-7.7.1-py2.py3-none-any.whl (123 kB)\n",
            "Collecting itsdangerous==2.2.0\n",
            "  Using cached itsdangerous-2.2.0-py3-none-any.whl (16 kB)\n",
            "Collecting jax==0.4.33\n",
            "  Using cached jax-0.4.33-py3-none-any.whl (2.1 MB)\n",
            "Collecting jax-cuda12-pjrt==0.4.33\n",
            "  Using cached jax_cuda12_pjrt-0.4.33-py3-none-manylinux2014_x86_64.whl (99.7 MB)\n",
            "Collecting jax-cuda12-plugin==0.4.33\n",
            "  Using cached jax_cuda12_plugin-0.4.33-cp311-cp311-manylinux2014_x86_64.whl (14.9 MB)\n",
            "Collecting jaxlib==0.4.33\n",
            "  Using cached jaxlib-0.4.33-cp311-cp311-manylinux2014_x86_64.whl (85.1 MB)\n",
            "Collecting jeepney==0.7.1\n",
            "  Using cached jeepney-0.7.1-py3-none-any.whl (54 kB)\n",
            "Collecting jellyfish==1.1.0\n",
            "  Using cached jellyfish-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (335 kB)\n",
            "Collecting jieba==0.42.1\n",
            "  Using cached jieba-0.42.1.tar.gz (19.2 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: Jinja2==3.1.5 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 243)) (3.1.5)\n",
            "Requirement already satisfied: jiter==0.8.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 244)) (0.8.2)\n",
            "Collecting joblib==1.4.2\n",
            "  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Collecting jsonpatch==1.33\n",
            "  Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting jsonpickle==4.0.2\n",
            "  Using cached jsonpickle-4.0.2-py3-none-any.whl (46 kB)\n",
            "Collecting jsonpointer==3.0.0\n",
            "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: jsonschema==4.23.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 249)) (4.23.0)\n",
            "Requirement already satisfied: jsonschema-specifications==2024.10.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 250)) (2024.10.1)\n",
            "Collecting jupyter-client==6.1.12\n",
            "  Using cached jupyter_client-6.1.12-py3-none-any.whl (112 kB)\n",
            "Collecting jupyter-console==6.1.0\n",
            "  Using cached jupyter_console-6.1.0-py2.py3-none-any.whl (21 kB)\n",
            "Collecting jupyter-leaflet==0.19.2\n",
            "  Using cached jupyter_leaflet-0.19.2-py3-none-any.whl (1.1 MB)\n",
            "Collecting jupyter-server==1.24.0\n",
            "  Using cached jupyter_server-1.24.0-py3-none-any.whl (347 kB)\n",
            "Requirement already satisfied: jupyter_core==5.7.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 255)) (5.7.2)\n",
            "Collecting jupyterlab_pygments==0.3.0\n",
            "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
            "Collecting jupyterlab_widgets==3.0.13\n",
            "  Using cached jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
            "Collecting kaggle==1.6.17\n",
            "  Using cached kaggle-1.6.17.tar.gz (82 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting kagglehub==0.3.9\n",
            "  Using cached kagglehub-0.3.9-py3-none-any.whl (62 kB)\n",
            "Collecting keras==3.8.0\n",
            "  Using cached keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
            "Collecting keras-hub==0.18.1\n",
            "  Using cached keras_hub-0.18.1-py3-none-any.whl (691 kB)\n",
            "Collecting keras-nlp==0.18.1\n",
            "  Using cached keras_nlp-0.18.1-py3-none-any.whl (2.0 kB)\n",
            "Collecting keyring==23.5.0\n",
            "  Using cached keyring-23.5.0-py3-none-any.whl (33 kB)\n",
            "Collecting kiwisolver==1.4.8\n",
            "  Using cached kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "Collecting langchain==0.3.19\n",
            "  Using cached langchain-0.3.19-py3-none-any.whl (1.0 MB)\n",
            "Collecting langchain-core==0.3.37\n",
            "  Using cached langchain_core-0.3.37-py3-none-any.whl (413 kB)\n",
            "Collecting langchain-text-splitters==0.3.6\n",
            "  Using cached langchain_text_splitters-0.3.6-py3-none-any.whl (31 kB)\n",
            "Collecting langcodes==3.5.0\n",
            "  Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
            "Collecting langsmith==0.3.8\n",
            "  Using cached langsmith-0.3.8-py3-none-any.whl (332 kB)\n",
            "Collecting language_data==1.3.0\n",
            "  Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
            "Requirement already satisfied: lark==1.2.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 271)) (1.2.2)\n",
            "Collecting launchpadlib==1.10.16\n",
            "  Using cached launchpadlib-1.10.16-py2.py3-none-any.whl (216 kB)\n",
            "Collecting lazr.restfulclient==0.14.4\n",
            "  Using cached lazr.restfulclient-0.14.4.tar.gz (62 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting lazr.uri==1.0.6\n",
            "  Using cached lazr.uri-1.0.6.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting lazy_loader==0.4\n",
            "  Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Collecting libclang==18.1.1\n",
            "  Using cached libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "Collecting libkvikio-cu12==24.12.1\n",
            "  Using cached libkvikio_cu12-24.12.1-py3-none-manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "Collecting librosa==0.10.2.post1\n",
            "  Using cached librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
            "Collecting lightgbm==4.5.0\n",
            "  Using cached lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "Collecting linkify-it-py==2.0.3\n",
            "  Using cached linkify_it_py-2.0.3-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: llvmlite==0.43.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 282)) (0.43.0)\n",
            "Requirement already satisfied: lm-format-enforcer==0.10.10 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 283)) (0.10.10)\n",
            "Collecting locket==1.0.0\n",
            "  Using cached locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
            "Collecting logical-unification==0.4.6\n",
            "  Using cached logical-unification-0.4.6.tar.gz (31 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting lxml==5.3.1\n",
            "  Using cached lxml-5.3.1-cp311-cp311-manylinux_2_28_x86_64.whl (5.0 MB)\n",
            "Collecting marisa-trie==1.2.1\n",
            "  Using cached marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "Collecting Markdown==3.7\n",
            "  Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
            "Requirement already satisfied: markdown-it-py==3.0.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 289)) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe==3.0.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 290)) (3.0.2)\n",
            "Collecting matplotlib==3.10.0\n",
            "  Using cached matplotlib-3.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "Requirement already satisfied: matplotlib-inline==0.1.7 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 292)) (0.1.7)\n",
            "Collecting matplotlib-venn==1.1.1\n",
            "  Using cached matplotlib-venn-1.1.1.tar.gz (40 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting mdit-py-plugins==0.4.2\n",
            "  Using cached mdit_py_plugins-0.4.2-py3-none-any.whl (55 kB)\n",
            "Requirement already satisfied: mdurl==0.1.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 295)) (0.1.2)\n",
            "Collecting miniKanren==1.0.3\n",
            "  Using cached miniKanren-1.0.3.tar.gz (41 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting missingno==0.5.2\n",
            "  Using cached missingno-0.5.2-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: mistral_common==1.5.3 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 298)) (1.5.3)\n",
            "Collecting mistune==3.1.2\n",
            "  Using cached mistune-3.1.2-py3-none-any.whl (53 kB)\n",
            "Collecting mizani==0.13.1\n",
            "  Using cached mizani-0.13.1-py3-none-any.whl (127 kB)\n",
            "Collecting mkl==2025.0.1\n",
            "  Using cached mkl-2025.0.1-py2.py3-none-manylinux_2_28_x86_64.whl (184.8 MB)\n",
            "Collecting ml-dtypes==0.4.1\n",
            "  Using cached ml_dtypes-0.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "Collecting mlxtend==0.23.4\n",
            "  Using cached mlxtend-0.23.4-py3-none-any.whl (1.4 MB)\n",
            "Collecting more-itertools==10.6.0\n",
            "  Using cached more_itertools-10.6.0-py3-none-any.whl (63 kB)\n",
            "Collecting moviepy==1.0.3\n",
            "  Using cached moviepy-1.0.3.tar.gz (388 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: mpmath==1.3.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 306)) (1.3.0)\n",
            "Requirement already satisfied: msgpack==1.1.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 307)) (1.1.0)\n",
            "Requirement already satisfied: msgspec==0.19.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 308)) (0.19.0)\n",
            "Requirement already satisfied: multidict==6.1.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 309)) (6.1.0)\n",
            "Collecting multipledispatch==1.0.0\n",
            "  Using cached multipledispatch-1.0.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: multiprocess==0.70.16 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 311)) (0.70.16)\n",
            "Collecting multitasking==0.0.11\n",
            "  Using cached multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
            "Collecting murmurhash==1.0.12\n",
            "  Using cached murmurhash-1.0.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (134 kB)\n",
            "Collecting music21==9.3.0\n",
            "  Using cached music21-9.3.0-py3-none-any.whl (22.9 MB)\n",
            "Collecting namex==0.0.8\n",
            "  Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Collecting narwhals==1.27.1\n",
            "  Using cached narwhals-1.27.1-py3-none-any.whl (308 kB)\n",
            "Collecting natsort==8.4.0\n",
            "  Using cached natsort-8.4.0-py3-none-any.whl (38 kB)\n",
            "Collecting nbclassic==1.2.0\n",
            "  Using cached nbclassic-1.2.0-py3-none-any.whl (10.0 MB)\n",
            "Collecting nbclient==0.10.2\n",
            "  Using cached nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
            "Collecting nbconvert==7.16.6\n",
            "  Using cached nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
            "Collecting nbformat==5.10.4\n",
            "  Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
            "Collecting ndindex==1.9.2\n",
            "  Using cached ndindex-1.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (506 kB)\n",
            "Requirement already satisfied: nest-asyncio==1.6.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 323)) (1.6.0)\n",
            "Requirement already satisfied: networkx==3.4.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 324)) (3.4.2)\n",
            "Collecting nibabel==5.3.2\n",
            "  Using cached nibabel-5.3.2-py3-none-any.whl (3.3 MB)\n",
            "Collecting nltk==3.9.1\n",
            "  Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "Collecting notebook==6.5.5\n",
            "  Using cached notebook-6.5.5-py3-none-any.whl (529 kB)\n",
            "Collecting notebook_shim==0.2.4\n",
            "  Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: numba==0.60.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 329)) (0.60.0)\n",
            "Collecting numba-cuda==0.0.17.1\n",
            "  Using cached numba_cuda-0.0.17.1-py3-none-any.whl (424 kB)\n",
            "Collecting numexpr==2.10.2\n",
            "  Using cached numexpr-2.10.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (398 kB)\n",
            "Requirement already satisfied: numpy==1.26.4 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 332)) (1.26.4)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 333)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 334)) (12.4.127)\n",
            "Collecting nvidia-cuda-nvcc-cu12==12.5.82\n",
            "  Using cached nvidia_cuda_nvcc_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (22.5 MB)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 336)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 337)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 338)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 339)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 340)) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 341)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 342)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 343)) (2.21.5)\n",
            "Collecting nvidia-nvcomp-cu12==4.1.0.6\n",
            "  Using cached nvidia_nvcomp_cu12-4.1.0.6-py3-none-manylinux_2_28_x86_64.whl (28.9 MB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 345)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 346)) (12.4.127)\n",
            "Collecting nvtx==0.2.10\n",
            "  Using cached nvtx-0.2.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (653 kB)\n",
            "Collecting oauth2client==4.1.3\n",
            "  Using cached oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
            "Collecting oauthlib==3.2.2\n",
            "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Collecting openai==1.61.1\n",
            "  Using cached openai-1.61.1-py3-none-any.whl (463 kB)\n",
            "Collecting opencv-contrib-python==4.11.0.86\n",
            "  Using cached opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "Collecting opencv-python==4.11.0.86\n",
            "  Using cached opencv_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.0 MB)\n",
            "Requirement already satisfied: opencv-python-headless==4.11.0.86 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 354)) (4.11.0.86)\n",
            "Collecting openpyxl==3.1.5\n",
            "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "Collecting opentelemetry-api==1.16.0\n",
            "  Using cached opentelemetry_api-1.16.0-py3-none-any.whl (57 kB)\n",
            "Collecting opentelemetry-sdk==1.16.0\n",
            "  Using cached opentelemetry_sdk-1.16.0-py3-none-any.whl (94 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.37b0\n",
            "  Using cached opentelemetry_semantic_conventions-0.37b0-py3-none-any.whl (26 kB)\n",
            "Collecting opt_einsum==3.4.0\n",
            "  Using cached opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "Collecting optax==0.2.4\n",
            "  Using cached optax-0.2.4-py3-none-any.whl (319 kB)\n",
            "Collecting optree==0.14.0\n",
            "  Using cached optree-0.14.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (405 kB)\n",
            "Collecting orbax-checkpoint==0.6.4\n",
            "  Using cached orbax_checkpoint-0.6.4-py3-none-any.whl (270 kB)\n",
            "Collecting orjson==3.10.15\n",
            "  Using cached orjson-3.10.15-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "Collecting osqp==0.6.7.post3\n",
            "  Using cached osqp-0.6.7.post3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (298 kB)\n",
            "Requirement already satisfied: outlines==0.1.11 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 365)) (0.1.11)\n",
            "Requirement already satisfied: outlines_core==0.1.26 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 366)) (0.1.26)\n",
            "Requirement already satisfied: packaging==24.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 367)) (24.2)\n",
            "Collecting pandas==2.2.2\n",
            "  Using cached pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "Collecting pandas-datareader==0.10.0\n",
            "  Using cached pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
            "Collecting pandas-gbq==0.27.0\n",
            "  Using cached pandas_gbq-0.27.0-py2.py3-none-any.whl (37 kB)\n",
            "Collecting pandas-stubs==2.2.2.240909\n",
            "  Using cached pandas_stubs-2.2.2.240909-py3-none-any.whl (157 kB)\n",
            "Collecting pandocfilters==1.5.1\n",
            "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting panel==1.6.1\n",
            "  Using cached panel-1.6.1-py3-none-any.whl (28.0 MB)\n",
            "Collecting param==2.2.0\n",
            "  Using cached param-2.2.0-py3-none-any.whl (119 kB)\n",
            "Requirement already satisfied: parso==0.8.4 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 375)) (0.8.4)\n",
            "Collecting parsy==2.1\n",
            "  Using cached parsy-2.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting partd==1.4.2\n",
            "  Using cached partd-1.4.2-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: partial-json-parser==0.2.1.1.post5 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 378)) (0.2.1.1.post5)\n",
            "Collecting pathlib==1.0.1\n",
            "  Using cached pathlib-1.0.1-py3-none-any.whl (14 kB)\n",
            "Collecting patsy==1.0.1\n",
            "  Using cached patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
            "Collecting peewee==3.17.9\n",
            "  Using cached peewee-3.17.9.tar.gz (3.0 MB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: peft==0.14.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 382)) (0.14.0)\n",
            "Requirement already satisfied: pexpect==4.9.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 383)) (4.9.0)\n",
            "Collecting pickleshare==0.7.5\n",
            "  Using cached pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: pillow==11.1.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 385)) (11.1.0)\n",
            "Requirement already satisfied: platformdirs==4.3.6 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 386)) (4.3.6)\n",
            "Collecting plotly==5.24.1\n",
            "  Using cached plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
            "Collecting plotnine==0.14.5\n",
            "  Using cached plotnine-0.14.5-py3-none-any.whl (1.3 MB)\n",
            "Requirement already satisfied: pluggy==1.5.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 389)) (1.5.0)\n",
            "Collecting ply==3.11\n",
            "  Using cached ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "Collecting polars==1.9.0\n",
            "  Using cached polars-1.9.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.1 MB)\n",
            "Collecting pooch==1.8.2\n",
            "  Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
            "Collecting portpicker==1.5.2\n",
            "  Using cached portpicker-1.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting preshed==3.0.9\n",
            "  Using cached preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
            "Collecting prettytable==3.14.0\n",
            "  Using cached prettytable-3.14.0-py3-none-any.whl (31 kB)\n",
            "Collecting proglog==0.1.10\n",
            "  Using cached proglog-0.1.10-py3-none-any.whl (6.1 kB)\n",
            "Collecting progressbar2==4.5.0\n",
            "  Using cached progressbar2-4.5.0-py3-none-any.whl (57 kB)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator==7.0.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 398)) (7.0.2)\n",
            "Requirement already satisfied: prometheus_client==0.21.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 399)) (0.21.1)\n",
            "Collecting promise==2.3\n",
            "  Using cached promise-2.3.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: prompt_toolkit==3.0.50 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 401)) (3.0.50)\n",
            "Collecting propcache==0.2.1\n",
            "  Using cached propcache-0.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
            "Collecting prophet==1.1.6\n",
            "  Using cached prophet-1.1.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.4 MB)\n",
            "Collecting proto-plus==1.26.0\n",
            "  Using cached proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
            "Requirement already satisfied: protobuf==3.20.3 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 405)) (3.20.3)\n",
            "Collecting psutil==5.9.5\n",
            "  Using cached psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 408)) (0.7.0)\n",
            "Requirement already satisfied: py-cpuinfo==9.0.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 409)) (9.0.0)\n",
            "Collecting py4j==0.10.9.7\n",
            "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
            "Collecting pyarrow==17.0.0\n",
            "  Using cached pyarrow-17.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "Collecting pyasn1==0.6.1\n",
            "  Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Collecting pyasn1_modules==0.4.1\n",
            "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
            "Requirement already satisfied: pybind11==2.13.6 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 414)) (2.13.6)\n",
            "Collecting pycocotools==2.0.8\n",
            "  Using cached pycocotools-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (458 kB)\n",
            "Requirement already satisfied: pycountry==24.6.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 416)) (24.6.1)\n",
            "Collecting pycparser==2.22\n",
            "  Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "Requirement already satisfied: pydantic==2.10.6 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 418)) (2.10.6)\n",
            "Requirement already satisfied: pydantic_core==2.27.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 419)) (2.27.2)\n",
            "Collecting pydata-google-auth==1.9.1\n",
            "  Using cached pydata_google_auth-1.9.1-py2.py3-none-any.whl (15 kB)\n",
            "Collecting pydot==3.0.4\n",
            "  Using cached pydot-3.0.4-py3-none-any.whl (35 kB)\n",
            "Collecting pydotplus==2.0.2\n",
            "  Using cached pydotplus-2.0.2.tar.gz (278 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting PyDrive==1.3.1\n",
            "  Using cached PyDrive-1.3.1.tar.gz (987 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting PyDrive2==1.21.3\n",
            "  Using cached PyDrive2-1.21.3-py3-none-any.whl (47 kB)\n",
            "Collecting pyerfa==2.0.1.5\n",
            "  Using cached pyerfa-2.0.1.5-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (738 kB)\n",
            "Collecting pygame==2.6.1\n",
            "  Using cached pygame-2.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "Collecting pygit2==1.17.0\n",
            "  Using cached pygit2-1.17.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
            "Collecting Pygments==2.18.0\n",
            "  Using cached pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
            "Collecting PyJWT==2.10.1\n",
            "  Using cached PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
            "Collecting pylibcugraph-cu12==24.12.0\n",
            "  Using cached pylibcugraph_cu12-24.12.0.tar.gz (3.8 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting pylibraft-cu12==24.12.0\n",
            "  Using cached pylibraft_cu12-24.12.0.tar.gz (5.6 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting pymc==5.20.1\n",
            "  Using cached pymc-5.20.1-py3-none-any.whl (518 kB)\n",
            "Collecting pymystem3==0.2.0\n",
            "  Using cached pymystem3-0.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting pynvjitlink-cu12==0.5.0\n",
            "  Using cached pynvjitlink_cu12-0.5.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (46.2 MB)\n",
            "Collecting pyogrio==0.10.0\n",
            "  Using cached pyogrio-0.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "Collecting Pyomo==6.8.2\n",
            "  Using cached Pyomo-6.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "Collecting PyOpenGL==3.1.9\n",
            "  Using cached PyOpenGL-3.1.9-py3-none-any.whl (3.2 MB)\n",
            "Collecting pyOpenSSL==24.2.1\n",
            "  Using cached pyOpenSSL-24.2.1-py3-none-any.whl (58 kB)\n",
            "Collecting pyparsing==3.2.1\n",
            "  Using cached pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
            "Collecting pyperclip==1.9.0\n",
            "  Using cached pyperclip-1.9.0.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting pyproj==3.7.1\n",
            "  Using cached pyproj-3.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.5 MB)\n",
            "Collecting pyshp==2.3.1\n",
            "  Using cached pyshp-2.3.1-py2.py3-none-any.whl (46 kB)\n",
            "Collecting PySocks==1.7.1\n",
            "  Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
            "Collecting pyspark==3.5.4\n",
            "  Using cached pyspark-3.5.4.tar.gz (317.3 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting pytensor==2.27.1\n",
            "  Using cached pytensor-2.27.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "Requirement already satisfied: pytest==8.3.4 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 448)) (8.3.4)\n",
            "Collecting python-apt==0.0.0\n",
            "  Using cached python-apt-0.0.0.tar.bz2 (105 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting python-box==7.3.2\n",
            "  Using cached python_box-7.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "Collecting python-dateutil==2.8.2\n",
            "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "Requirement already satisfied: python-dotenv==1.0.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 452)) (1.0.1)\n",
            "Collecting python-louvain==0.16\n",
            "  Using cached python-louvain-0.16.tar.gz (204 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: python-multipart==0.0.20 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 454)) (0.0.20)\n",
            "Collecting python-slugify==8.0.4\n",
            "  Using cached python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
            "Collecting python-snappy==0.7.3\n",
            "  Using cached python_snappy-0.7.3-py3-none-any.whl (9.2 kB)\n",
            "Collecting python-utils==3.9.1\n",
            "  Using cached python_utils-3.9.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pytz==2025.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 458)) (2025.1)\n",
            "Collecting pyviz_comms==3.0.4\n",
            "  Using cached pyviz_comms-3.0.4-py3-none-any.whl (83 kB)\n",
            "Requirement already satisfied: PyYAML==6.0.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 460)) (6.0.2)\n",
            "Collecting pyzmq==24.0.1\n",
            "  Using cached pyzmq-24.0.1-cp311-cp311-manylinux_2_28_x86_64.whl (1.1 MB)\n",
            "Collecting qdldl==0.1.7.post5\n",
            "  Using cached qdldl-0.1.7.post5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "Collecting ratelim==0.1.6\n",
            "  Using cached ratelim-0.1.6-py2.py3-none-any.whl (4.0 kB)\n",
            "Requirement already satisfied: ray==2.40.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 464)) (2.40.0)\n",
            "Requirement already satisfied: referencing==0.36.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 465)) (0.36.2)\n",
            "Requirement already satisfied: regex==2024.11.6 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 466)) (2024.11.6)\n",
            "Requirement already satisfied: requests==2.32.3 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 467)) (2.32.3)\n",
            "Collecting requests-oauthlib==2.0.0\n",
            "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting requests-toolbelt==1.0.0\n",
            "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "Collecting requirements-parser==0.9.0\n",
            "  Using cached requirements_parser-0.9.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: rich==13.9.4 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 471)) (13.9.4)\n",
            "Requirement already satisfied: rich-toolkit==0.13.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 472)) (0.13.2)\n",
            "Collecting rmm-cu12==24.12.1\n",
            "  Using cached rmm_cu12-24.12.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (2.0 MB)\n",
            "Collecting rsa==4.9\n",
            "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: safetensors==0.5.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 477)) (0.5.2)\n",
            "Collecting scikit-image==0.25.2\n",
            "  Downloading scikit_image-0.25.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn==1.6.1\n",
            "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.13.1\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting scooby==0.10.0\n",
            "  Downloading scooby-0.10.0-py3-none-any.whl (18 kB)\n",
            "Collecting scs==3.2.7.post2\n",
            "  Downloading scs-3.2.7.post2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting seaborn==0.13.2\n",
            "  Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Collecting SecretStorage==3.3.1\n",
            "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
            "Collecting Send2Trash==1.8.3\n",
            "  Downloading Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
            "Collecting sentence-transformers==3.4.1\n",
            "  Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.9/275.9 kB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sentencepiece==0.2.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 487)) (0.2.0)\n",
            "Collecting sentry-sdk==2.22.0\n",
            "  Downloading sentry_sdk-2.22.0-py2.py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.8/325.8 kB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setproctitle==1.3.4\n",
            "  Using cached setproctitle-1.3.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Collecting shap==0.46.0\n",
            "  Downloading shap-0.46.0-cp311-cp311-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (540 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.2/540.2 kB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting shapely==2.0.7\n",
            "  Downloading shapely-2.0.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: shellingham==1.5.4 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 492)) (1.5.4)\n",
            "Requirement already satisfied: shtab==1.7.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 493)) (1.7.1)\n",
            "Collecting simple-parsing==0.1.7\n",
            "  Downloading simple_parsing-0.1.7-py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.8/112.8 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simsimd==6.2.1\n",
            "  Downloading simsimd-6.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (632 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m632.7/632.7 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six==1.17.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 496)) (1.17.0)\n",
            "Collecting sklearn-compat==0.1.3\n",
            "  Downloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
            "Collecting sklearn-pandas==2.2.0\n",
            "  Downloading sklearn_pandas-2.2.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting slicer==0.0.8\n",
            "  Downloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
            "Collecting smart-open==7.1.0\n",
            "  Using cached smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "Collecting smmap==5.0.2\n",
            "  Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: sniffio==1.3.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 502)) (1.3.1)\n",
            "Collecting snowballstemmer==2.2.0\n",
            "  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.0/93.0 kB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting soundfile==0.13.1\n",
            "  Downloading soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soupsieve==2.6 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 505)) (2.6)\n",
            "Collecting soxr==0.5.0.post1\n",
            "  Downloading soxr-0.5.0.post1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.5/252.5 kB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy==3.7.5\n",
            "  Downloading spacy-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting spacy-legacy==3.0.12\n",
            "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
            "Collecting spacy-loggers==1.0.5\n",
            "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
            "Collecting spanner-graph-notebook==1.1.1\n",
            "  Downloading spanner_graph_notebook-1.1.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting Sphinx==8.1.3\n",
            "  Downloading sphinx-8.1.3-py3-none-any.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib-applehelp==2.0.0\n",
            "  Downloading sphinxcontrib_applehelp-2.0.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib-devhelp==2.0.0\n",
            "  Downloading sphinxcontrib_devhelp-2.0.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.5/82.5 kB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib-htmlhelp==2.1.0\n",
            "  Downloading sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 kB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib-jsmath==1.0.1\n",
            "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
            "Collecting sphinxcontrib-qthelp==2.0.0\n",
            "  Downloading sphinxcontrib_qthelp-2.0.0-py3-none-any.whl (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib-serializinghtml==2.0.0\n",
            "  Downloading sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting SQLAlchemy==2.0.38\n",
            "  Downloading SQLAlchemy-2.0.38-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlglot==25.6.1\n",
            "  Downloading sqlglot-25.6.1-py3-none-any.whl (391 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m391.6/391.6 kB\u001b[0m \u001b[31m98.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlparse==0.5.3\n",
            "  Downloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting srsly==2.5.1\n",
            "  Downloading srsly-2.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stanio==0.5.1\n",
            "  Downloading stanio-0.5.1-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: starlette==0.45.3 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 523)) (0.45.3)\n",
            "Collecting statsmodels==0.14.4\n",
            "  Downloading statsmodels-0.14.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting stringzilla==3.11.3\n",
            "  Downloading stringzilla-3.11.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.6/307.6 kB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy==1.13.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 526)) (1.13.1)\n",
            "Collecting tables==3.10.2\n",
            "  Downloading tables-3.10.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting tabulate==0.9.0\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Collecting tbb==2022.0.0\n",
            "  Downloading tbb-2022.0.0-py2.py3-none-manylinux_2_28_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting tcmlib==1.2.0\n",
            "  Downloading tcmlib-1.2.0-py2.py3-none-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting tenacity==9.0.0\n",
            "  Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
            "Collecting tensorboard==2.18.0\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-data-server==0.7.2\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.18.0\n",
            "  Downloading tensorflow-2.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.4/615.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-datasets==4.9.7\n",
            "  Downloading tensorflow_datasets-4.9.7-py3-none-any.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
            "\u001b[?25hCollecting tensorflow-hub==0.16.1\n",
            "  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
            "Collecting tensorflow-io-gcs-filesystem==0.37.1\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-metadata==1.16.1\n",
            "  Downloading tensorflow_metadata-1.16.1-py3-none-any.whl (28 kB)\n",
            "Collecting tensorflow-probability==0.25.0\n",
            "  Downloading tensorflow_probability-0.25.0-py2.py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m90.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-text==2.18.1\n",
            "  Downloading tensorflow_text-2.18.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting tensorstore==0.1.71\n",
            "  Downloading tensorstore-0.1.71-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.8/17.8 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor==2.5.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 542)) (2.5.0)\n",
            "Collecting terminado==0.18.1\n",
            "  Downloading terminado-0.18.1-py3-none-any.whl (14 kB)\n",
            "Collecting text-unidecode==1.3\n",
            "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting textblob==0.19.0\n",
            "  Downloading textblob-0.19.0-py3-none-any.whl (624 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.3/624.3 kB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tf-slim==1.1.0\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tf_keras==2.18.0\n",
            "  Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting thinc==8.2.5\n",
            "  Downloading thinc-8.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (920 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.2/920.2 kB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl==3.5.0\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Collecting tifffile==2025.2.18\n",
            "  Downloading tifffile-2025.2.18-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tiktoken==0.9.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 551)) (0.9.0)\n",
            "Collecting timm==1.0.14\n",
            "  Downloading timm-1.0.14-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tinycss2==1.4.0\n",
            "  Downloading tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: tokenizers==0.21.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 554)) (0.21.0)\n",
            "Collecting toml==0.10.2\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting toolz==0.12.1\n",
            "  Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchsummary==1.5.1\n",
            "  Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
            "Requirement already satisfied: tornado==6.4.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 561)) (6.4.2)\n",
            "Requirement already satisfied: tqdm==4.67.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 562)) (4.67.1)\n",
            "Collecting traitlets==5.7.1\n",
            "  Downloading traitlets-5.7.1-py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.9/109.9 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting traittypes==0.2.1\n",
            "  Downloading traittypes-0.2.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Collecting transformers==4.48.3\n",
            "  Using cached transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
            "Collecting treescope==0.1.9\n",
            "  Downloading treescope-0.1.9-py3-none-any.whl (182 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.2/182.2 kB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==3.1.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 567)) (3.1.0)\n",
            "Requirement already satisfied: trl==0.15.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 568)) (0.15.2)\n",
            "Collecting tweepy==4.15.0\n",
            "  Downloading tweepy-4.15.0-py3-none-any.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.4/99.4 kB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typeguard==4.4.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 570)) (4.4.2)\n",
            "Requirement already satisfied: typer==0.15.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 571)) (0.15.1)\n",
            "Collecting types-pytz==2025.1.0.20250204\n",
            "  Downloading types_pytz-2025.1.0.20250204-py3-none-any.whl (10 kB)\n",
            "Collecting types-setuptools==75.8.0.20250210\n",
            "  Downloading types_setuptools-75.8.0.20250210-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions==4.12.2 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 574)) (4.12.2)\n",
            "Requirement already satisfied: tyro==0.9.16 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 575)) (0.9.16)\n",
            "Requirement already satisfied: tzdata==2025.1 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 576)) (2025.1)\n",
            "Collecting tzlocal==5.3\n",
            "  Downloading tzlocal-5.3-py3-none-any.whl (17 kB)\n",
            "Collecting uc-micro-py==1.0.3\n",
            "  Downloading uc_micro_py-1.0.3-py3-none-any.whl (6.2 kB)\n",
            "Collecting umf==0.9.1\n",
            "  Downloading umf-0.9.1-py2.py3-none-manylinux_2_28_x86_64.whl (161 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.6/161.6 kB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: unsloth==2025.2.15 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 580)) (2025.2.15)\n",
            "Requirement already satisfied: unsloth_zoo==2025.2.7 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 581)) (2025.2.7)\n",
            "Collecting uritemplate==4.1.1\n",
            "  Downloading uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: urllib3==2.3.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 583)) (2.3.0)\n",
            "Requirement already satisfied: uvicorn==0.34.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 584)) (0.34.0)\n",
            "Requirement already satisfied: uvloop==0.21.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 585)) (0.21.0)\n",
            "Collecting vega-datasets==0.9.0\n",
            "  Downloading vega_datasets-0.9.0-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.8/210.8 kB\u001b[0m \u001b[31m75.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: vllm==0.7.3 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 587)) (0.7.3)\n",
            "Collecting wadllib==1.3.6\n",
            "  Downloading wadllib-1.3.6.tar.gz (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.2/62.2 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting wandb==0.19.6\n",
            "  Using cached wandb-0.19.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.9 MB)\n",
            "Collecting wasabi==1.1.3\n",
            "  Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: watchfiles==1.0.4 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 591)) (1.0.4)\n",
            "Requirement already satisfied: wcwidth==0.2.13 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 592)) (0.2.13)\n",
            "Collecting weasel==0.4.1\n",
            "  Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting webcolors==24.11.1\n",
            "  Downloading webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
            "Collecting webencodings==0.5.1\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting websocket-client==1.8.0\n",
            "  Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets==14.2\n",
            "  Downloading websockets-14.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (169 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.9/169.9 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Werkzeug==3.1.3\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting widgetsnbextension==3.6.10\n",
            "  Downloading widgetsnbextension-3.6.10-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wordcloud==1.9.4\n",
            "  Downloading wordcloud-1.9.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.9/547.9 kB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wrapt==1.17.2\n",
            "  Using cached wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "Collecting xarray==2025.1.2\n",
            "  Downloading xarray-2025.1.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xarray-einstats==0.8.0\n",
            "  Downloading xarray_einstats-0.8.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: xformers==0.0.28.post3 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 604)) (0.0.28.post3)\n",
            "Collecting xgboost==2.1.4\n",
            "  Downloading xgboost-2.1.4-py3-none-manylinux_2_28_x86_64.whl (223.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xgrammar==0.1.11 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 606)) (0.1.11)\n",
            "Collecting xlrd==2.0.1\n",
            "  Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash==3.5.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 608)) (3.5.0)\n",
            "Collecting xyzservices==2025.1.0\n",
            "  Downloading xyzservices-2025.1.0-py3-none-any.whl (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: yarl==1.18.3 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 610)) (1.18.3)\n",
            "Collecting yellowbrick==1.5\n",
            "  Downloading yellowbrick-1.5-py3-none-any.whl (282 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.6/282.6 kB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yfinance==0.2.54\n",
            "  Downloading yfinance-0.2.54-py2.py3-none-any.whl (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.7/108.7 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp==3.21.0 in /home/siai/.local/lib/python3.11/site-packages (from -r requirements.txt (line 613)) (3.21.0)\n",
            "Collecting zstandard==0.23.0\n",
            "  Downloading zstandard-0.23.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools>=60.0.0 in /usr/local/lib/python3.11/site-packages (from arviz==0.20.0->-r requirements.txt (line 17)) (65.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/siai/.local/lib/python3.11/site-packages (from astunparse==1.6.3->-r requirements.txt (line 21)) (0.45.1)\n",
            "Requirement already satisfied: fsspec[http]<=2024.12.0,>=2023.1.0 in /home/siai/.local/lib/python3.11/site-packages (from datasets==3.3.2->-r requirements.txt (line 79)) (2024.12.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/site-packages (from fastai==2.7.18->-r requirements.txt (line 111)) (22.3)\n",
            "Collecting googleapis-common-protos[grpc]<2.0.0dev,>=1.56.0\n",
            "  Downloading googleapis_common_protos-1.68.0-py2.py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.0/165.0 kB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of grpcio to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of grpc-interceptor to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of grpc-google-iam-v1 to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of greenlet to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of graphviz to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of googledrivedownloader to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of googleapis-common-protos to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-spark-connect to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-resumable-media to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-pasta to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-genai to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-crc32c to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-translate to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-storage to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-spanner to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-resource-manager to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-pubsub to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-language to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-iam to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-functions to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-firestore to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-datastore to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-dataproc to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-core to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-bigtable to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-bigquery-storage to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-bigquery-connection to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-bigquery to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-aiplatform to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-auth-oauthlib to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-auth-httplib2 to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-auth to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-api-python-client to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-api-core to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-ai-generativelanguage to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of glob2 to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of gitpython to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of gitdb to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of gin-config to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of gguf to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting gguf==0.10.0\n",
            "  Using cached gguf-0.10.0-py3-none-any.whl (71 kB)\n",
            "INFO: pip is looking at multiple versions of geopy to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of geopandas to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of geographiclib to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of geocoder to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of gensim to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of geemap to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of gdown to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of gcsfs to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of gast to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of future to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of fsspec to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of frozenlist to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting frozenlist==1.5.0\n",
            "  Using cached frozenlist-1.5.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (274 kB)\n",
            "INFO: pip is looking at multiple versions of frozendict to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of fonttools to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of folium to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of flax to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of flatbuffers to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of flask to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of firebase-admin to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of filelock to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting filelock==3.17.0\n",
            "  Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
            "INFO: pip is looking at multiple versions of fastrlock to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting fastrlock==0.8.3\n",
            "  Using cached fastrlock-0.8.3-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (54 kB)\n",
            "INFO: pip is looking at multiple versions of fastprogress to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of fastjsonschema to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of fastdownload to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of fastcore to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of fastapi-cli to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting fastapi-cli==0.0.7\n",
            "  Using cached fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n",
            "INFO: pip is looking at multiple versions of fastapi to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting fastapi==0.115.8\n",
            "  Using cached fastapi-0.115.8-py3-none-any.whl (94 kB)\n",
            "INFO: pip is looking at multiple versions of fastai to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of farama-notifications to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of etuples to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of etils to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of et-xmlfile to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of entrypoints to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of email-validator to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting email_validator==2.2.0\n",
            "  Using cached email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "INFO: pip is looking at multiple versions of grpc-google-iam-v1 to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of googleapis-common-protos to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-translate to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-spanner to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-resource-manager to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-pubsub to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-language to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-iam to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-functions to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-firestore to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-datastore to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-dataproc to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-bigtable to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-bigquery-storage to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-bigquery-connection to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-cloud-aiplatform to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-api-core to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of google-ai-generativelanguage to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of einops to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting einops==0.8.1\n",
            "  Using cached einops-0.8.1-py3-none-any.whl (64 kB)\n",
            "INFO: pip is looking at multiple versions of eerepr to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of editdistance to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of easydict to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of earthengine-api to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of duckdb to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of dopamine-rl to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of docutils to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of docstring-parser to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting docstring_parser==0.16\n",
            "  Using cached docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
            "INFO: pip is looking at multiple versions of docker-pycreds to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of dnspython to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting dnspython==2.7.0\n",
            "  Using cached dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "INFO: pip is looking at multiple versions of dm-tree to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of dlib to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of distro to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting distro==1.9.0\n",
            "  Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "INFO: pip is looking at multiple versions of diskcache to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting diskcache==5.6.3\n",
            "  Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "INFO: pip is looking at multiple versions of dill to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting dill==0.3.8\n",
            "  Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "INFO: pip is looking at multiple versions of diffusers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting diffusers==0.32.2\n",
            "  Using cached diffusers-0.32.2-py3-none-any.whl (3.2 MB)\n",
            "INFO: pip is looking at multiple versions of depyf to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting depyf==0.18.0\n",
            "  Using cached depyf-0.18.0-py3-none-any.whl (38 kB)\n",
            "INFO: pip is looking at multiple versions of deprecated to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of defusedxml to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of decorator to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of debugpy to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of dbus-python to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of db-dtypes to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of datasets to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting datasets==3.3.2\n",
            "  Using cached datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "INFO: pip is looking at multiple versions of datascience to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of dask to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cython to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cymem to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cycler to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cvxpy to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cvxopt to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cut-cross-entropy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting cut-cross-entropy==25.1.1\n",
            "  Using cached cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "INFO: pip is looking at multiple versions of cupy-cuda12x to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting cupy-cuda12x==13.3.0\n",
            "  Using cached cupy_cuda12x-13.3.0-cp311-cp311-manylinux2014_x86_64.whl (91.2 MB)\n",
            "INFO: pip is looking at multiple versions of cufflinks to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cuda-python to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cryptography to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cramjam to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of contourpy to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cons to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of confection to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of compressed-tensors to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting compressed-tensors==0.9.1\n",
            "  Using cached compressed_tensors-0.9.1-py3-none-any.whl (96 kB)\n",
            "INFO: pip is looking at multiple versions of community to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of colour to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of colorlover to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of colorcet to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cmdstanpy to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cmake to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cloudpickle to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting cloudpickle==3.1.1\n",
            "  Using cached cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "INFO: pip is looking at multiple versions of cloudpathlib to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of click to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting click==8.1.8\n",
            "  Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
            "INFO: pip is looking at multiple versions of clarabel to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of chex to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of charset-normalizer to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting charset-normalizer==3.4.1\n",
            "  Using cached charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "INFO: pip is looking at multiple versions of chardet to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cffi to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of certifi to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting certifi==2025.1.31\n",
            "  Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "INFO: pip is looking at multiple versions of catalogue to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cachetools to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of cachecontrol to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of branca to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of bqplot to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of bottleneck to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of bokeh to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of blosc2 to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of blis to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of blinker to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of bleach to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of blake3 to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting blake3==1.0.4\n",
            "  Using cached blake3-1.0.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (376 kB)\n",
            "INFO: pip is looking at multiple versions of bitsandbytes to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting bitsandbytes==0.45.3\n",
            "  Using cached bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "INFO: pip is looking at multiple versions of bigquery-magics to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of bigframes to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of betterproto to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of beautifulsoup4 to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting beautifulsoup4==4.13.3\n",
            "  Using cached beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
            "INFO: pip is looking at multiple versions of backcall to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of babel to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of autograd to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of audioread to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of attrs to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting attrs==25.1.0\n",
            "  Using cached attrs-25.1.0-py3-none-any.whl (63 kB)\n",
            "INFO: pip is looking at multiple versions of atpublic to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of astunparse to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of astropy-iers-data to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of astropy to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of astor to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting astor==0.8.1\n",
            "  Using cached astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
            "INFO: pip is looking at multiple versions of arviz to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of array-record to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of argon2-cffi-bindings to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of argon2-cffi to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of anyio to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of annotated-types to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting annotated-types==0.7.0\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "INFO: pip is looking at multiple versions of altair to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of ale-py to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of albumentations to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of albucore to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of alabaster to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of airportsdata to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting airportsdata==20250224\n",
            "  Using cached airportsdata-20250224-py3-none-any.whl (913 kB)\n",
            "INFO: pip is looking at multiple versions of aiosignal to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting aiosignal==1.3.2\n",
            "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "INFO: pip is looking at multiple versions of aiohttp to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of aiohappyeyeballs to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting aiohappyeyeballs==2.4.6\n",
            "  Using cached aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
            "INFO: pip is looking at multiple versions of accelerate to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of absl-py to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install -r requirements.txt (line 146), -r requirements.txt (line 147), -r requirements.txt (line 152), -r requirements.txt (line 154), -r requirements.txt (line 155), -r requirements.txt (line 156), -r requirements.txt (line 158), -r requirements.txt (line 159), -r requirements.txt (line 160), -r requirements.txt (line 161), -r requirements.txt (line 162), -r requirements.txt (line 163), -r requirements.txt (line 164), -r requirements.txt (line 165), -r requirements.txt (line 166), -r requirements.txt (line 168), -r requirements.txt (line 172), -r requirements.txt (line 176), -r requirements.txt (line 180), -r requirements.txt (line 183) and protobuf==3.20.3 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    The user requested protobuf==3.20.3\n",
            "    google-ai-generativelanguage 0.6.15 depends on protobuf!=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0dev and >=3.20.2\n",
            "    google-api-core 2.24.1 depends on protobuf!=3.20.0, !=3.20.1, !=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0.dev0 and >=3.19.5\n",
            "    google-cloud-aiplatform 1.79.0 depends on protobuf!=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0dev and >=3.20.2\n",
            "    google-cloud-bigquery-connection 1.18.0 depends on protobuf!=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0dev and >=3.20.2\n",
            "    google-cloud-bigquery-storage 2.28.0 depends on protobuf!=3.20.0, !=3.20.1, !=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0dev and >=3.20.2\n",
            "    google-cloud-bigtable 2.28.1 depends on protobuf!=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0dev and >=3.20.2\n",
            "    google-cloud-dataproc 5.17.0 depends on protobuf!=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0dev and >=3.20.2\n",
            "    google-cloud-datastore 2.20.2 depends on protobuf!=3.20.0, !=3.20.1, !=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0dev and >=3.20.2\n",
            "    google-cloud-firestore 2.20.0 depends on protobuf!=3.20.0, !=3.20.1, !=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0dev and >=3.20.2\n",
            "    google-cloud-functions 1.19.0 depends on protobuf!=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0dev and >=3.20.2\n",
            "    google-cloud-iam 2.18.0 depends on protobuf!=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0dev and >=3.20.2\n",
            "    google-cloud-language 2.16.0 depends on protobuf!=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0dev and >=3.20.2\n",
            "    google-cloud-pubsub 2.25.0 depends on protobuf!=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0dev and >=3.20.2\n",
            "    google-cloud-resource-manager 1.14.0 depends on protobuf!=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0dev and >=3.20.2\n",
            "    google-cloud-spanner 3.51.0 depends on protobuf!=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0dev and >=3.20.2\n",
            "    google-cloud-translate 3.19.0 depends on protobuf!=4.21.0, !=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0dev and >=3.20.2\n",
            "    google-generativeai 0.8.4 depends on protobuf\n",
            "    googleapis-common-protos 1.67.0 depends on protobuf!=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0.dev0 and >=3.20.2\n",
            "    grpc-google-iam-v1 0.14.0 depends on protobuf!=4.21.1, !=4.21.2, !=4.21.3, !=4.21.4, !=4.21.5, <6.0.0dev and >=3.20.2\n",
            "    grpcio-status 1.62.3 depends on protobuf>=4.21.6\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.11 install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip3.11 install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xnm_FUyqG4S"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1zyu9Ug2XEt"
      },
      "source": [
        "Use `PatchFastRL` before all functions to patch GRPO and other RL algorithms!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59DIs5BMcvjN",
        "outputId": "a4b3de70-c99c-4e76-ee06-dab6a6505a8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/siai/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named '_lzma'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munsloth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel, PatchFastRL\n\u001b[1;32m      2\u001b[0m PatchFastRL(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGRPO\u001b[39m\u001b[38;5;124m\"\u001b[39m, FastLanguageModel)\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/unsloth/__init__.py:212\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsloth: Please install unsloth_zoo via `pip install unsloth_zoo`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 212\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msave\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchat_templates\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/unsloth/models/__init__.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2023-present Daniel Han-Chen & the Unsloth team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgranite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastGraniteModel\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m\u001b[38;5;250m  \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel, FastVisionModel\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllama\u001b[39;00m\u001b[38;5;250m   \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastLlamaModel\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/unsloth/models/granite.py:15\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2023-present Daniel Han-Chen & the Unsloth team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllama\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/unsloth/models/llama.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfunctools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m partial\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Optional, Tuple, List, Union\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m scaled_dot_product_attention\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/unsloth/models/_utils.py:78\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msubprocess\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpsutil\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munsloth_zoo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munsloth_zoo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenizer_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     79\u001b[0m     patch_tokenizer \u001b[38;5;28;01mas\u001b[39;00m _patch_tokenizer,\n\u001b[1;32m     80\u001b[0m )\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munsloth_zoo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatching_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     82\u001b[0m     patch_compiling_bitsandbytes,\n\u001b[1;32m     83\u001b[0m     patch_layernorm,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m     patch_compiled_autograd,\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01munsloth_zoo\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgradient_checkpointing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     89\u001b[0m     Unsloth_Offloaded_Gradient_Checkpointer,\n\u001b[1;32m     90\u001b[0m     unsloth_offloaded_gradient_checkpoint,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     unpatch_unsloth_smart_gradient_checkpointing,\n\u001b[1;32m    101\u001b[0m )\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/unsloth_zoo/tokenizer_utils.py:21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m     24\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_of_trained_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd_new_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfix_untrained_tokens\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatch_tokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     29\u001b[0m ]\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/__init__.py:17\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m3.3.2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/arrow_dataset.py:78\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m thread_map\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowReader\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_writer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArrowWriter, OptimizedTypedSequence\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_files\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sanitize_patterns\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/arrow_reader.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpq\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m thread_map\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnaming\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _split_re, filenames_for_dataset_split\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InMemoryTable, MemoryMappedTable, Table, concat_tables\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/download/__init__.py:9\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloadConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloadManager\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloadMode\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStreamingDownloadManager\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_manager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DownloadManager, DownloadMode\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstreaming_download_manager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StreamingDownloadManager\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/download/download_manager.py:32\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m hf_tqdm\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     33\u001b[0m     ArchiveIterable,\n\u001b[1;32m     34\u001b[0m     FilesIterable,\n\u001b[1;32m     35\u001b[0m     cached_path,\n\u001b[1;32m     36\u001b[0m     is_relative_path,\n\u001b[1;32m     37\u001b[0m     stack_multiprocessing_download_progress_bars,\n\u001b[1;32m     38\u001b[0m     url_or_path_join,\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_size_checksum_dict\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_logger, tqdm\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/utils/file_utils.py:45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _tqdm, logging\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_filelock\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FileLock\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mextract\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ExtractManager\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrack\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TrackedIterableFromGenerator\n\u001b[1;32m     49\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n",
            "File \u001b[0;32m~/.local/lib/python3.11/site-packages/datasets/utils/extract.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbz2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgzip\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlzma\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshutil\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/lib/python3.11/lzma.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mio\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lzma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_lzma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _encode_filter_properties, _decode_filter_properties\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_compression\u001b[39;00m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '_lzma'"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel, PatchFastRL\n",
        "PatchFastRL(\"GRPO\", FastLanguageModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8-SLRUB2gwM"
      },
      "source": [
        "Load up `Llama 3.1 8B Instruct`, and set parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700,
          "referenced_widgets": [
            "d8d0dca36cfc47f0919924da07c231e8",
            "5f3d96b613e94e9984d4599ca9ca7b17",
            "66c3271554b1455eb56be55c9241e45e",
            "d36b61cf796c429080e93ea838a3759e",
            "94873c3c077e483790b34f95c421f484",
            "ea549fffa8c2469888d1668158bc105c",
            "98b432b98839428f85d91580c21e80e2",
            "fee4f852c9744a07b909e586e3615604",
            "3febcf8a8eca40c28aafc697f3ec8776",
            "b4e1eb8eeb064c88a2142e474fb8327f",
            "da10502506f9448c9de94f1ddd84d3b1",
            "e6cc388e78c14abfaa49d2be6fa1b5d9",
            "769bde36e2ba4434bddd78e7d5911be4",
            "3c522d78b1834068bd4b155d0f87a4d7",
            "a23afba19c2a4d3a90d771fc55f8d490",
            "6221f0be3b8d48e797c873565a216680",
            "1ac03aff5c314b00ac938c80eb7b2f8a",
            "88c63d94a05a42c49d5f8958a27987a6",
            "0ca67b0c4ca64eb788358a51308f6b97",
            "83c3c811923a4642aba156d1215b39d2",
            "e863bf099e064da7b482c21fe7b77de7",
            "697faad6643a43aca98015da4faef186"
          ]
        },
        "id": "DkIvEkIIkEyB",
        "outputId": "514dea04-804e-47a8-b891-ed3f4a6fb530"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth 2025.2.15: Fast Llama patching. Transformers: 4.48.3.\n",
            "   \\\\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.0+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post2. FA2 = True]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading unsloth/meta-llama-3.1-8b-instruct-unsloth-bnb-4bit with actual GPU utilization = 37.89%\n",
            "Unsloth: Your GPU has CUDA compute capability 8.6 with VRAM = 47.54 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 512. Num Sequences = 224.\n",
            "Unsloth: vLLM's KV Cache can use up to 11.84 GB. Also swap space = 6 GB.\n",
            "INFO 02-25 19:54:22 config.py:526] This model supports multiple tasks: {'embed', 'score', 'reward', 'generate', 'classify'}. Defaulting to 'generate'.\n",
            "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'bfloat16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.1.mlp'], 'llm_int8_threshold': 6.0}\n",
            "INFO 02-25 19:54:22 llm_engine.py:232] Initializing a V0 LLM engine (v0.7.1) with config: model='unsloth/meta-llama-3.1-8b-instruct-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/meta-llama-3.1-8b-instruct-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=512, download_dir=None, load_format=bitsandbytes, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/meta-llama-3.1-8b-instruct-unsloth-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":224}, use_cached_outputs=False, \n",
            "INFO 02-25 19:54:23 cuda.py:235] Using Flash Attention backend.\n",
            "INFO 02-25 19:54:23 model_runner.py:1111] Starting to load model unsloth/meta-llama-3.1-8b-instruct-unsloth-bnb-4bit...\n",
            "INFO 02-25 19:54:23 loader.py:1078] Loading weights with BitsAndBytes quantization.  May take a while ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W225 19:54:23.469496515 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-25 19:54:24 weight_utils.py:251] Using model weights format ['*.safetensors']\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a36da39d39ed4983b60597d6044b7094",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "246977ae6f424246914f5faa7764bdd1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-25 19:54:26 model_runner.py:1116] Loading model weights took 5.5976 GB\n",
            "INFO 02-25 19:54:26 punica_selector.py:16] Using PunicaWrapperGPU.\n",
            "INFO 02-25 19:54:28 worker.py:266] Memory profiling takes 1.34 seconds\n",
            "INFO 02-25 19:54:28 worker.py:266] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.38) = 18.01GiB\n",
            "INFO 02-25 19:54:28 worker.py:266] model weights take 5.60GiB; non_torch_memory takes 0.06GiB; PyTorch activation peak memory takes 1.04GiB; the rest of the memory reserved for KV Cache is 11.32GiB.\n",
            "INFO 02-25 19:54:28 executor_base.py:108] # CUDA blocks: 5794, # CPU blocks: 3072\n",
            "INFO 02-25 19:54:28 executor_base.py:113] Maximum concurrency for 512 tokens per request: 181.06x\n",
            "INFO 02-25 19:54:33 model_runner.py:1435] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Capturing CUDA graph shapes: 100%|██████████| 31/31 [00:32<00:00,  1.05s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-25 19:55:05 model_runner.py:1563] Graph capturing finished in 32 secs, took 4.01 GiB\n",
            "INFO 02-25 19:55:05 llm_engine.py:429] init engine (profile, create kv cache, warmup model) took 39.17 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Unsloth 2025.2.15 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import is_bfloat16_supported\n",
        "import torch\n",
        "max_seq_length = 512 # Can increase for longer reasoning traces\n",
        "lora_rank = 32 # Larger rank = smarter, but slower\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"meta-llama/meta-Llama-3.1-8B-Instruct\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    load_in_4bit = True, # False for LoRA 16bit\n",
        "    fast_inference = True, # Enable vLLM fast inference\n",
        "    max_lora_rank = lora_rank,\n",
        "    gpu_memory_utilization = 0.6, # Reduce if out of memory\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "    ], # Remove QKVO if out of memory\n",
        "    lora_alpha = lora_rank,\n",
        "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
        "    random_state = 3407,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KGgPgk_5S8r"
      },
      "source": [
        "### Data Prep\n",
        "<a name=\"Data\"></a>\n",
        "\n",
        "We directly leverage [@willccbb](https://gist.github.com/willccbb/4676755236bb08cab5f4e54a0475d6fb) for data prep and all reward functions. You are free to create your own!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cXk993X6C2ZZ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Load and prep dataset\n",
        "SYSTEM_PROMPT = \"\"\"\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "...\n",
        "</reasoning>\n",
        "<answer>\n",
        "...\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "XML_COT_FORMAT = \"\"\"\\\n",
        "<reasoning>\n",
        "{reasoning}\n",
        "</reasoning>\n",
        "<answer>\n",
        "{answer}\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    answer = text.split(\"<answer>\")[-1]\n",
        "    answer = answer.split(\"</answer>\")[0]\n",
        "    return answer.strip()\n",
        "\n",
        "def extract_hash_answer(text: str) -> str | None:\n",
        "    if \"####\" not in text:\n",
        "        return None\n",
        "    return text.split(\"####\")[1].strip()\n",
        "\n",
        "# uncomment middle messages for 1-shot prompting\n",
        "def get_gsm8k_questions(split = \"train\") -> Dataset:\n",
        "    data = load_dataset('openai/gsm8k', 'main')[split] # type: ignore\n",
        "    data = data.map(lambda x: { # type: ignore\n",
        "        'prompt': [\n",
        "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
        "            {'role': 'user', 'content': x['question']}\n",
        "        ],\n",
        "        'answer': extract_hash_answer(x['answer'])\n",
        "    }) # type: ignore\n",
        "    return data # type: ignore\n",
        "\n",
        "dataset = get_gsm8k_questions()\n",
        "\n",
        "# Reward functions\n",
        "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    q = prompts[0][-1]['content']\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "    print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
        "    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]\n",
        "\n",
        "def int_reward_func(completions, **kwargs) -> list[float]:\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]\n",
        "\n",
        "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"^<reasoning>\\n.*?\\n</reasoning>\\n<answer>\\n.*?\\n</answer>\\n$\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [re.match(pattern, r) for r in responses]\n",
        "    return [0.5 if match else 0.0 for match in matches]\n",
        "\n",
        "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [re.match(pattern, r) for r in responses]\n",
        "    return [0.5 if match else 0.0 for match in matches]\n",
        "\n",
        "def count_xml(text) -> float:\n",
        "    count = 0.0\n",
        "    if text.count(\"<reasoning>\\n\") == 1:\n",
        "        count += 0.125\n",
        "    if text.count(\"\\n</reasoning>\\n\") == 1:\n",
        "        count += 0.125\n",
        "    if text.count(\"\\n<answer>\\n\") == 1:\n",
        "        count += 0.125\n",
        "        count -= len(text.split(\"\\n</answer>\\n\")[-1])*0.001\n",
        "    if text.count(\"\\n</answer>\") == 1:\n",
        "        count += 0.125\n",
        "        count -= (len(text.split(\"\\n</answer>\")[-1]) - 1)*0.001\n",
        "    return count\n",
        "\n",
        "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
        "    contents = [completion[0][\"content\"] for completion in completions]\n",
        "    return [count_xml(c) for c in contents]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux6iqP7z5YOo"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "\n",
        "Now set up GRPO Trainer and all configurations!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptqkXK2D4d6p",
        "outputId": "9d5551f4-0276-47ca-e4ca-e96c846cc976"
      },
      "outputs": [],
      "source": [
        "from trl import GRPOConfig, GRPOTrainer\n",
        "training_args = GRPOConfig(\n",
        "    use_vllm = True, # use vLLM for fast inference!\n",
        "    learning_rate = 5e-6,\n",
        "    adam_beta1 = 0.9,\n",
        "    adam_beta2 = 0.99,\n",
        "    weight_decay = 0.1,\n",
        "    warmup_ratio = 0.1,\n",
        "    lr_scheduler_type = \"cosine\",\n",
        "    optim = \"paged_adamw_8bit\",\n",
        "    logging_steps = 1,\n",
        "    bf16 = is_bfloat16_supported(),\n",
        "    fp16 = not is_bfloat16_supported(),\n",
        "    per_device_train_batch_size = 1,\n",
        "    gradient_accumulation_steps = 1, # Increase to 4 for smoother training\n",
        "    num_generations = 6, # Decrease if out of memory\n",
        "    max_prompt_length = 256,\n",
        "    max_completion_length = 200,\n",
        "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
        "    max_steps = 250,\n",
        "    save_steps = 250,\n",
        "    max_grad_norm = 0.1,\n",
        "    report_to = \"none\", # Can use Weights & Biases\n",
        "    output_dir = \"outputs\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset.set_format(type='torch')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9Mv8UZO5hz-"
      },
      "source": [
        "And let's run the trainer! If you scroll up, you'll see a table of rewards. The goal is to see the `reward` column increase!\n",
        "\n",
        "You might have to wait 150 to 200 steps for any action. You'll probably get 0 reward for the first 100 steps. Please be patient!\n",
        "\n",
        "| Step | Training Loss | reward    | reward_std | completion_length | kl       |\n",
        "|------|---------------|-----------|------------|-------------------|----------|\n",
        "| 1    | 0.000000      | 0.125000  | 0.000000   | 200.000000        | 0.000000 |\n",
        "| 2    | 0.000000      | 0.072375  | 0.248112   | 200.000000        | 0.000000 |\n",
        "| 3    | 0.000000      | -0.079000 | 0.163776   | 182.500000        | 0.000005 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vzOuSVCL_GA9",
        "outputId": "a71824d4-afd8-47ac-f0ea-eae276927e19"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 7,473 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 1 | Gradient Accumulation steps = 1\n",
            "\\        /    Total batch size = 1 | Total steps = 250\n",
            " \"-____-\"     Number of trainable parameters = 83,886,080\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "list indices must be integers or slices, not str",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_4036652/2401788477.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2171\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2172\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2173\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/unsloth/models/_utils.py\u001b[0m in \u001b[0;36m_unsloth_training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n",
            "\u001b[0;32m~/Documents/GitHub/NeSy_Policy_Reasoning/unsloth_compiled_cache/UnslothGRPOTrainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m    764\u001b[0m         \u001b[0;31m# Compute the per-token log probabilities for the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m         \u001b[0mprompt_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"prompt_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m         \u001b[0mcompletion_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompletion_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"completion_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"completion_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprompt_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompletion_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ],
      "source": [
        "trainer = GRPOTrainer(\n",
        "    model = model,\n",
        "    processing_class = tokenizer,\n",
        "    reward_funcs = [\n",
        "        xmlcount_reward_func,\n",
        "        soft_format_reward_func,\n",
        "        strict_format_reward_func,\n",
        "        int_reward_func,\n",
        "        correctness_reward_func,\n",
        "    ],\n",
        "    args = training_args,\n",
        "    train_dataset = dataset,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlaUdxC_VHpz"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Now let's try the model we just trained! First, let's first try the model without any GRPO trained:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "qtcz_lpbVC92",
        "outputId": "9b12655a-7905-42a8-d6f0-210ff74a6d73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.78s/it, est. speed input: 1.64 toks/s, output: 19.94 toks/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Calculating pi to a large number of decimal places is a complex task that requires a computational approach, rather than a simple mathematical formula. Here\\'s a way to calculate pi using the Monte Carlo method, which is an approximation method that uses random numbers to estimate the value of pi:\\n\\n**The Monte Carlo Method**\\n\\nThe Monte Carlo method is based on the idea of simulating the probability of a random walk across a square and circle. Here\\'s the basic idea:\\n\\n1. Draw a square and a circle on a piece of paper.\\n2. Generate random points within the square.\\n3. Count the proportion of points that fall within the circle.\\n4. The ratio of points within the circle to the total number of points is approximately equal to the ratio of the area of the circle to the area of the square, which is pi.\\n\\n**Mathematical Formulation**\\n\\nLet\\'s denote the following variables:\\n\\n*   `N`: the number of random points generated\\n*   `n`: the number of points within the circle\\n*   `pi_approx`: the approximated value of pi\\n\\nThe formula to calculate pi is:\\n\\n`pi_approx = (4 * n) / N`\\n\\n**Python Code**\\n\\nHere\\'s a simple Python code snippet to calculate pi using the Monte Carlo method:\\n\\n```python\\nimport random\\nimport math\\n\\ndef calculate_pi(num_points):\\n    # Generate random points within the square (-1, -1) to (1, 1)\\n    points_inside_circle = 0\\n    for _ in range(num_points):\\n        x, y = random.uniform(-1, 1), random.uniform(-1, 1)\\n        # Check if the point falls within the circle (radius 1)\\n        if x**2 + y**2 <= 1:\\n            points_inside_circle += 1\\n\\n    # Calculate pi using the Monte Carlo method\\n    pi_approx = (4 * points_inside_circle) / num_points\\n    return pi_approx\\n\\nnum_points = 1000000\\npi_approx = calculate_pi(num_points)\\nprint(f\"Approximated pi: {pi_approx}\")\\nprint(f\"Difference between approximated pi and actual pi: {abs(pi_approx - math.pi)}\")\\n```\\n\\n**Note**: The more points you generate, the more accurate the approximation will be.\\n\\n**Limitations**\\n\\nThis method has a few limitations:\\n\\n'"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = tokenizer.apply_chat_template([\n",
        "    {\"role\" : \"user\", \"content\" : \"Calculate pi.\"},\n",
        "], tokenize = False, add_generation_prompt = True)\n",
        "\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 0.8,\n",
        "    top_p = 0.95,\n",
        "    max_tokens = 1024,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    [text],\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = None,\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Colxz9TAVMsi"
      },
      "source": [
        "And now with the LoRA we just trained with GRPO - we first save the LoRA first!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL-BcuB1VLIv"
      },
      "outputs": [],
      "source": [
        "model.save_lora(\"grpo_saved_lora\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwpbwnDBVRLg"
      },
      "source": [
        "Now we load the LoRA and test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "zf_OY5WMVOxF",
        "outputId": "c34d81a7-192d-427d-81f0-cbca7009b7d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Processed prompts: 100%|██████████| 1/1 [00:23<00:00, 23.29s/it, est. speed input: 2.62 toks/s, output: 19.41 toks/s]\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"<reasoning>\\nPi (π) is an irrational number that represents the ratio of a circle's circumference to its diameter. It is approximately equal to 3.14159, but its decimal representation goes on indefinitely without repeating.\\n\\nTo calculate pi, we can use various mathematical formulas and methods, such as the Leibniz formula, the Gregory-Leibniz series, or the Monte Carlo method. However, these methods are not practical for obtaining a high degree of accuracy.\\n\\nA more practical approach is to use the Bailey-Borwein-Plouffe (BBP) formula, which is a spigot algorithm that allows us to calculate any digit of pi without having to compute the preceding digits.\\n\\nAnother method is to use the Chudnovsky algorithm, which is a fast and efficient method for calculating pi to a high degree of accuracy.\\n\\nFor simplicity, we can use the first few terms of the BBP formula to estimate pi:\\nπ = 3 + 1/(4/3 - 1/(4/3 - 1/(4/3 - ...))\\n\\nLet's use this simplified formula to estimate pi:\\n\\nπ ≈ 3 + 1/(4/3) ≈ 3 + 1.3333 ≈ 4.3333\\n\\nNow, let's add the next term:\\nπ ≈ 4.3333 + 1/(4/3 - 1/(4/3)) ≈ 4.3333 + 1/(1.3333 - 0.3333) ≈ 4.3333 + 0.6667 ≈ 5.0000\\n\\nNext term:\\nπ ≈ 5.0000 + 1/(1.3333 - 1/(1.3333 - 1/(1.3333))) ≈ 5.0000 + 1/(0.6667 - 0.3333) ≈ 5.0000 + 0.3333 ≈ 5.3333\\n\\nContinuing this process, we can obtain more accurate approximations of pi. However, for a more accurate answer, we would need to use a computer program or a calculator.\\n\\nA more precise calculation using a computer or calculator would give us a\""
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = tokenizer.apply_chat_template([\n",
        "    {\"role\" : \"system\", \"content\" : SYSTEM_PROMPT},\n",
        "    {\"role\" : \"user\", \"content\" : \"Calculate pi.\"},\n",
        "], tokenize = False, add_generation_prompt = True)\n",
        "\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 0.8,\n",
        "    top_p = 0.95,\n",
        "    max_tokens = 1024,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    text,\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = model.load_lora(\"grpo_saved_lora\"),\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aDgFfhFYIAS"
      },
      "source": [
        "Our reasoning model is much better - it's not always correct, since we only trained it for an hour or so - it'll be better if we extend the sequence length and train for longer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NUEmHFSYNTp"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjXGTkp7YNtB"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52WMb3k_YPt8"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyEjW-WuYQIm"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n33Lwz_eqG4Z"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp or a UI based system like Jan or Open WebUI. You can install Jan [here](https://github.com/janhq/jan) and Open WebUI [here](https://github.com/open-webui/open-webui)\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Llama 3.2 Conversational notebook. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ⭐️ <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ⭐️\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ca67b0c4ca64eb788358a51308f6b97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ac03aff5c314b00ac938c80eb7b2f8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c522d78b1834068bd4b155d0f87a4d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ca67b0c4ca64eb788358a51308f6b97",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83c3c811923a4642aba156d1215b39d2",
            "value": 1
          }
        },
        "3febcf8a8eca40c28aafc697f3ec8776": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f3d96b613e94e9984d4599ca9ca7b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea549fffa8c2469888d1668158bc105c",
            "placeholder": "​",
            "style": "IPY_MODEL_98b432b98839428f85d91580c21e80e2",
            "value": ""
          }
        },
        "6221f0be3b8d48e797c873565a216680": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66c3271554b1455eb56be55c9241e45e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fee4f852c9744a07b909e586e3615604",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3febcf8a8eca40c28aafc697f3ec8776",
            "value": 1
          }
        },
        "697faad6643a43aca98015da4faef186": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "769bde36e2ba4434bddd78e7d5911be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ac03aff5c314b00ac938c80eb7b2f8a",
            "placeholder": "​",
            "style": "IPY_MODEL_88c63d94a05a42c49d5f8958a27987a6",
            "value": ""
          }
        },
        "83c3c811923a4642aba156d1215b39d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88c63d94a05a42c49d5f8958a27987a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94873c3c077e483790b34f95c421f484": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98b432b98839428f85d91580c21e80e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a23afba19c2a4d3a90d771fc55f8d490": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e863bf099e064da7b482c21fe7b77de7",
            "placeholder": "​",
            "style": "IPY_MODEL_697faad6643a43aca98015da4faef186",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:16&lt;00:00, 16.13s/it]\n"
          }
        },
        "b4e1eb8eeb064c88a2142e474fb8327f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d36b61cf796c429080e93ea838a3759e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4e1eb8eeb064c88a2142e474fb8327f",
            "placeholder": "​",
            "style": "IPY_MODEL_da10502506f9448c9de94f1ddd84d3b1",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:27&lt;00:00, 27.50s/it]\n"
          }
        },
        "d8d0dca36cfc47f0919924da07c231e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f3d96b613e94e9984d4599ca9ca7b17",
              "IPY_MODEL_66c3271554b1455eb56be55c9241e45e",
              "IPY_MODEL_d36b61cf796c429080e93ea838a3759e"
            ],
            "layout": "IPY_MODEL_94873c3c077e483790b34f95c421f484"
          }
        },
        "da10502506f9448c9de94f1ddd84d3b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6cc388e78c14abfaa49d2be6fa1b5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_769bde36e2ba4434bddd78e7d5911be4",
              "IPY_MODEL_3c522d78b1834068bd4b155d0f87a4d7",
              "IPY_MODEL_a23afba19c2a4d3a90d771fc55f8d490"
            ],
            "layout": "IPY_MODEL_6221f0be3b8d48e797c873565a216680"
          }
        },
        "e863bf099e064da7b482c21fe7b77de7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea549fffa8c2469888d1668158bc105c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fee4f852c9744a07b909e586e3615604": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
