{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZ5x6xlUqG4N"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxKlbfLhqG4P"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sf7gq1YJqG4Q"
      },
      "source": [
        "**Read our [blog post](https://unsloth.ai/blog/r1-reasoning) for guidance on how to train reasoning models.**\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Xpcb5j3qG4Q"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xnm_FUyqG4S"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1zyu9Ug2XEt"
      },
      "source": [
        "Use `PatchFastRL` before all functions to patch GRPO and other RL algorithms!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59DIs5BMcvjN",
        "outputId": "a4b3de70-c99c-4e76-ee06-dab6a6505a8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/siai/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-02-27 14:44:27,398\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel, PatchFastRL\n",
        "PatchFastRL(\"GRPO\", FastLanguageModel)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8-SLRUB2gwM"
      },
      "source": [
        "Load up `Llama 3.1 8B Instruct`, and set parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700,
          "referenced_widgets": [
            "d8d0dca36cfc47f0919924da07c231e8",
            "5f3d96b613e94e9984d4599ca9ca7b17",
            "66c3271554b1455eb56be55c9241e45e",
            "d36b61cf796c429080e93ea838a3759e",
            "94873c3c077e483790b34f95c421f484",
            "ea549fffa8c2469888d1668158bc105c",
            "98b432b98839428f85d91580c21e80e2",
            "fee4f852c9744a07b909e586e3615604",
            "3febcf8a8eca40c28aafc697f3ec8776",
            "b4e1eb8eeb064c88a2142e474fb8327f",
            "da10502506f9448c9de94f1ddd84d3b1",
            "e6cc388e78c14abfaa49d2be6fa1b5d9",
            "769bde36e2ba4434bddd78e7d5911be4",
            "3c522d78b1834068bd4b155d0f87a4d7",
            "a23afba19c2a4d3a90d771fc55f8d490",
            "6221f0be3b8d48e797c873565a216680",
            "1ac03aff5c314b00ac938c80eb7b2f8a",
            "88c63d94a05a42c49d5f8958a27987a6",
            "0ca67b0c4ca64eb788358a51308f6b97",
            "83c3c811923a4642aba156d1215b39d2",
            "e863bf099e064da7b482c21fe7b77de7",
            "697faad6643a43aca98015da4faef186"
          ]
        },
        "id": "DkIvEkIIkEyB",
        "outputId": "514dea04-804e-47a8-b891-ed3f4a6fb530"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-27 14:44:28 __init__.py:207] Automatically detected platform cuda.\n",
            "==((====))==  Unsloth 2025.2.15: Fast Qwen2 patching. Transformers: 4.49.0.\n",
            "   \\\\   /|    GPU: NVIDIA RTX A6000. Max memory: 47.536 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.5.1+cu124. CUDA: 8.6. CUDA Toolkit: 12.4. Triton: 3.1.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.28.post3. FA2 = True]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: vLLM loading kings-crown/Isabelle_FVELer_SFT with actual GPU utilization = 79.47%\n",
            "Unsloth: Your GPU has CUDA compute capability 8.6 with VRAM = 47.54 GB.\n",
            "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 2048. Num Sequences = 288.\n",
            "Unsloth: vLLM's KV Cache can use up to 22.99 GB. Also swap space = 6 GB.\n",
            "INFO 02-27 14:44:33 config.py:549] This model supports multiple tasks: {'embed', 'generate', 'reward', 'score', 'classify'}. Defaulting to 'generate'.\n",
            "INFO 02-27 14:44:33 llm_engine.py:234] Initializing a V0 LLM engine (v0.7.3) with config: model='kings-crown/Isabelle_FVELer_SFT', speculative_config=None, tokenizer='kings-crown/Isabelle_FVELer_SFT', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='xgrammar'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=kings-crown/Isabelle_FVELer_SFT, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":288}, use_cached_outputs=False, \n",
            "INFO 02-27 14:44:34 cuda.py:229] Using Flash Attention backend.\n",
            "INFO 02-27 14:44:34 model_runner.py:1110] Starting to load model kings-crown/Isabelle_FVELer_SFT...\n",
            "INFO 02-27 14:44:34 weight_utils.py:254] Using model weights format ['*.safetensors']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[W227 14:44:34.127945147 CUDAAllocatorConfig.h:28] Warning: expandable_segments not supported on this platform (function operator())\n",
            "Loading safetensors checkpoint shards:   0% Completed | 0/4 [00:00<?, ?it/s]\n",
            "Loading safetensors checkpoint shards:  25% Completed | 1/4 [00:00<00:01,  2.47it/s]\n",
            "Loading safetensors checkpoint shards:  50% Completed | 2/4 [00:00<00:00,  3.40it/s]\n",
            "Loading safetensors checkpoint shards:  75% Completed | 3/4 [00:01<00:00,  2.61it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.15it/s]\n",
            "Loading safetensors checkpoint shards: 100% Completed | 4/4 [00:01<00:00,  2.35it/s]\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-27 14:44:36 model_runner.py:1115] Loading model weights took 14.3854 GB\n",
            "INFO 02-27 14:44:36 punica_selector.py:18] Using PunicaWrapperGPU.\n",
            "INFO 02-27 14:44:38 worker.py:267] Memory profiling takes 1.32 seconds\n",
            "INFO 02-27 14:44:38 worker.py:267] the current vLLM instance can use total_gpu_memory (47.54GiB) x gpu_memory_utilization (0.79) = 37.78GiB\n",
            "INFO 02-27 14:44:38 worker.py:267] model weights take 14.39GiB; non_torch_memory takes 0.06GiB; PyTorch activation peak memory takes 1.58GiB; the rest of the memory reserved for KV Cache is 21.76GiB.\n",
            "INFO 02-27 14:44:38 executor_base.py:111] # cuda blocks: 25460, # CPU blocks: 7021\n",
            "INFO 02-27 14:44:38 executor_base.py:116] Maximum concurrency for 2048 tokens per request: 198.91x\n",
            "INFO 02-27 14:44:42 model_runner.py:1434] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Capturing CUDA graph shapes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 39/39 [00:21<00:00,  1.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 02-27 14:45:03 model_runner.py:1562] Graph capturing finished in 21 secs, took 2.12 GiB\n",
            "INFO 02-27 14:45:03 llm_engine.py:436] init engine (profile, create kv cache, warmup model) took 27.04 seconds\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Unsloth 2025.2.15 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import is_bfloat16_supported\n",
        "import torch\n",
        "import time\n",
        "\n",
        "max_seq_length = 2048 # Can increase for longer reasoning traces\n",
        "lora_rank = 128 # Larger rank = smarter, but slower\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"kings-crown/Isabelle_FVELer_SFT\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    load_in_4bit = False, # False for LoRA 16bit\n",
        "    fast_inference = True, # Enable vLLM fast inference\n",
        "    max_lora_rank = lora_rank,\n",
        "    gpu_memory_utilization = 0.8, # Reduce if out of memory\n",
        ")\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 64, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
        "    ], # Remove QKVO if out of memory\n",
        "    lora_alpha = lora_rank,\n",
        "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
        "    random_state = 3407,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Checker(object):\n",
        "    \"\"\"A modified version of the Draft, Sketch, Prove proof-checking client.\n",
        "    (https://github.com/albertqjiang/draft_sketch_prove/blob/main/autoformalization/checker.py)\n",
        "\n",
        "    This checker supports Isabelle2022 via the new version of PISA\n",
        "    (https://albertqjiang.github.io/Portal-to-ISAbelle/).\n",
        "\n",
        "    It supports checking a miniF2F-style proof via `check`.\n",
        "\n",
        "    Finally, it replaces `sledgehammer` with a call to `normalhammer`.\n",
        "    \"\"\"\n",
        "    def __init__(self, working_dir, isa_path, theory_file_path, port=9000):\n",
        "        sys.path.append(os.environ.get('PISA_PATH', ''))\n",
        "        try:\n",
        "            from pisa_client import initialise_env\n",
        "            self.initialise_env = initialise_env\n",
        "        except ImportError:\n",
        "            print(\"Set $PISA_PATH to /yourpath/to/Portal-to-ISAbelle/src/main/python\")\n",
        "\n",
        "        self.working_dir = working_dir\n",
        "        self.isa_path = isa_path\n",
        "        self.theory_file_path = theory_file_path\n",
        "        self.port = port\n",
        "\n",
        "    def _initialize(self):\n",
        "        \"\"\"Initialize the PISA environment.\"\"\"\n",
        "        env = self.initialise_env(\n",
        "            self.port,\n",
        "            isa_path=self.isa_path,\n",
        "            theory_file_path=self.theory_file_path,\n",
        "            working_directory=self.working_dir\n",
        "        )\n",
        "        return env\n",
        "\n",
        "    def _exit(self, env):\n",
        "        \"\"\"Exit the environment and clean up resources.\"\"\"\n",
        "        try:\n",
        "            env.post('exit')\n",
        "        except Exception:\n",
        "            pass\n",
        "        os.system(\"ps aux | grep Isabelle | awk '{print $2}' | xargs kill -9 > /dev/null 2>&1\")\n",
        "        os.system(\"ps aux | grep poly | awk '{print $2}' | xargs kill -9 > /dev/null 2>&1\")\n",
        "\n",
        "    def _parse_output(self, obs):\n",
        "        \"\"\"Parse the sledgehammer output, returning the relevant part.\"\"\"\n",
        "        return obs.split('<hammer>')[0] if '<hammer>' in obs else ''\n",
        "\n",
        "    def _run_step(self, step, i, tls_name, env):\n",
        "        \"\"\"Run a single proof step.\"\"\"\n",
        "        try:\n",
        "            obs, reward, done, metadata = env.step_to_top_level_state(\n",
        "                action=step,\n",
        "                tls_name=tls_name,\n",
        "                new_name=f'default_{i}'\n",
        "            )\n",
        "            return obs, reward, done, metadata, None\n",
        "        except Exception as e:\n",
        "            return '', 0, False, None, str(e)\n",
        "\n",
        "    def _run_sledgehammer(self, step, i, tls_name, env):\n",
        "        \"\"\"Run sledgehammer or fallback heuristics on a step.\"\"\"\n",
        "        heuristics = [\n",
        "            'by auto', 'by simp', 'by blast', 'by fastforce',\n",
        "            'by force', 'by eval', 'by presburger', 'by sos',\n",
        "            'by arith', 'by linarith', 'by (auto simp: field_simps)'\n",
        "        ]\n",
        "        for heuristic in heuristics:\n",
        "            step_ = step.replace('normalhammer', heuristic)\n",
        "            obs, reward, done, metadata, error = self._run_step(step_, i, tls_name, env)\n",
        "            if error is None:\n",
        "                obs = f'{heuristic} <hammer> {obs}'\n",
        "                return obs, reward, done, metadata, error\n",
        "        return self._run_step(step.replace(\"normalhammer\", \"sledgehammer\"), i, tls_name, env)\n",
        "\n",
        "    def check(self, statement_and_proof):\n",
        "        \"\"\"Check the given proof.\"\"\"\n",
        "        env = self._initialize()\n",
        "        env.initialise()\n",
        "\n",
        "        theory = self.wrap_theorem(statement_and_proof)\n",
        "        steps = self.get_parsed(env, theory)\n",
        "\n",
        "        result = self._check(env, steps)\n",
        "        self._exit(env)\n",
        "\n",
        "        # Output the result\n",
        "        #print(\"\\n==== Success: %s\" % result['success'])\n",
        "        #print(\"--- Complete proof:\\n%s\" % result['theorem_and_proof'])\n",
        "        return result\n",
        "\n",
        "    def _check(self, env, steps):\n",
        "        \"\"\"Run the proof steps and collect results.\"\"\"\n",
        "        success, reason, done = False, '', False\n",
        "        step_results = []\n",
        "        tls_name = 'default'\n",
        "\n",
        "        for i, step in enumerate(steps):\n",
        "            time0 = time.time()\n",
        "            if 'normalhammer' in step or 'sledgehammer' in step:\n",
        "                obs, reward, done, metadata, error = self._run_sledgehammer(step, i, tls_name, env)\n",
        "            else:\n",
        "                obs, reward, done, metadata, error = self._run_step(step, i, tls_name, env)\n",
        "\n",
        "            step_time = time.time() - time0\n",
        "            step_results.append({\n",
        "                'index': i, 'step': step, \n",
        "                'output': self._parse_output(obs), \n",
        "                'step_time': step_time\n",
        "            })\n",
        "\n",
        "            if error:\n",
        "                reason = error\n",
        "                break\n",
        "            tls_name = f'default_{i}'\n",
        "\n",
        "        success = done and reward == 1.0\n",
        "        return {\n",
        "            'success': success,\n",
        "            'reason': reason,\n",
        "            'num_steps': len(steps),\n",
        "            'last_step': len(step_results),\n",
        "            'step_results': step_results,\n",
        "            'theorem_and_proof': self.reconstruct(step_results) if success else ''\n",
        "        }\n",
        "\n",
        "    @staticmethod\n",
        "    def reconstruct(step_results):\n",
        "        \"\"\"Reconstruct the complete proof.\"\"\"\n",
        "        return '\\n'.join(\n",
        "            step_result['output'].strip() if step_result['output'] else step_result['step'].strip()\n",
        "            for step_result in step_results[1:]\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def wrap_theorem(theorem):\n",
        "        \"\"\"Wrap the theorem in a theory file.\"\"\"\n",
        "        return (\n",
        "            'theory Interactive imports HOL.HOL Complex_Main '\n",
        "            '\"HOL-Library.Code_Target_Numeral\" \"HOL-Library.Sum_of_Squares\" '\n",
        "            '\"Symmetric_Polynomials.Vieta\" \"HOL-Computational_Algebra.Computational_Algebra\" '\n",
        "            '\"HOL-Number_Theory.Number_Theory\" \\n begin\\n%s' % theorem\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def get_parsed(env, theory):\n",
        "        \"\"\"Parse the theory and extract proof steps.\"\"\"\n",
        "        raw_steps = env.post(f\"<parse text> ${theory}\")\n",
        "        steps = [s.strip() for s in raw_steps.split('<SEP>') if s.strip() and s != '$']\n",
        "        processed_steps = []\n",
        "        for i, step in enumerate(steps):\n",
        "            if step.lower() == \"then\" and (i == 0 or steps[i - 1].startswith(\"proof\")):\n",
        "                continue\n",
        "            processed_steps.append(step)\n",
        "        return processed_steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append('../')\n",
        "os.environ['PISA_PATH'] = '/home/siai/Portal-to-ISAbelle/src/main/python'\n",
        "\n",
        "#import dsp_utils\n",
        "\n",
        "checker = Checker(\n",
        "    working_dir='/home/siai/Isabelle2022/src/HOL/Examples',\n",
        "    isa_path='/home/siai/Isabelle2022',\n",
        "    theory_file_path='/home/siai/Isabelle2022/src/HOL/Examples/Interactive.thy',\n",
        "    port=9000\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KGgPgk_5S8r"
      },
      "source": [
        "### Data Prep\n",
        "<a name=\"Data\"></a>\n",
        "\n",
        "We directly leverage [@willccbb](https://gist.github.com/willccbb/4676755236bb08cab5f4e54a0475d6fb) for data prep and all reward functions. You are free to create your own!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cXk993X6C2ZZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1138/1138 [00:00<00:00, 14085.10 examples/s]\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import sys\n",
        "import os\n",
        "from datasets import load_dataset, Dataset\n",
        "\n",
        "# Load and prep dataset\n",
        "SYSTEM_PROMPT = \"\"\"Write a proof in Isabelle that appropriately proves the given statement in natural language.\n",
        "Make sure to wrap the proof within ``isabelle and ``` tags inside answer.\n",
        "Respond in the following format:\n",
        "<reasoning>\n",
        "[Your explanation or chain of thought]\n",
        "</reasoning>\n",
        "<answer>\n",
        "``` \n",
        "isabelle \n",
        "[Your formal Isabelle code]\n",
        "``` \n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "XML_COT_FORMAT = \"\"\"\\\n",
        "<reasoning>\n",
        "{reasoning}\n",
        "</reasoning>\n",
        "<answer>\n",
        "{answer}\n",
        "</answer>\n",
        "\"\"\"\n",
        "\n",
        "def extract_xml_answer(text: str) -> str:\n",
        "    answer = text.split(\"<answer>\")[-1]\n",
        "    answer = answer.split(\"</answer>\")[0]\n",
        "    return answer.strip()\n",
        "\n",
        "\n",
        "def extract_isabelle_snippet(text: str) -> str | None:\n",
        "    \"\"\"\n",
        "    Extracts Isabelle proof content from text. Handles both Markdown code blocks \n",
        "    and inline structured proofs by detecting `lemma`, `proof`, and `qed`.\n",
        "    \"\"\"\n",
        "    if not isinstance(text,str) or text.strip() == \"\":\n",
        "        return None\n",
        "    \n",
        "    if \":\" in text and \"```isabelle\" in text:\n",
        "        text = text.split(\"```isabelle\",1)[1]\n",
        "        text = \"```isabelle\" + text\n",
        "        \n",
        "    code_pattern = r\"```isabelle\\s*(.+?)\\s*```\"\n",
        "    matches = re.findall(code_pattern, text, flags=re.DOTALL | re.IGNORECASE)\n",
        "    \n",
        "    if matches:\n",
        "        return matches[0].strip() \n",
        "    inline_pattern = r\"(lemma.*?proof.*?qed)\"\n",
        "    matches = re.findall(inline_pattern, text, flags=re.DOTALL | re.IGNORECASE)\n",
        "\n",
        "    if matches:\n",
        "        return matches[0].strip() \n",
        "    return None\n",
        "\n",
        "\n",
        "# uncomment middle messages for 1-shot prompting\n",
        "def get_gsm8k_questions(split = \"train\") -> Dataset:\n",
        "    data = load_dataset('kings-crown/FVELer_PISA_Proven', 'default')[split] # type: ignore\n",
        "    data = data.map(lambda x: { # type: ignore\n",
        "        'prompt': [\n",
        "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
        "            {'role': 'user', 'content': x['natural_language_statement']}\n",
        "        ],\n",
        "        'answer': extract_isabelle_snippet(x['formal_proof'])\n",
        "    }) # type: ignore\n",
        "    return data # type: ignore\n",
        "\n",
        "dataset = get_gsm8k_questions()\n",
        "\n",
        "# Reward functions\n",
        "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    q = prompts[0][-1]['content']\n",
        "    extracted_responses = [extract_isabelle_snippet(r) for r in responses]\n",
        "    #print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_responses[0]}\")\n",
        "    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]\n",
        "\n",
        "def checker_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    q = prompts[0][-1]['content']\n",
        "    extracted_snippets = [extract_isabelle_snippet(r) for r in responses]\n",
        "\n",
        "    print('-'*20, f\"Question:\\n{q}\", f\"\\nAnswer:\\n{answer[0]}\", f\"\\nResponse:\\n{responses[0]}\", f\"\\nExtracted:\\n{extracted_snippets[0]}\")\n",
        "\n",
        "    for content in extracted_snippets:\n",
        "        checker = Checker(\n",
        "            working_dir='/home/siai/Isabelle2022/src/HOL/Examples',\n",
        "            isa_path='/home/siai/Isabelle2022',\n",
        "            theory_file_path='/home/siai/Isabelle2022/src/HOL/Examples/Interactive.thy',\n",
        "            port=9000\n",
        "        )\n",
        "        #result = checker.check(content)\n",
        "        rewards = [2.0 if checker.check(content).get(\"success\", False) else 0.0 for content in extracted_snippets]\n",
        "    return rewards\n",
        "\n",
        "def int_reward_func(completions, **kwargs) -> list[float]:\n",
        "    responses = [completion[0]['content'] for completion in completions]\n",
        "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
        "    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]\n",
        "\n",
        "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"^<reasoning>\\n.*?\\n</reasoning>\\n<answer>\\n.*?\\n</answer>\\n$\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [re.match(pattern, r) for r in responses]\n",
        "    return [0.5 if match else 0.0 for match in matches]\n",
        "\n",
        "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"<reasoning>.*?</reasoning>\\s*<answer>.*?</answer>\"\n",
        "    responses = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [re.match(pattern, r) for r in responses]\n",
        "    return [0.5 if match else 0.0 for match in matches]\n",
        "\n",
        "def count_xml(text) -> float:\n",
        "    count = 0.0\n",
        "    if text.count(\"<reasoning>\\n\") == 1:\n",
        "        count += 0.125\n",
        "    if text.count(\"\\n</reasoning>\\n\") == 1:\n",
        "        count += 0.125\n",
        "    if text.count(\"\\n<answer>\\n\") == 1:\n",
        "        count += 0.125\n",
        "        count -= len(text.split(\"\\n</answer>\\n\")[-1])*0.001\n",
        "    if text.count(\"\\n</answer>\") == 1:\n",
        "        count += 0.125\n",
        "        count -= (len(text.split(\"\\n</answer>\")[-1]) - 1)*0.001\n",
        "    return count\n",
        "\n",
        "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
        "    contents = [completion[0][\"content\"] for completion in completions]\n",
        "    return [count_xml(c) for c in contents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'natural_language_statement': 'The lemma states that if set \\\\( S \\\\) is a subset of set \\\\( T \\\\), and there exists an element \\\\( x \\\\) such that \\\\( S \\\\) is the singleton set containing \\\\( x \\\\), and there exists an element \\\\( y \\\\) such that \\\\( T \\\\) is the singleton set containing \\\\( y \\\\), then \\\\( S \\\\) is equal to \\\\( T \\\\).',\n",
              " 'formal_proof': 'To translate the informal proof into a structured Isabelle proof, we will follow the steps outlined in the informal reasoning and use `sledgehammer` to assist in finding any necessary lemmas or theorems. Here\\'s how the structured proof in Isabelle might look:\\n\\n```isabelle\\nlemma eq:\\n  assumes \"S \\\\<subseteq> T\"\\n    and \"\\\\<exists>x. S = {x}\"\\n    and \"\\\\<exists>y. T = {y}\"\\n  shows \"S = T\"\\nproof -\\n  from `\\\\<exists>x. S = {x}` obtain x where \"S = {x}\" by auto\\n  from `\\\\<exists>y. T = {y}` obtain y where \"T = {y}\" by auto\\n  have \"x \\\\<in> T\" using `S \\\\<subseteq> T` `S = {x}` by auto\\n  then have \"x = y\" using `T = {y}` by auto\\n  then have \"S = T\" using `S = {x}` `T = {y}` by simp\\n  thus ?thesis by simp\\nqed\\n```\\n\\n### Explanation:\\n\\n1. **Assumptions**: We start by assuming the conditions given in the lemma: `S \\\\<subseteq> T`, `\\\\<exists>x. S = {x}`, and `\\\\<exists>y. T = {y}`.\\n\\n2. **Existential Elimination**: We use `obtain` to extract the elements `x` and `y` such that `S = {x}` and `T = {y}`.\\n\\n3. **Subset Condition**: From the subset condition `S \\\\<subseteq> T` and the fact that `S = {x}`, we deduce that `x` must be an element of `T`.\\n\\n4. **Singleton Property**: Since `T = {y}`, the only element in `T` is `y`, so `x = y`.\\n\\n5. **Set Equality**: With `x = y`, we conclude that `S = {x} = {y} = T`.\\n\\n6. **Conclusion**: The proof concludes with `S = T`, as required by the lemma.\\n\\nThis structured proof closely follows the informal reasoning and uses basic set properties and logical deductions to reach the conclusion.',\n",
              " 'prompt': [{'content': 'Write a proof in Isabelle that appropriately proves the given statement in natural language.\\nMake sure to wrap the proof within ``isabelle and ``` tags inside answer.\\nRespond in the following format:\\n<reasoning>\\n[Your explanation or chain of thought]\\n</reasoning>\\n<answer>\\n``` \\nisabelle \\n[Your formal Isabelle code]\\n``` \\n</answer>\\n',\n",
              "   'role': 'system'},\n",
              "  {'content': 'The lemma states that if set \\\\( S \\\\) is a subset of set \\\\( T \\\\), and there exists an element \\\\( x \\\\) such that \\\\( S \\\\) is the singleton set containing \\\\( x \\\\), and there exists an element \\\\( y \\\\) such that \\\\( T \\\\) is the singleton set containing \\\\( y \\\\), then \\\\( S \\\\) is equal to \\\\( T \\\\).',\n",
              "   'role': 'user'}],\n",
              " 'answer': 'lemma eq:\\n  assumes \"S \\\\<subseteq> T\"\\n    and \"\\\\<exists>x. S = {x}\"\\n    and \"\\\\<exists>y. T = {y}\"\\n  shows \"S = T\"\\nproof -\\n  from `\\\\<exists>x. S = {x}` obtain x where \"S = {x}\" by auto\\n  from `\\\\<exists>y. T = {y}` obtain y where \"T = {y}\" by auto\\n  have \"x \\\\<in> T\" using `S \\\\<subseteq> T` `S = {x}` by auto\\n  then have \"x = y\" using `T = {y}` by auto\\n  then have \"S = T\" using `S = {x}` `T = {y}` by simp\\n  thus ?thesis by simp\\nqed'}"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux6iqP7z5YOo"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "\n",
        "Now set up GRPO Trainer and all configurations!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptqkXK2D4d6p",
        "outputId": "9d5551f4-0276-47ca-e4ca-e96c846cc976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unsloth: We now expect `per_device_train_batch_size` to be a multiple of `num_generations`.\n",
            "We will change the batch size of 2 to the `num_generations` of 6\n"
          ]
        }
      ],
      "source": [
        "from trl import GRPOConfig, GRPOTrainer\n",
        "training_args = GRPOConfig(\n",
        "    use_vllm = True, # use vLLM for fast inference!\n",
        "    learning_rate = 5e-6,\n",
        "    adam_beta1 = 0.9,\n",
        "    adam_beta2 = 0.99,\n",
        "    weight_decay = 0.1,\n",
        "    warmup_ratio = 0.1,\n",
        "    lr_scheduler_type = \"cosine\",\n",
        "    optim = \"paged_adamw_8bit\",\n",
        "    logging_steps = 1,\n",
        "    bf16 = is_bfloat16_supported(),\n",
        "    fp16 = not is_bfloat16_supported(),\n",
        "    per_device_train_batch_size = 2,\n",
        "    gradient_accumulation_steps = 4, # Increase to 4 for smoother training\n",
        "    num_generations = 6, # Decrease if out of memory\n",
        "    max_prompt_length = 256,\n",
        "    max_completion_length = 3000,\n",
        "    num_train_epochs = 3, # Set to 1 for a full training run\n",
        "    max_steps = 500,\n",
        "    save_steps = 50,\n",
        "    max_grad_norm = 0.1,\n",
        "    report_to = \"wandb\", # Can use Weights & Biases\n",
        "    output_dir = \"output_RL\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9Mv8UZO5hz-"
      },
      "source": [
        "And let's run the trainer! If you scroll up, you'll see a table of rewards. The goal is to see the `reward` column increase!\n",
        "\n",
        "You might have to wait 150 to 200 steps for any action. You'll probably get 0 reward for the first 100 steps. Please be patient!\n",
        "\n",
        "| Step | Training Loss | reward    | reward_std | completion_length | kl       |\n",
        "|------|---------------|-----------|------------|-------------------|----------|\n",
        "| 1    | 0.000000      | 0.125000  | 0.000000   | 200.000000        | 0.000000 |\n",
        "| 2    | 0.000000      | 0.072375  | 0.248112   | 200.000000        | 0.000000 |\n",
        "| 3    | 0.000000      | -0.079000 | 0.163776   | 182.500000        | 0.000005 |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vzOuSVCL_GA9",
        "outputId": "a71824d4-afd8-47ac-f0ea-eae276927e19"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 1,138 | Num Epochs = 2\n",
            "O^O/ \\_/ \\    Batch size per device = 6 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 24 | Total steps = 500\n",
            " \"-____-\"     Number of trainable parameters = 161,480,704\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbalaji-vir1997\u001b[0m (\u001b[33mbalaji-vir1997-stevens-institute-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/siai/Documents/GitHub/NeSy_Policy_Reasoning/wandb/run-20250227_144619-fza0e0f3</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/balaji-vir1997-stevens-institute-of-technology/huggingface/runs/fza0e0f3' target=\"_blank\">output_RL</a></strong> to <a href='https://wandb.ai/balaji-vir1997-stevens-institute-of-technology/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/balaji-vir1997-stevens-institute-of-technology/huggingface' target=\"_blank\">https://wandb.ai/balaji-vir1997-stevens-institute-of-technology/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/balaji-vir1997-stevens-institute-of-technology/huggingface/runs/fza0e0f3' target=\"_blank\">https://wandb.ai/balaji-vir1997-stevens-institute-of-technology/huggingface/runs/fza0e0f3</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------- Question:\n",
            "The lemma states that for any natural numbers \\( a \\) and \\( b \\), the product of the integer division of \\( a \\) by \\( b \\) and \\( b \\) is less than or equal to \\( a \\). \n",
            "Answer:\n",
            "lemma div_mult_le:\n",
            "  \"a div b * b \\<le> a\" for a b :: nat\n",
            "proof -\n",
            "  have \"a = (a div b) * b + (a mod b)\"\n",
            "    by (simp add: div_mult_mod_eq)\n",
            "  then have \"(a div b) * b \\<le> a\"\n",
            "    by simp\n",
            "  thus ?thesis .\n",
            "qed \n",
            "Response:\n",
            "Okay, so I need to prove that for any natural numbers \\( a \\) and \\( b \\), the product of the integer division of \\( a \\) by \\( b \\) and \\( b \\) is less than or equal to \\( a \\). Hmm, let me break this down step by step.\n",
            "\n",
            "First, what does integer division mean? I think it's when you divide two numbers and take the floor of the result. So, \\( a \\div b \\) would give a quotient which is the largest integer less than or equal to the actual division result of \\( a \\) by \\( b \\). For example, if \\( a = 10 \\) and \\( b = 3 \\), then \\( 10 \\div 3 = 3 \\) because 3 times 3 is 9, which is less than 10, and the next multiple would be 12, which is more than 10.\n",
            "\n",
            "So, the statement is saying that when you take \\( a \\div b \\) and multiply it by \\( b \\), the result should be less than or equal to \\( a \\). Using my previous example, \\( 3 \\times 3 = 9 \\) which is indeed less than or equal to 10.\n",
            "\n",
            "I guess this makes sense because when you divide \\( a \\) by \\( b \\), you're essentially seeing how many times \\( b \\) fits completely into \\( a \\). Then, when you multiply that quotient back by \\( b \\), you're getting the largest multiple of \\( b \\) that doesn't exceed \\( a \\). So, naturally, this product should be less than or equal to \\( a \\).\n",
            "\n",
            "But wait, what if \\( b \\) is 0? Division by zero is undefined, so \\( b \\) must be a positive natural number, right? Or maybe \\( b \\) can't be zero because division by zero isn't allowed. So, in the context of natural numbers, \\( b \\) should be at least 1.\n",
            "\n",
            "Let me think about another example to test this. If \\( a = 7 \\) and \\( b = 2 \\), then \\( 7 \\div 2 = 3 \\), and \\( 3 \\times 2 = 6 \\), which is less than 7. Another example: if \\( a = 5 \\) and \\( b = 5 \\), then \\( 5 \\div 5 = 1 \\), and \\( 1 \\times 5 = 5 \\), which is equal to \\( a \\). So, it still holds.\n",
            "\n",
            "Now, how do I formally prove this? Maybe I can use the definition of integer division. So, \\( a \\div b \\) is the largest integer \\( q \\) such that \\( q \\times b \\leq a \\). So, by definition, \\( q = a \\div b \\) implies that \\( q \\times b \\leq a < (q + 1) \\times b \\). Therefore, \\( a \\div b \\times b \\leq a \\) directly follows from the definition.\n",
            "\n",
            "Wait, is that enough? Maybe I should elaborate more. Perhaps I can use the properties of natural numbers and division. Also, maybe consider different cases, like whether \\( a \\) is a multiple of \\( b \\) or not. If \\( a \\) is a multiple of \\( b \\), then \\( a \\div b \\times b = a \\), so equality holds. If not, \\( a \\div b \\times b \\) is strictly less than \\( a \\).\n",
            "\n",
            "Maybe I should also think about how this relates to the remainder. If \\( a = q \\times b + r \\), where \\( 0 \\leq r < b \\), then \\( a \\div b = q \\), so \\( q \\times b = a - r \\), which is less than or equal to \\( a \\) since \\( r \\geq 0 \\).\n",
            "\n",
            "I think that covers it. Using the definition of division with quotient and remainder, we can show that \\( q \\times b \\) is indeed less than or equal to \\( a \\).\n",
            "\n",
            "So, putting it all together, the proof would start by defining what integer division is, then using that definition or the properties of division to show the desired inequality holds.\n",
            "</think>\n",
            "\n",
            "<reasoning>\n",
            "To prove that for any natural numbers \\( a \\) and \\( b \\) (with \\( b > 0 \\)), \\( a \\div b \\times b \\leq a \\):\n",
            "\n",
            "1. **Understand Integer Division**: \\( a \\div b \\) gives the quotient \\( q \\), which is the largest integer such that \\( q \\times b \\leq a \\).\n",
            "\n",
            "2. **Express \\( a \\) in Terms of \\( q \\) and \\( b \\)**: \\( a = q \\times b + r \\), where \\( 0 \\leq r < b \\) is the remainder.\n",
            "\n",
            "3. **Multiply Quotient by \\( b \\)**: \\( q \\times b = a - r \\).\n",
            "\n",
            "4. **Establish the Inequality**: Since \\( r \\geq 0 \\), \\( a - r \\leq a \\).\n",
            "\n",
            "5. **Conclude**: \\( q \\times b \\leq a \\).\n",
            "</reasoning>\n",
            "\n",
            "<answer>\n",
            "``` \n",
            "isabelle \n",
            "lemma \"‚àÄ a b::nat. b > 0 ‚ü∂ (a div b) * b ‚â§ a\" \n",
            "by (induction b) \n",
            " (auto intro: le_add_comm le_of_lt)\n",
            "``` \n",
            "</answer>\n",
            "``` \n",
            "Extracted:\n",
            "None\n",
            "-------------------- Question:\n",
            "The lemma `if_evrv` can be translated into the following natural language statement:\n",
            "\n",
            "Suppose we have two conditions:\n",
            "1. If the boolean condition `b` is true, then the function `f` satisfies the property `equiv_valid_rv_inv` with respect to the invariant `I`, the set of actions `A`, the relation `R`, and the precondition `P`.\n",
            "2. If the boolean condition `b` is false, then the function `g` satisfies the property `equiv_valid_rv_inv` with respect to the invariant `I`, the set of actions `A`, the relation `R`, and the precondition `Q`.\n",
            "\n",
            "Under these assumptions, the function that chooses `f` if `b` is true and `g` if `b` is false satisfies the property `equiv_valid_rv_inv` with respect to the invariant `I`, the set of actions `A`, the relation `R`, and the combined precondition that requires `P` to hold when `b` is true and `Q` to hold when `b` is false. \n",
            "Answer:\n",
            "lemma if_evrv:\n",
            "  assumes \"b \\<Longrightarrow> equiv_valid_rv_inv I A R P f\"\n",
            "  assumes \"\\<not> b \\<Longrightarrow> equiv_valid_rv_inv I A R Q g\"\n",
            "  shows \"equiv_valid_rv_inv I A R (\\<lambda>s. (b \\<longrightarrow> P s) \\<and> (\\<not>b \\<longrightarrow> Q s)) (if b then f else g)\"\n",
            "proof (cases b)\n",
            "  case True\n",
            "  then have \"equiv_valid_rv_inv I A R P f\" using assms(1) by simp\n",
            "  moreover have \"(\\<lambda>s. (True \\<longrightarrow> P s) \\<and> (False \\<longrightarrow> Q s)) = P\" by auto\n",
            "  ultimately show ?thesis by simp\n",
            "next\n",
            "  case False\n",
            "  then have \"equiv_valid_rv_inv I A R Q g\" using assms(2) by simp\n",
            "  moreover have \"(\\<lambda>s. (False \\<longrightarrow> P s) \\<and> (True \\<longrightarrow> Q s)) = Q\" by auto\n",
            "  ultimately show ?thesis by simp\n",
            "qed \n",
            "Response:\n",
            "Okay, so I have this lemma called `if_evrv` that I need to prove using Isabelle. I'm a bit new to this, but I'll try to figure it out step by step.\n",
            "\n",
            "First, I need to understand what the lemma is about. From the code snippet I see that it involves boolean conditions and functions that satisfy certain properties. It looks like the lemma is about choosing between two functions, f and g, based on the value of a boolean condition b. If b is true, it uses f; if b is false, it uses g. I need to show that the resulting function still satisfies some kind of equivalence or validity property.\n",
            "\n",
            "In the code, there are two assumptions: `h1` and `h2`. h1 says that if b is true, then f satisfies `equiv_valid_rv_inv` with some arguments. Similarly, h2 says that if b is false, then g satisfies the same property. I need to combine these to show that the function that selects f or g based on b also satisfies `equiv_valid_rv_inv`.\n",
            "\n",
            "I think the key here is to use the logical structure of the boolean condition b. Since b can only be true or false, the function's behavior is determined by which function we pick in each case. So, if I can show that in both scenarios (b true and b false), the resulting function behaves correctly, then overall it should hold.\n",
            "\n",
            "Maybe I can use case analysis on b. If b is true, then the function is f, and I apply h1 directly. If b is false, the function is g, and I apply h2. Since in both cases, the properties hold, combining them should give the desired result.\n",
            "\n",
            "I also notice that `equiv_valid_rv_inv` is being applied with the same setup except for the precondition. So, when b is true, the precondition is P, and when it's false, it's Q. The combined precondition makes sure both are satisfied.\n",
            "\n",
            "I need to make sure that I correctly combine these properties. Maybe using logical disjunction because the conditions are based on b. If b is true, P holds, and if b is false, Q holds. So, the combined precondition is (P ‚àß b) ‚à® (Q ‚àß ¬¨b).\n",
            "\n",
            "Putting it all together, I think the proof structure should involve assuming b and proving the property using h1 or h2 depending on the case. Then, since in both cases the property holds, the theorem is proven.\n",
            "\n",
            "I should also check if there are any implicit assumptions or if I need to handle any other aspects in Isabelle, like closing assumptions or using specific tactics. Maybe I need to use `cases` to handle the boolean b and then apply the respective assumptions.\n",
            "\n",
            "Overall, the approach seems to be to use case analysis on b, apply the corresponding function that satisfies the property in each case, and then combine the results. I need to structure this carefully in Isabelle to make sure the proof is correct and covers all scenarios.\n",
            "</think>\n",
            "\n",
            "<reasoning>\n",
            "To prove the `if_evrv` lemma, we perform a case analysis on the boolean condition `b`. If `b` is `true`, the function `f` must satisfy the `equiv_valid_rv_inv` property. If `b` is `false`, the function `g` must satisfy the property. By ensuring that the combined function (which selects `f` or `g` based on `b`) satisfies `equiv_valid_rv_inv` under both cases, we establish the lemma's validity.\n",
            "</reasoning>\n",
            "\n",
            "```isabelle\n",
            "lemma \"if_evrv P b f Q g <-> (b --> P) & (~b --> Q)\" \n",
            "  (is \"_ <-> ?R\")\n",
            "  apply Iff.intro \n",
            "  apply simp_all\n",
            "  apply rule\n",
            "  apply intro\n",
            "  apply IffD1\n",
            "  apply conjI\n",
            "-- Case analysis on the boolean condition b\n",
            "  apply (case b in <;> simp_all)\n",
            "  ¬∑ apply IffD1\n",
            "    apply conjI\n",
            "    ¬∑ apply IffD1\n",
            "      apply (drule h1, simp_all)\n",
            "    ¬∑ apply IffD1\n",
            "      apply (drule h2, simp_all)\n",
            "  apply IffD2\n",
            "  apply conjI\n",
            "  ¬∑ apply IffD1\n",
            "    apply (drule h1, simp_all)\n",
            "  ¬∑ apply IffD1\n",
            "    apply (drule h2, simp_all)\n",
            "``` \n",
            "Extracted:\n",
            "lemma \"if_evrv P b f Q g <-> (b --> P) & (~b --> Q)\" \n",
            "  (is \"_ <-> ?R\")\n",
            "  apply Iff.intro \n",
            "  apply simp_all\n",
            "  apply rule\n",
            "  apply intro\n",
            "  apply IffD1\n",
            "  apply conjI\n",
            "-- Case analysis on the boolean condition b\n",
            "  apply (case b in <;> simp_all)\n",
            "  ¬∑ apply IffD1\n",
            "    apply conjI\n",
            "    ¬∑ apply IffD1\n",
            "      apply (drule h1, simp_all)\n",
            "    ¬∑ apply IffD1\n",
            "      apply (drule h2, simp_all)\n",
            "  apply IffD2\n",
            "  apply conjI\n",
            "  ¬∑ apply IffD1\n",
            "    apply (drule h1, simp_all)\n",
            "  ¬∑ apply IffD1\n",
            "    apply (drule h2, simp_all)\n",
            "-------------------- Question:\n",
            "The lemma `if_Not_x` states that the expression \"if \\( p \\) then not \\( x \\) else \\( x \\)\" is equivalent to the statement \"the truth value of \\( p \\) is equal to the negation of \\( x \\).\" In other words, the conditional expression evaluates to the negation of \\( x \\) when \\( p \\) is true, and to \\( x \\) itself when \\( p \\) is false, which is the same as saying that \\( p \\) is true if and only if \\( x \\) is false. \n",
            "Answer:\n",
            "lemma if_Not_x: \"(if p then \\<not> x else x) = (p = (\\<not> x))\"\n",
            "proof -\n",
            "  {\n",
            "    assume \"p\"\n",
            "    then have \"(if p then \\<not> x else x) = \\<not> x\" by simp\n",
            "    also from `p` have \"p = (\\<not> x) \\<longleftrightarrow> \\<not> x\" by auto\n",
            "    finally have \"(if p then \\<not> x else x) = (p = (\\<not> x))\" by simp\n",
            "  }\n",
            "  moreover\n",
            "  {\n",
            "    assume \"\\<not> p\"\n",
            "    then have \"(if p then \\<not> x else x) = x\" by simp\n",
            "    also from `\\<not> p` have \"p = (\\<not> x) \\<longleftrightarrow> x\" by auto\n",
            "    finally have \"(if p then \\<not> x else x) = (p = (\\<not> x))\" by simp\n",
            "  }\n",
            "  ultimately show ?thesis by auto\n",
            "qed \n",
            "Response:\n",
            "Okay, so I have to write a proof in Isabelle that the expression \"if p then not x else x\" is equivalent to the statement that the truth value of p is equal to the negation of x. Hmm, let me try to understand this first. \n",
            "\n",
            "So, the expression \"if p then not x else x\" is a conditional expression in Isabelle, right? I remember that in Isabelle, this is similar to a ternary conditional operator in other programming languages. So, when p is true, it evaluates to not x, and when p is false, it just evaluates to x. \n",
            "\n",
            "Now, the statement we're supposed to prove is that this conditional expression is equivalent to the statement \"the truth value of p is equal to the negation of x,\" which I think is written as p = (¬¨x). But wait, in Isabelle, truth values are typically in the context of propositions, so maybe this means that p is equivalent to (¬¨x). Or perhaps it's saying that p is equivalent to the boolean equality between x and not x. I'm a bit confused about how exactly the equivalence is being set up here.\n",
            "\n",
            "Let me think about how to approach this. Maybe I should break down the conditional expression into its two cases: when p is true and when p is false. If p is true, the expression simplifies to not x. If p is false, it simplifies to x. So, in the first case, when p is true, the expression is not x, which would mean that p implies not x. In the second case, when p is false, the expression is x, which would mean that not p implies x. \n",
            "\n",
            "Putting these together, p implies not x and not p implies x. Wait, that sounds like a biconditional. Because if p implies not x and not p implies x, then p is equivalent to not x. Because p implies not x and not x implies p, right? So, I think that's the connection. \n",
            "\n",
            "But I'm getting a bit tangled up here. Maybe I should try to write out the truth table to verify this. Let's see, for all possible truth values of p and x, I can evaluate the conditional expression and see if it matches the statement p = (¬¨x). \n",
            "\n",
            "Let's say p is true and x is true. Then, not x is false. So, the conditional evaluates to false. Now, p = (¬¨x) would be true if p is equal to not x. But p is true and not x is false, so p = (¬¨x) is false. So, both the conditional expression and p = (¬¨x) are false in this case.\n",
            "\n",
            "If p is true and x is false, then not x is true. The conditional expression evaluates to true. And p = (¬¨x) is true because p is true and not x is also true. So, both are true here.\n",
            "\n",
            "If p is false and x is true, then the conditional expression evaluates to x, which is true. Now, p = (¬¨x) would be false because p is false and not x is false. Wait, that can't be right because if p is false and x is true, then p = (¬¨x) is false, but the conditional expression is true. So, they are not equivalent. Hmm, that's a problem. Did I make a mistake in my initial understanding?\n",
            "\n",
            "Alternatively, maybe I'm misinterpreting the statement. Perhaps the statement is that the conditional expression is equivalent to (p ‚â° ¬¨x). Or maybe it's that the conditional expression is equivalent to p ‚áî ¬¨x. Let me check the original statement again.\n",
            "\n",
            "It says, \"the expression \"if p then not x else x\" is equivalent to the statement \"the truth value of p is equal to the negation of x.\" So, perhaps it's not an equivalence but a biconditional. But in my truth table, I saw that when p is true and x is true, both the conditional and p = ¬¨x are false. When p is true and x is false, both are true. When p is false and x is false, the conditional is x (which is false), and p = ¬¨x is true because p is false and not x is false, wait no, p is false and not x is true because x is false, so p = ¬¨x is false. Wait, that doesn't make sense. Let me recast the truth table.\n",
            "\n",
            "Wait, p and x are both booleans, so their truth values are true or false. The expression p = ¬¨x would be true when p and ¬¨x are equal, meaning when p is true and x is false, or when p is false and x is true. Now, the conditional expression \"if p then not x else x\" is equivalent to (p ‚àß ¬¨x) ‚à® (¬¨p ‚àß x). Let's compare this to (p ‚â° ¬¨x), which is (p ‚àß ¬¨x) ‚à® (¬¨p ‚àß x). They look identical. So, yes, the conditional expression is equivalent to (p ‚â° ¬¨x). So, perhaps I made a mistake in the earlier truth table. Let me recast it correctly.\n",
            "\n",
            "So, the conditional expression is equivalent to (p ‚àß ¬¨x) ‚à® (¬¨p ‚àß x), which is the same as p ‚â° ¬¨x. Therefore, the two are indeed equivalent. So, my initial confusion was because of a misinterpretation of the truth table. Once I correctly express the conditional in terms of logical connectives, it matches the biconditional p ‚â° ¬¨x.\n",
            "\n",
            "Okay, so the proof would involve showing that the conditional expression can be expanded into (p ‚àß ¬¨x) ‚à® (¬¨p ‚àß x), and that this is logically equivalent to p ‚â° ¬¨x. Then, I can use Isabelle's built-in logical rules to formalize this proof. I just need to make sure that the expansion of the conditional matches exactly with the biconditional expression. Once that's established, the equivalence follows from the logical equivalence of these two expressions.\n",
            "\n",
            "I think that's the way to go. I'll proceed to write the formal proof in Isabelle, making sure to show each step clearly and use the appropriate logical rules to establish the equivalence.\n",
            "</think>\n",
            "\n",
            "<answer>\n",
            "``` \n",
            "isabelle \n",
            "lemma if_Not_x: \"(if p then not x else x) ‚ü∑ (p ‚ü∫ ¬¨x)\" \n",
            "  by (simp only [if_same, not_iff_not_eq, xor_iff_iff_not_imp])\n",
            "  <reasoning>\n",
            "Alright, so I need to prove that the conditional expression \"if \\( p \\) then not \\( x \\) else \\( x \\)\" is equivalent to the statement \"the truth value of \\( p \\) is equal to the negation of \\( x \\)\", which is written as \\( p \\iff \\neg x \\).\n",
            "\n",
            "First, let's understand the conditional expression. In Isabelle, \"if \\( p \\) then not \\( x \\) else \\( x \\)\" can be expanded into logical connectives. This expression evaluates to not \\( x \\) when \\( p \\) is true and to \\( x \\) when \\( p \\) is false.\n",
            "\n",
            "Now, let's consider the statement \\( p \\iff \\neg x \\). This means that \\( p \\) is logically equivalent to the negation of \\( x \\), i.e., \\( p \\) and \\( \\neg x \\) are both true or both false.\n",
            "\n",
            "To establish equivalence between the conditional expression and the biconditional statement, let's expand the conditional expression:\n",
            "1. When \\( p \\) is true, the expression evaluates to \\( \\neg x \\).\n",
            "2. When \\( p \\) is false, the expression evaluates to \\( x \\).\n",
            "\n",
            "Now, the biconditional \\( p \\iff \\neg x \\) holds true in the following cases:\n",
            "1. \\( p \\) is true and \\( \\neg x \\) is true (i.e., \\( x \\) is false).\n",
            "2. \\( p \\) is false and \\( \\neg x \\) is false (i.e., \\( x \\) is true).\n",
            "\n",
            "Comparing the two scenarios:\n",
            "1. In the conditional expression, when \\( p \\) is true and \\( x \\) is false, the expression evaluates to true, matching the biconditional.\n",
            "2. When \\( p \\) is false and \\( x \\) is true, the conditional expression evaluates to true, again matching the biconditional.\n",
            "\n",
            "Thus, the conditional expression and the biconditional statement cover the same truth conditions, proving their equivalence.\n",
            "\n",
            "The proof can be formalized in Isabelle using the simplification rules for conditional expressions and biconditionals.\n",
            "</reasoning>\n",
            "``` \n",
            "``` \n",
            "Extracted:\n",
            "None\n",
            "-------------------- Question:\n",
            "The lemma `set_compre_unwrap` states that the set of all elements `x` satisfying the property `P x` is a subset of the set `S` if and only if, for every element `x`, if `P x` holds, then `x` is an element of `S`. \n",
            "Answer:\n",
            "lemma set_compre_unwrap: \"({x. P x} \\<subseteq> S) = (\\<forall>x. P x \\<longrightarrow> x \\<in> S)\"\n",
            "proof\n",
            "  -- \"Forward direction: Assume {x. P x} \\<subseteq> S and show \\<forall>x. P x \\<longrightarrow> x \\<in> S\"\n",
            "  assume \"({x. P x} \\<subseteq> S)\"\n",
            "  then show \"\\<forall>x. P x \\<longrightarrow> x \\<in> S\"\n",
            "  proof\n",
            "    fix x\n",
            "    assume \"P x\"\n",
            "    -- \"Since {x. P x} \\<subseteq> S, x \\<in> {x. P x} implies x \\<in> S\"\n",
            "    with `({x. P x} \\<subseteq> S)` have \"x \\<in> S\"\n",
            "      by auto\n",
            "    thus \"P x \\<longrightarrow> x \\<in> S\"\n",
            "      using `P x` by simp\n",
            "  qed\n",
            "\n",
            "  -- \"Backward direction: Assume \\<forall>x. P x \\<longrightarrow> x \\<in> S and show {x. P x} \\<subseteq> S\"\n",
            "  assume \"\\<forall>x. P x \\<longrightarrow> x \\<in> S\"\n",
            "  then show \"{x. P x} \\<subseteq> S\"\n",
            "  proof\n",
            "    fix x\n",
            "    assume \"x \\<in> {x. P x}\"\n",
            "    then have \"P x\"\n",
            "      by simp\n",
            "    with `\\<forall>x. P x \\<longrightarrow> x \\<in> S` have \"x \\<in> S\"\n",
            "      by auto\n",
            "    thus \"x \\<in> S\"\n",
            "      by simp\n",
            "  qed\n",
            "qed \n",
            "Response:\n",
            "Okay, so I'm trying to prove this lemma called `set_compre_unwrap`. From what I understand, the lemma is saying that the set of all elements `x` that satisfy the property `P x` is a subset of another set `S` if and only if, for every element `x`, whenever `P x` is true, `x` must also be in `S`. Hmm, that makes sense because that's basically what it means for one set to be a subset of another.\n",
            "\n",
            "Let me break this down. A subset `A` is a subset of `B` if every element in `A` is also in `B`. So, in this case, the set `{x | P x}` is the collection of all elements `x` that make `P x` true. If this set is a subset of `S`, that means every element in this set (i.e., every `x` that satisfies `P x`) is also in `S`.\n",
            "\n",
            "Now, the lemma is stating this in two directions. The \"if and only if\" means I need to prove both that if `{x | P x} subset S`, then for all `x`, `P x` implies `x in S`, and conversely, if for all `x`, `P x` implies `x in S`, then `{x | P x}` is a subset of `S`.\n",
            "\n",
            "I should probably start by recalling the definitions of subset and set comprehension. The subset relation `A subset B` is defined as `forall x. x in A --> x in B`. The set comprehension `{x | P x}` is the set of all `x` such that `P x` holds.\n",
            "\n",
            "So for the first part of the proof: if `{x | P x} subset S`, then by the definition of subset, for all `x`, if `x` is in `{x | P x}`, then `x` is in `S`. But `x` being in `{x | P x}` means that `P x` is true. Therefore, this directly translates to `forall x. P x --> x in S`, which is the statement we needed to prove for one direction.\n",
            "\n",
            "For the converse, if we know that `forall x. P x --> x in S`, then by the definition of subset, `{x | P x}` is a subset of `S` because every element that satisfies `P x` is indeed in `S`. So this direction follows straightforwardly from the definition as well.\n",
            "\n",
            "I should also consider if there are any edge cases or special scenarios where this might not hold. For example, what if `P x` is never true? Then `{x | P x}` would be an empty set, and the empty set is a subset of any set `S`, which aligns with the logic since there are no elements to violate the subset condition. Similarly, if `P x` is always true, then `{x | P x}` would include all elements that are in `S`, which again fits with the statement.\n",
            "\n",
            "I think the key here is understanding the fundamental definitions and applying them correctly. As long as I'm careful with the logical implications and the definitions, the proof should hold.\n",
            "\n",
            "Wait, maybe I should also think about how this relates to the axiom of separation in set theory, which says that for any property `P`, there exists a set `{x | P x}` that contains exactly those elements satisfying `P`. The subset condition here is essentially leveraging that axiom to ensure elements of the comprehension are within another set `S`.\n",
            "\n",
            "Another thing to consider is the use of logical implication in the proof. The statement `P x --> x in S` is a universal statement, meaning it applies to all `x`. So, when we prove it, we have to ensure that it holds for every possible element `x` in the universe of discourse.\n",
            "\n",
            "Perhaps I should outline the proof step by step to make sure I cover both directions properly.\n",
            "</think>\n",
            "\n",
            "Alright, let's lay out the proof step by step.\n",
            "\n",
            "Firstly, we will prove the lemma `set_compre_unwrap`, which establishes an equivalence between the subset relation of a set comprehension and the conditional membership of its elements. Specifically, we aim to show:\n",
            "`{x | P x} subset S` if and only if `for all x, P x --> x in S`.\n",
            "\n",
            "**Proof:**\n",
            "\n",
            "1. **Understanding the Definitions:**\n",
            "   - `A subset B` means that for all elements `x`, if `x` is in `A`, then `x` is also in `B`.\n",
            "   - `{x | P x}` is the set of all elements `x` for which the property `P x` holds.\n",
            "\n",
            "2. **Proving the Forward Direction (`=>`):**\n",
            "   - Assume `{x | P x} subset S`; that is, every element `x` in `{x | P x}` is also in `S`.\n",
            "   - By the definition of subset: `forall x, x in {x | P x} --> x in S`.\n",
            "   - By the definition of set comprehension, `x in {x | P x}` is equivalent to `P x`.\n",
            "   - Therefore, `forall x, P x --> x in S`.\n",
            "\n",
            "3. **Proving the Reverse Direction (`<=`):**\n",
            "   - Assume that for all `x`, `P x` implies `x in S`; that is, `forall x, P x --> x in S`.\n",
            "   - By the definition of subset: `A subset B` is equivalent to `forall x, x in A --> x in B`.\n",
            "   - Here, `A` is `{x | P x}` and `B` is `S`.\n",
            "   - Therefore, `{x | P x} subset S` because for every `x`, if `x` is in `{x | P x}`, then `x in S` holds by our assumption.\n",
            "\n",
            "4. **Conclusion:**\n",
            "   - Since both directions have been established, we conclude that `{x | P x} subset S` if and only if `forall x, P x --> x in S`.\n",
            "\n",
            "**Final Answer:**\n",
            "\n",
            "```isabelle\n",
            "lemma set_compre_unwrap:\n",
            "  \"{x | P x} subset S <-> (forall x. P x --> x in S)\"\n",
            "  by (simp only: subset_def Ball_bool_eq_forall True_and)\n",
            "``` \n",
            "Extracted:\n",
            "lemma set_compre_unwrap:\n",
            "  \"{x | P x} subset S <-> (forall x. P x --> x in S)\"\n",
            "  by (simp only: subset_def Ball_bool_eq_forall True_and)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  2/500 : < :, Epoch 0.00/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>reward</th>\n",
              "      <th>reward_std</th>\n",
              "      <th>completion_length</th>\n",
              "      <th>kl</th>\n",
              "      <th>rewards / xmlcount_reward_func</th>\n",
              "      <th>rewards / soft_format_reward_func</th>\n",
              "      <th>rewards / strict_format_reward_func</th>\n",
              "      <th>rewards / int_reward_func</th>\n",
              "      <th>rewards / correctness_reward_func</th>\n",
              "      <th>rewards / checker_reward_func</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-------------------- Question:\n",
            "The lemma `list_all_dest` can be translated into the following natural language statements:\n",
            "\n",
            "1. For a list containing a single pair \\((x, y)\\), the predicate `list_all P` holds if and only if the predicate \\(P\\) holds for the pair \\((x, y)\\).\n",
            "\n",
            "2. For a list starting with a pair \\((x, y)\\) followed by another element \\(z\\) and the rest of the list \\(xs\\), the predicate `list_all P` holds if and only if the predicate \\(P\\) holds for the pair \\((x, y)\\) and `list_all P` holds for the remainder of the list starting with \\(z\\) and followed by \\(xs\\). \n",
            "Answer:\n",
            "lemma list_all_dest:\n",
            "  shows \"list_all P [(x, y)] \\<equiv> P (x, y)\"\n",
            "    and \"list_all P ((x, y) # z # xs) \\<equiv> (P (x, y) \\<and> list_all P (z # xs))\"\n",
            "proof -\n",
            "  (* Proof for the first statement *)\n",
            "  show \"list_all P [(x, y)] \\<equiv> P (x, y)\"\n",
            "  proof -\n",
            "    have \"list_all P [(x, y)] = (\\<forall>p \\<in> set [(x, y)]. P p)\"\n",
            "      by (simp add: list_all_iff)\n",
            "    also have \"... = P (x, y)\"\n",
            "      by simp\n",
            "    finally show ?thesis .\n",
            "  qed\n",
            "\n",
            "  (* Proof for the second statement *)\n",
            "  show \"list_all P ((x, y) # z # xs) \\<equiv> (P (x, y) \\<and> list_all P (z # xs))\"\n",
            "  proof -\n",
            "    have \"list_all P ((x, y) # z # xs) = (\\<forall>p \\<in> set ((x, y) # z # xs). P p)\"\n",
            "      by (simp add: list_all_iff)\n",
            "    also have \"... = (P (x, y) \\<and> (\\<forall>p \\<in> set (z # xs). P p))\"\n",
            "      by simp\n",
            "    also have \"... = (P (x, y) \\<and> list_all P (z # xs))\"\n",
            "      by (simp add: list_all_iff)\n",
            "    finally show ?thesis .\n",
            "  qed\n",
            "qed \n",
            "Response:\n",
            "Okay, so I need to prove two lemmas about the `list_all` predicate in Isabelle. Let's start by understanding what `list_all` does. From what I remember, `list_all` is a function that takes a predicate `P` and a list, and it checks if `P` holds for every element in the list. So, if I have a list of elements, `list_all P [a, b, c]` should be true only if `P a`, `P b`, and `P c` are all true.\n",
            "\n",
            "Now, looking at the first lemma, `dest`, it seems to be about a list that contains exactly one pair, like `(x, y)`. The lemma states that `list_all dest [x y]` is equivalent to applying `dest` to that pair, which would check if `x` is assignable to some type `c`. I need to show both directions: if `list_all dest [x y]` is true, then `dest x` holds, and vice versa.\n",
            "\n",
            "The second lemma, `dest_get`, is about a more complex list structure. It says that if you have a list that starts with a pair `(x, y)` followed by another element `z` and then the rest of the list `xs`, then `list_all dest [x y] (z xs)` is true if and only if the predicate holds for the pair and also holds for the list starting with `z xs`.\n",
            "\n",
            "I'm a bit confused about how `dest` applies here. Wait, I think `dest` is another predicate that's part of locale definitions, and it's used to extract conditions for certain locale rules. So maybe `dest` is a specific predicate I'm meant to consider when proving these lemmas.\n",
            "\n",
            "For the first lemma, I might need to consider pattern matching or the structure of a singleton list containing a pair. If the list is just `[x y]`, then `list_all dest [x y]` should reduce to checking if `dest (x y)` holds. Since it's a singleton, it's straightforward.\n",
            "\n",
            "For the second part, with a longer list, I think I need to use induction on the list. By breaking down the list into the first element and the rest, I can apply the induction hypothesis to the sublist. So, if I have `[x y] (z xs)`, then checking `list_all dest` on this list should depend on two conditions: first, that `dest (x y)` holds, and second, that `list_all dest` holds for the sublist `[z] xs`.\n",
            "\n",
            "I need to make sure I'm applying the right rules and not missing any cases. Perhaps I should also consider the base case when the list is empty, but in this lemma, the list starts with a pair and then has more elements, so the case for an empty list might not apply here.\n",
            "\n",
            "Another thing to think about is how `dest` interacts with the pair `(x y)`. Is there any special behavior when `dest` is applied to a pair? I'm assuming that `dest` expects a pair and then applies certain rules or conditions based on that. So, when I apply `dest` to `(x y)`, it's equivalent to checking the specific conditions defined by `dest` for that pair.\n",
            "\n",
            "I should also verify if there are any lemmas or definitions that could help here. Maybe there's a lemma about how `dest` behaves on singleton lists or on combined lists. Without knowing all the definitions, it's a bit tricky, but I'll proceed with what I have.\n",
            "\n",
            "Now, moving on to the `dest_get` lemma. It seems similar but applies to a more complex structure. If I have `[x y] (z xs)`, then `list_all dest` should hold if `dest (x y)` holds and `list_all dest (z xs)` holds. This makes sense because every element in the list needs to satisfy the `dest` predicate.\n",
            "\n",
            "I think the key here is to use the induction rule for lists. By structuring the proof correctly, I can ensure that each step checks the current element and then proceeds to check the rest of the list.\n",
            "\n",
            "Overall, I need to make sure that both lemmas are proven by checking each element in the list against the `dest` predicate, ensuring that all conditions are met for the entire list to satisfy `list_all dest`.\n",
            "</think>\n",
            "\n",
            "<reasoning>\n",
            "The lemmas `dest` and `dest_get` are about proving properties related to the `list_all` predicate in Isabelle. Specifically, these lemmas ensure that the `dest` function correctly verifies the conditions for each element in a list of pairs. The proofs involve checking each element against the `dest` predicate and ensuring that all conditions are met for the entire list.\n",
            "\n",
            "To prove these lemmas, we can structure the argument as follows:\n",
            "\n",
            "1. **Understanding `list_all`**: The `list_all` predicate applies a given predicate `P` to every element in a list. In the context of these lemmas, `P` is replaced by `dest`, which is a specific predicate used elsewhere in the development.\n",
            "\n",
            "2. **Lemma `dest`**:\n",
            "   - **Statement**: For a list containing a single pair `(x, y)`, `list_all dest [x y]` is equivalent to `dest x`.\n",
            "   - **Proof**:\n",
            "     - Since the list contains only one element `(x, y)`, applying `list_all dest` to this list reduces to checking `dest (x, y)`, which is the same as `dest x`.\n",
            "\n",
            "3. **Lemma `dest_get`**:\n",
            "   - **Statement**: For a list starting with a pair `(x, y)` followed by another element `z` and the rest of the list `xs`, `list_all dest [x y] (z xs)` is equivalent to `dest (x, y) ‚àß list_all dest (z xs)`.\n",
            "   - **Proof**:\n",
            "     - By induction on the list:\n",
            "       - **Base Case**: When the list is `[x y]`, this reduces to the previous lemma, where `list_all dest [x y]` is equivalent to `dest x`.\n",
            "       - **Inductive Step**: Assume the statement holds for a list `[z] xs`. Then, for the list `[x y] (z xs)`, applying `list_all dest` requires both `dest (x, y)` and `list_all dest (z xs)`, which is exactly what the lemma states.\n",
            "\n",
            "4. **Conclusion**: Both lemmas rely on the definition of `dest` and the structure of the lists. The proofs ensure that each element satisfies the `dest` predicate, thus verifying the entire list under `list_all`.\n",
            "</reasoning>\n",
            "\n",
            "<answer>\n",
            "``` \n",
            "isabelle \n",
            "lemma dest:\n",
            "  \"list_all dest [x y] ‚ü∑ dest x\"\n",
            "  by (cases \"[x y]\", simp [dest])\n",
            " \n",
            "lemma dest_get:\n",
            "  \"list_all dest [x y] (z xs) ‚ü∑ dest x ‚àß list_all dest (z xs)\"\n",
            "  by (cases \"[x y] (z xs)\", simp [dest])\n",
            "``` \n",
            "</answer>\n",
            "``` \n",
            "Extracted:\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "sys.path.append('../')\n",
        "os.environ['PISA_PATH'] = '/home/siai/Portal-to-ISAbelle/src/main/python'\n",
        "\n",
        "\n",
        "trainer = GRPOTrainer(\n",
        "    model = model,\n",
        "    processing_class = tokenizer,\n",
        "    reward_funcs = [\n",
        "        xmlcount_reward_func,\n",
        "        soft_format_reward_func,\n",
        "        strict_format_reward_func,\n",
        "        int_reward_func,\n",
        "        correctness_reward_func,\n",
        "        checker_reward_func,\n",
        "    ],\n",
        "    args = training_args,\n",
        "    train_dataset = dataset,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlaUdxC_VHpz"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Now let's try the model we just trained! First, let's first try the model without any GRPO trained:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "qtcz_lpbVC92",
        "outputId": "9b12655a-7905-42a8-d6f0-210ff74a6d73"
      },
      "outputs": [],
      "source": [
        "text = tokenizer.apply_chat_template([\n",
        "    {\"role\" : \"user\", \"content\" : \"Calculate pi.\"},\n",
        "], tokenize = False, add_generation_prompt = True)\n",
        "\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 0.8,\n",
        "    top_p = 0.95,\n",
        "    max_tokens = 1024,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    [text],\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = None,\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Colxz9TAVMsi"
      },
      "source": [
        "And now with the LoRA we just trained with GRPO - we first save the LoRA first!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL-BcuB1VLIv"
      },
      "outputs": [],
      "source": [
        "model.save_lora(\"grpo_saved_lora\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CwpbwnDBVRLg"
      },
      "source": [
        "Now we load the LoRA and test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "zf_OY5WMVOxF",
        "outputId": "c34d81a7-192d-427d-81f0-cbca7009b7d1"
      },
      "outputs": [],
      "source": [
        "text = tokenizer.apply_chat_template([\n",
        "    {\"role\" : \"system\", \"content\" : SYSTEM_PROMPT},\n",
        "    {\"role\" : \"user\", \"content\" : \"Calculate pi.\"},\n",
        "], tokenize = False, add_generation_prompt = True)\n",
        "\n",
        "from vllm import SamplingParams\n",
        "sampling_params = SamplingParams(\n",
        "    temperature = 0.8,\n",
        "    top_p = 0.95,\n",
        "    max_tokens = 1024,\n",
        ")\n",
        "output = model.fast_generate(\n",
        "    text,\n",
        "    sampling_params = sampling_params,\n",
        "    lora_request = model.load_lora(\"grpo_saved_lora\"),\n",
        ")[0].outputs[0].text\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aDgFfhFYIAS"
      },
      "source": [
        "Our reasoning model is much better - it's not always correct, since we only trained it for an hour or so - it'll be better if we extend the sequence length and train for longer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NUEmHFSYNTp"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjXGTkp7YNtB"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52WMb3k_YPt8"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QyEjW-WuYQIm"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n33Lwz_eqG4Z"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp or a UI based system like Jan or Open WebUI. You can install Jan [here](https://github.com/janhq/jan) and Open WebUI [here](https://github.com/open-webui/open-webui)\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Llama 3.2 Conversational notebook. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(1B_and_3B)-Conversational.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ‚≠êÔ∏è <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠êÔ∏è\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0ca67b0c4ca64eb788358a51308f6b97": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ac03aff5c314b00ac938c80eb7b2f8a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c522d78b1834068bd4b155d0f87a4d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ca67b0c4ca64eb788358a51308f6b97",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83c3c811923a4642aba156d1215b39d2",
            "value": 1
          }
        },
        "3febcf8a8eca40c28aafc697f3ec8776": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f3d96b613e94e9984d4599ca9ca7b17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea549fffa8c2469888d1668158bc105c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_98b432b98839428f85d91580c21e80e2",
            "value": ""
          }
        },
        "6221f0be3b8d48e797c873565a216680": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66c3271554b1455eb56be55c9241e45e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fee4f852c9744a07b909e586e3615604",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3febcf8a8eca40c28aafc697f3ec8776",
            "value": 1
          }
        },
        "697faad6643a43aca98015da4faef186": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "769bde36e2ba4434bddd78e7d5911be4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ac03aff5c314b00ac938c80eb7b2f8a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_88c63d94a05a42c49d5f8958a27987a6",
            "value": ""
          }
        },
        "83c3c811923a4642aba156d1215b39d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "88c63d94a05a42c49d5f8958a27987a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94873c3c077e483790b34f95c421f484": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98b432b98839428f85d91580c21e80e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a23afba19c2a4d3a90d771fc55f8d490": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e863bf099e064da7b482c21fe7b77de7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_697faad6643a43aca98015da4faef186",
            "value": "Loading‚Äásafetensors‚Äácheckpoint‚Äáshards:‚Äá100%‚ÄáCompleted‚Äá|‚Äá1/1‚Äá[00:16&lt;00:00,‚Äá16.13s/it]\n"
          }
        },
        "b4e1eb8eeb064c88a2142e474fb8327f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d36b61cf796c429080e93ea838a3759e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4e1eb8eeb064c88a2142e474fb8327f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_da10502506f9448c9de94f1ddd84d3b1",
            "value": "Loading‚Äásafetensors‚Äácheckpoint‚Äáshards:‚Äá100%‚ÄáCompleted‚Äá|‚Äá1/1‚Äá[00:27&lt;00:00,‚Äá27.50s/it]\n"
          }
        },
        "d8d0dca36cfc47f0919924da07c231e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f3d96b613e94e9984d4599ca9ca7b17",
              "IPY_MODEL_66c3271554b1455eb56be55c9241e45e",
              "IPY_MODEL_d36b61cf796c429080e93ea838a3759e"
            ],
            "layout": "IPY_MODEL_94873c3c077e483790b34f95c421f484"
          }
        },
        "da10502506f9448c9de94f1ddd84d3b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6cc388e78c14abfaa49d2be6fa1b5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_769bde36e2ba4434bddd78e7d5911be4",
              "IPY_MODEL_3c522d78b1834068bd4b155d0f87a4d7",
              "IPY_MODEL_a23afba19c2a4d3a90d771fc55f8d490"
            ],
            "layout": "IPY_MODEL_6221f0be3b8d48e797c873565a216680"
          }
        },
        "e863bf099e064da7b482c21fe7b77de7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea549fffa8c2469888d1668158bc105c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fee4f852c9744a07b909e586e3615604": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
