{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ArqgnsfGhgHI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2025-02-16 17:59:16,680] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "INFO 02-16 17:59:17 __init__.py:183] Automatically detected platform cuda.\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "import os\n",
        "import sys\n",
        "from dataclasses import dataclass, field\n",
        "import time\n",
        "import openai\n",
        "import json\n",
        "import random\n",
        "import gym\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any\n",
        "import random\n",
        "import torch\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForCausalLM, AdamW\n",
        ")\n",
        "from accelerate import Accelerator, notebook_launcher\n",
        "import random\n",
        "import torch\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer, AutoModelForCausalLM, AdamW\n",
        ")\n",
        "\n",
        "\n",
        "from peft import LoraConfig\n",
        "from trl import GRPOConfig, GRPOTrainer\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import textwrap\n",
        "import warnings\n",
        "from collections import defaultdict\n",
        "from typing import Any, Callable, Optional, Union\n",
        "from unittest.mock import patch\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import transformers\n",
        "from accelerate.utils import broadcast_object_list, gather_object\n",
        "from transformers import (\n",
        "    PreTrainedModel,\n",
        "    Trainer,\n",
        ")\n",
        "from trl.trainer import GRPOTrainer\n",
        "from trl.data_utils import (\n",
        "    apply_chat_template,\n",
        "    is_conversational,\n",
        "    maybe_apply_chat_template,\n",
        ")\n",
        "from trl.models import unwrap_model_for_generation\n",
        "from trl.trainer.grpo_config import GRPOConfig\n",
        "from trl.trainer.utils import pad\n",
        "import datasets\n",
        "from datasets import load_dataset\n",
        "from transformers import set_seed\n",
        "from transformers.trainer_utils import get_last_checkpoint\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import subprocess\n",
        "from typing import TYPE_CHECKING, Dict, Union\n",
        "from concurrent.futures import Future\n",
        "\n",
        "from transformers import AutoConfig\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional\n",
        "\n",
        "import re\n",
        "from latex2sympy2_extended import NormalizationConfig\n",
        "from math_verify import LatexExtractionConfig, parse, verify\n",
        "\n",
        "import trl\n",
        "\n",
        "import subprocess\n",
        "from typing import List\n",
        "\n",
        "from transformers import TrainerCallback\n",
        "from transformers.trainer_callback import TrainerControl, TrainerState\n",
        "from transformers.training_args import TrainingArguments\n",
        "\n",
        "from trl import ModelConfig, ScriptArguments, TrlParser, get_peft_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bz7whDjhk4jJ"
      },
      "outputs": [],
      "source": [
        "#from utils.callbacks import get_callbacks\n",
        "def get_callbacks(train_config, model_config) -> List[TrainerCallback]:\n",
        "    callbacks = []\n",
        "    for callback_name in train_config.callbacks:\n",
        "        if callback_name not in CALLBACKS:\n",
        "            raise ValueError(f\"Callback {callback_name} not found in CALLBACKS.\")\n",
        "        callbacks.append(CALLBACKS[callback_name](model_config))\n",
        "\n",
        "    return callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Checker(object):\n",
        "    \"\"\"A modified version of the Draft, Sketch, Prove proof-checking client.\n",
        "    (https://github.com/albertqjiang/draft_sketch_prove/blob/main/autoformalization/checker.py)\n",
        "\n",
        "    This checker supports Isabelle2022 via the new version of PISA\n",
        "    (https://albertqjiang.github.io/Portal-to-ISAbelle/).\n",
        "\n",
        "    It supports checking a miniF2F-style proof via `check`.\n",
        "\n",
        "    Finally, it replaces `sledgehammer` with a call to `normalhammer`.\n",
        "    \"\"\"\n",
        "    def __init__(self, working_dir, isa_path, theory_file, port=9000):\n",
        "        sys.path.append(os.environ['PISA_PATH'])\n",
        "        try:\n",
        "            from pisa_client import initialise_env\n",
        "            self.initialise_env = initialise_env\n",
        "        except:\n",
        "            print(\"Set $PISA_PATH to /yourpath/to/Portal-to-ISAbelle/src/main/python\")\n",
        "\n",
        "        self.working_dir = working_dir\n",
        "        self.isa_path = isa_path\n",
        "        self.theory_file = theory_file\n",
        "        self.port = port\n",
        "\n",
        "    def _initialize(self):\n",
        "        env = self.initialise_env(\n",
        "            self.port,\n",
        "            isa_path=self.isa_path,\n",
        "            theory_file_path=self.theory_file,\n",
        "            working_directory=self.working_dir\n",
        "        )\n",
        "        return env\n",
        "\n",
        "    def _exit(self, env):\n",
        "        try:\n",
        "            env.post('exit')\n",
        "        except:\n",
        "            print(\"env.post('exit') timed out\")\n",
        "            pass\n",
        "        os.system(\"ps aux | grep Isabelle | awk '{print $2}' | xargs kill -9 > /dev/null 2>&1\")\n",
        "        os.system(\"ps aux | grep poly | awk '{print $2}' | xargs kill -9 > /dev/null 2>&1\")\n",
        "\n",
        "    def _parse_output(self, obs):\n",
        "        \"\"\"Parse the sledgehammer output, otherwise return an empty string\"\"\"\n",
        "        if '<hammer>' in obs:\n",
        "            output = obs.split('<hammer>')[0]\n",
        "        else:\n",
        "            output = ''\n",
        "        return output\n",
        "\n",
        "    def _run_step(self, step, i, tls_name, env):\n",
        "        obs, reward, done, metadata = env.step_to_top_level_state(\n",
        "            action=step,\n",
        "            tls_name=tls_name,\n",
        "            new_name='default_%d' % i\n",
        "        )\n",
        "        error = None\n",
        "        if 'error:' in obs or 'Step error' in obs or 'Unknown error' in obs:\n",
        "            error = obs\n",
        "        return obs, reward, done, metadata, error\n",
        "\n",
        "    def _run_sledgehammer(self, step, i, tls_name, env):\n",
        "        # First try heuristics\n",
        "        for heuristic in ['by auto', 'by simp', 'by blast', 'by fastforce', 'by force', 'by eval', 'by presburger', 'by sos', 'by arith', 'by linarith', 'by (auto simp: field_simps)']:\n",
        "            step_ = step.replace('normalhammer', heuristic)\n",
        "            obs, reward, done, metadata, error = self._run_step(step_, i, tls_name, env)\n",
        "            if error is None:\n",
        "                obs = '%s <hammer> %s' % (heuristic, obs)\n",
        "                return obs, reward, done, metadata, error\n",
        "        # Try sledgehammer\n",
        "        out = self._run_step(step, i, tls_name, env)\n",
        "        return out\n",
        "\n",
        "    def check(self, statement_and_proof):\n",
        "        # Initialize environment\n",
        "        env = self._initialize()\n",
        "        env.initialise()\n",
        "\n",
        "        # Wrap and parse theorem\n",
        "        theory = Checker.wrap_theorem(statement_and_proof)\n",
        "        steps = Checker.get_parsed(env, theory)\n",
        "\n",
        "        result = self._check(env, steps)\n",
        "        return result\n",
        "\n",
        "    def _check(self, env, steps):\n",
        "        done = False\n",
        "        reason = ''\n",
        "        success = False\n",
        "        step_results = []\n",
        "        tls_name = 'default'\n",
        "        for i, step in enumerate(steps):\n",
        "            try:\n",
        "                time0 = time.time()\n",
        "                if 'normalhammer' in step:\n",
        "                    obs, reward, done, metadata, error = self._run_sledgehammer(step, i, tls_name, env)\n",
        "                else:\n",
        "                    obs, reward, done, metadata, error = self._run_step(step, i, tls_name, env)\n",
        "                step_time = time.time() - time0\n",
        "                step_results.append(dict(index=i, step=step, output=self._parse_output(obs), step_time=step_time))\n",
        "                if error is not None:\n",
        "                    reason = error\n",
        "                    success = False\n",
        "                    done = False\n",
        "                    break\n",
        "            except:\n",
        "                # Timeout - end the proof attempt\n",
        "                success = False\n",
        "                done = False\n",
        "                reason = 'timeout (%d)' % len(step_results)\n",
        "                step_results.append(dict(index=i, step=step, output=''))\n",
        "                break\n",
        "\n",
        "            # Change when successful\n",
        "            tls_name = 'default_%d' % i\n",
        "\n",
        "        if done and reward == 1.0:\n",
        "            success = True\n",
        "\n",
        "        result = {\n",
        "            'success': success,\n",
        "            'reason': reason,\n",
        "            'num_steps': len(steps),\n",
        "            'last_step': len(step_results),\n",
        "            'step_results': step_results,\n",
        "            'theorem_and_proof': self.reconstruct(step_results) if success else ''\n",
        "        }\n",
        "        # Exit environment\n",
        "        self._exit(env)\n",
        "        return result\n",
        "    \n",
        "    @staticmethod\n",
        "    def reconstruct(step_results):\n",
        "        steps = []\n",
        "        for step_result in step_results[1:]:\n",
        "            if step_result['output'] != '':\n",
        "                steps.append(step_result['output'].strip())\n",
        "            else:\n",
        "                steps.append(step_result['step'].strip())\n",
        "        theorem_and_proof = '\\n'.join(steps)\n",
        "        return theorem_and_proof\n",
        "\n",
        "    @staticmethod\n",
        "    def wrap_theorem(theorem):\n",
        "        return 'theory Interactive imports HOL.HOL Complex_Main \"HOL-Library.Code_Target_Numeral\" \"HOL-Library.Sum_of_Squares\" \"Symmetric_Polynomials.Vieta\" \"HOL-Computational_Algebra.Computational_Algebra\" \"HOL-Number_Theory.Number_Theory\" \\n begin\\n%s' % theorem\n",
        "\n",
        "    @staticmethod\n",
        "    def get_parsed(env, theory, tls_name='default'):\n",
        "        # HACK: the parsing doesn't work well with `normalhammer`, so we replace\n",
        "        # all hammer calls with sorry, then replace sorry to normalhammer after parsing.\n",
        "        theory = theory.replace('sledgehammer', 'sorry')\n",
        "        theory = theory.replace('normalhammer', 'sorry')\n",
        "\n",
        "        steps = env.post(f\"<parse text> ${theory}\")\n",
        "        steps = steps.split('<SEP>')\n",
        "        steps = [s for s in steps if s.strip() != '']\n",
        "        # remove weird '$' step and whitespace steps\n",
        "        steps = [s for s in steps if s != '$' and s.strip() != '']\n",
        "        steps = [s.replace('sorry', 'normalhammer') for s in steps]\n",
        "        return steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('../')\n",
        "os.environ['PISA_PATH'] = '/home/siai/Portal-to-ISAbelle/src/main/python'\n",
        "\n",
        "checker = Checker(\n",
        "    working_dir='/home/siai/Isabelle2022/src/HOL/Examples',\n",
        "    isa_path='/home/siai/Isabelle2022',\n",
        "    theory_file='/home/siai/Isabelle2022/src/HOL/Examples/Interactive.thy',\n",
        "    port=9000\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1UNDdSjJl1vw"
      },
      "outputs": [],
      "source": [
        "#from grpo_trainer import GRPOTrainer\n",
        "\n",
        "\n",
        "RewardFunc = Union[str, PreTrainedModel, Callable[[list, list], list[float]]]\n",
        "\n",
        "\n",
        "class GRPOTrainer(GRPOTrainer):\n",
        "    # base trl GRPO_trainer\n",
        "    def compute_loss(\n",
        "        self, model, inputs, return_outputs=False, num_items_in_batch=None\n",
        "    ):\n",
        "        if return_outputs:\n",
        "            raise ValueError(\"The GRPOTrainer does not support returning outputs\")\n",
        "\n",
        "        device = self.accelerator.device\n",
        "        prompts = [x[\"prompt\"] for x in inputs]\n",
        "        prompts_text = [\n",
        "            maybe_apply_chat_template(example, self.processing_class)[\"prompt\"]\n",
        "            for example in inputs\n",
        "        ]\n",
        "        prompt_inputs = self.processing_class(\n",
        "            prompts_text,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            padding_side=\"left\",\n",
        "            add_special_tokens=False,\n",
        "        )\n",
        "        prompt_inputs = super()._prepare_inputs(prompt_inputs)\n",
        "\n",
        "        if self.max_prompt_length is not None:\n",
        "            prompt_inputs[\"input_ids\"] = prompt_inputs[\"input_ids\"][\n",
        "                :, -self.max_prompt_length :\n",
        "            ]\n",
        "            prompt_inputs[\"attention_mask\"] = prompt_inputs[\"attention_mask\"][\n",
        "                :, -self.max_prompt_length :\n",
        "            ]\n",
        "\n",
        "        # Generate completions using either vLLM or regular generation\n",
        "        if self.args.use_vllm:\n",
        "            # First, have main process load weights if needed\n",
        "            if self.state.global_step != self._last_loaded_step:\n",
        "                with unwrap_model_for_generation(\n",
        "                    model, self.accelerator\n",
        "                ) as unwrapped_model:\n",
        "                    state_dict = unwrapped_model.state_dict()\n",
        "                if self.accelerator.is_main_process:\n",
        "                    llm_model = (\n",
        "                        self.llm.llm_engine.model_executor.driver_worker.model_runner.model\n",
        "                    )\n",
        "                    llm_model.load_weights(state_dict.items())\n",
        "                self._last_loaded_step = self.state.global_step\n",
        "\n",
        "            # Generate completions using vLLM: gather all prompts and use them in a single call in the main process\n",
        "            all_prompts_text = gather_object(prompts_text)\n",
        "            if self.accelerator.is_main_process:\n",
        "                outputs = self.llm.generate(\n",
        "                    all_prompts_text,\n",
        "                    sampling_params=self.sampling_params,\n",
        "                    use_tqdm=False,\n",
        "                )\n",
        "                completion_ids = [\n",
        "                    out.token_ids\n",
        "                    for completions in outputs\n",
        "                    for out in completions.outputs\n",
        "                ]\n",
        "                for output in outputs:\n",
        "                    print(\"-\" * 100)\n",
        "                    print(\"\\n\\n\\n\")\n",
        "                    prompt = output.prompt\n",
        "                    for output_t in output.outputs:\n",
        "                        # print(completion_ids)\n",
        "                        print(\"=\" * 100)\n",
        "                        generated_text = output_t.text\n",
        "                        print(\"【USER】: \", prompt)\n",
        "                        print(\"\\n【ASSISTANT】:\", generated_text)\n",
        "            else:\n",
        "                completion_ids = [None] * len(all_prompts_text) * self.num_generations\n",
        "\n",
        "            # Broadcast the completions from the main process to all processes, ensuring each process receives its\n",
        "            # corresponding slice.\n",
        "            completion_ids = broadcast_object_list(completion_ids, from_process=0)\n",
        "            process_slice = slice(\n",
        "                self.accelerator.process_index * len(prompts) * self.num_generations,\n",
        "                (self.accelerator.process_index + 1)\n",
        "                * len(prompts)\n",
        "                * self.num_generations,\n",
        "            )\n",
        "            completion_ids = completion_ids[process_slice]\n",
        "\n",
        "            # Pad the completions, and concatenate them with the prompts\n",
        "            completion_ids = [\n",
        "                torch.tensor(ids, device=device) for ids in completion_ids\n",
        "            ]\n",
        "            completion_ids = pad(\n",
        "                completion_ids, padding_value=self.processing_class.pad_token_id\n",
        "            )\n",
        "            prompt_inputs_repeated = torch.repeat_interleave(\n",
        "                prompt_inputs[\"input_ids\"], self.num_generations, dim=0\n",
        "            ).to(device)\n",
        "            prompt_completion_ids = torch.cat(\n",
        "                [prompt_inputs_repeated, completion_ids], dim=1\n",
        "            )\n",
        "        else:\n",
        "            # Regular generation path\n",
        "            with unwrap_model_for_generation(\n",
        "                model, self.accelerator\n",
        "            ) as unwrapped_model:\n",
        "                prompt_inputs[\"input_ids\"] = prompt_inputs[\"input_ids\"].to(device)\n",
        "                prompt_inputs[\"attention_mask\"] = prompt_inputs[\"attention_mask\"].to(\n",
        "                    device\n",
        "                )\n",
        "\n",
        "                prompt_completion_ids = unwrapped_model.generate(\n",
        "                    **prompt_inputs, generation_config=self.generation_config\n",
        "                )\n",
        "\n",
        "        prompt_length = prompt_inputs[\"input_ids\"].size(1)\n",
        "        completion_ids = prompt_completion_ids[:, prompt_length:]\n",
        "\n",
        "        # Get the per-token log probabilities for the completions for the model and the reference model\n",
        "        def get_per_token_logps(model, input_ids, num_logits_to_keep):\n",
        "            # We add 1 to `num_logits_to_keep` because the last logits of the sequence is later excluded\n",
        "            logits = model(\n",
        "                input_ids, num_logits_to_keep=num_logits_to_keep + 1\n",
        "            ).logits  # (B, L, V)\n",
        "            logits = logits[\n",
        "                :, :-1, :\n",
        "            ]  # (B, L-1, V), exclude the last logit: it corresponds to the next token pred\n",
        "\n",
        "            # Compute the log probabilities for the input tokens. Use a loop to reduce memory peak.\n",
        "            per_token_logps = []\n",
        "            for logits_row, input_ids_row in zip(\n",
        "                logits, input_ids[:, -num_logits_to_keep:]\n",
        "            ):\n",
        "                log_probs = logits_row.log_softmax(dim=-1)\n",
        "                token_log_prob = torch.gather(\n",
        "                    log_probs, dim=1, index=input_ids_row.unsqueeze(1)\n",
        "                ).squeeze(1)\n",
        "                per_token_logps.append(token_log_prob)\n",
        "            return torch.stack(per_token_logps)\n",
        "\n",
        "        num_logits_to_keep = completion_ids.size(\n",
        "            1\n",
        "        )  # we only need to compute the logits for the completion tokens\n",
        "        per_token_logps = get_per_token_logps(\n",
        "            model, prompt_completion_ids, num_logits_to_keep\n",
        "        )\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            if self.ref_model is not None:\n",
        "                ref_per_token_logps = get_per_token_logps(\n",
        "                    self.ref_model, prompt_completion_ids, num_logits_to_keep\n",
        "                )\n",
        "            else:\n",
        "                with self.accelerator.unwrap_model(model).disable_adapter():\n",
        "                    ref_per_token_logps = get_per_token_logps(\n",
        "                        model, prompt_completion_ids, num_logits_to_keep\n",
        "                    )\n",
        "\n",
        "        # Compute the KL divergence between the model and the reference model\n",
        "        per_token_kl = (\n",
        "            torch.exp(ref_per_token_logps - per_token_logps)\n",
        "            - (ref_per_token_logps - per_token_logps)\n",
        "            - 1\n",
        "        )\n",
        "\n",
        "        # Mask everything after the first EOS token\n",
        "        is_eos = completion_ids == self.processing_class.eos_token_id\n",
        "        eos_idx = torch.full(\n",
        "            (is_eos.size(0),), is_eos.size(1), dtype=torch.long, device=device\n",
        "        )\n",
        "        eos_idx[is_eos.any(dim=1)] = is_eos.int().argmax(dim=1)[is_eos.any(dim=1)]\n",
        "        sequence_indices = torch.arange(is_eos.size(1), device=device).expand(\n",
        "            is_eos.size(0), -1\n",
        "        )\n",
        "        completion_mask = (sequence_indices <= eos_idx.unsqueeze(1)).int()\n",
        "\n",
        "        # Decode the generated completions\n",
        "        completions = self.processing_class.batch_decode(\n",
        "            completion_ids, skip_special_tokens=True\n",
        "        )\n",
        "        if is_conversational(inputs[0]):\n",
        "            completions = [\n",
        "                [{\"role\": \"assistant\", \"content\": completion}]\n",
        "                for completion in completions\n",
        "            ]\n",
        "\n",
        "        # Compute the rewards\n",
        "        prompts = [prompt for prompt in prompts for _ in range(self.num_generations)]\n",
        "\n",
        "        rewards_per_func = torch.zeros(\n",
        "            len(prompts), len(self.reward_funcs), device=device\n",
        "        )\n",
        "        for i, (reward_func, reward_processing_class) in enumerate(\n",
        "            zip(self.reward_funcs, self.reward_processing_classes)\n",
        "        ):\n",
        "            if isinstance(reward_func, PreTrainedModel):\n",
        "                if is_conversational(inputs[0]):\n",
        "                    messages = [\n",
        "                        {\"messages\": p + c} for p, c in zip(prompts, completions)\n",
        "                    ]\n",
        "                    texts = [\n",
        "                        apply_chat_template(x, reward_processing_class)[\"text\"]\n",
        "                        for x in messages\n",
        "                    ]\n",
        "                else:\n",
        "                    texts = [p + c for p, c in zip(prompts, completions)]\n",
        "                reward_inputs = reward_processing_class(\n",
        "                    texts,\n",
        "                    return_tensors=\"pt\",\n",
        "                    padding=True,\n",
        "                    padding_side=\"right\",\n",
        "                    add_special_tokens=False,\n",
        "                )\n",
        "                reward_inputs = super()._prepare_inputs(reward_inputs)\n",
        "                with torch.inference_mode():\n",
        "                    rewards_per_func[:, i] = reward_func(**reward_inputs).logits[\n",
        "                        :, 0\n",
        "                    ]  # Shape (B*G,)\n",
        "            else:\n",
        "                # Repeat all input columns (but \"prompt\" and \"completion\") to match the number of generations\n",
        "                reward_kwargs = {\n",
        "                    key: []\n",
        "                    for key in inputs[0].keys()\n",
        "                    if key not in [\"prompt\", \"completion\"]\n",
        "                }\n",
        "                for key in reward_kwargs:\n",
        "                    for example in inputs:\n",
        "                        # Repeat each value in the column for `num_generations` times\n",
        "                        reward_kwargs[key].extend([example[key]] * self.num_generations)\n",
        "                output_reward_func = reward_func(\n",
        "                    prompts=prompts, completions=completions, **reward_kwargs\n",
        "                )\n",
        "                rewards_per_func[:, i] = torch.tensor(\n",
        "                    output_reward_func, dtype=torch.float32, device=device\n",
        "                )\n",
        "\n",
        "        # Sum the rewards from all reward functions\n",
        "        rewards = rewards_per_func.sum(dim=1)\n",
        "\n",
        "        # Compute grouped-wise rewards\n",
        "        mean_grouped_rewards = rewards.view(-1, self.num_generations).mean(dim=1)\n",
        "        std_grouped_rewards = rewards.view(-1, self.num_generations).std(dim=1)\n",
        "\n",
        "        # Normalize the rewards to compute the advantages\n",
        "        mean_grouped_rewards = mean_grouped_rewards.repeat_interleave(\n",
        "            self.num_generations, dim=0\n",
        "        )\n",
        "        std_grouped_rewards = std_grouped_rewards.repeat_interleave(\n",
        "            self.num_generations, dim=0\n",
        "        )\n",
        "        advantages = (rewards - mean_grouped_rewards) / (std_grouped_rewards + 1e-4)\n",
        "\n",
        "        # x - x.detach() allows for preserving gradients from x\n",
        "        per_token_loss = torch.exp(\n",
        "            per_token_logps - per_token_logps.detach()\n",
        "        ) * advantages.unsqueeze(1)\n",
        "        per_token_loss = -(per_token_loss - self.beta * per_token_kl)\n",
        "        loss = (\n",
        "            (per_token_loss * completion_mask).sum(dim=1) / completion_mask.sum(dim=1)\n",
        "        ).mean()\n",
        "\n",
        "        # Log the metrics\n",
        "        completion_length = (\n",
        "            self.accelerator.gather_for_metrics(completion_mask.sum(1))\n",
        "            .float()\n",
        "            .mean()\n",
        "            .item()\n",
        "        )\n",
        "        self._metrics[\"completion_length\"].append(completion_length)\n",
        "\n",
        "        reward_per_func = self.accelerator.gather_for_metrics(rewards_per_func).mean(0)\n",
        "        for i, reward_func in enumerate(self.reward_funcs):\n",
        "            if isinstance(reward_func, PreTrainedModel):\n",
        "                reward_func_name = reward_func.config._name_or_path.split(\"/\")[-1]\n",
        "            else:\n",
        "                reward_func_name = reward_func.__name__\n",
        "            self._metrics[f\"rewards/{reward_func_name}\"].append(\n",
        "                reward_per_func[i].item()\n",
        "            )\n",
        "\n",
        "        self._metrics[\"reward\"].append(\n",
        "            self.accelerator.gather_for_metrics(rewards).mean().item()\n",
        "        )\n",
        "\n",
        "        self._metrics[\"reward_std\"].append(\n",
        "            self.accelerator.gather_for_metrics(std_grouped_rewards).mean().item()\n",
        "        )\n",
        "\n",
        "        mean_kl = (\n",
        "            (per_token_kl * completion_mask).sum(dim=1) / completion_mask.sum(dim=1)\n",
        "        ).mean()\n",
        "        self._metrics[\"kl\"].append(\n",
        "            self.accelerator.gather_for_metrics(mean_kl).mean().item()\n",
        "        )\n",
        "\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SIsFSQYik_vJ"
      },
      "outputs": [],
      "source": [
        "#from .evaluation import run_benchmark_jobs\n",
        "def run_benchmark_jobs(training_args: Union[\"SFTConfig\", \"GRPOConfig\"], model_args: \"ModelConfig\") -> None:\n",
        "    benchmarks = training_args.benchmarks\n",
        "    if len(benchmarks) == 1 and benchmarks[0] == \"all\":\n",
        "        benchmarks = get_lighteval_tasks()\n",
        "        # Evaluate on all supported benchmarks. Later we may want to include a `chat` option\n",
        "        # that just evaluates on `ifeval` and `mt_bench` etc.\n",
        "\n",
        "    for benchmark in benchmarks:\n",
        "        print(f\"Launching benchmark `{benchmark}`\")\n",
        "        if benchmark in get_lighteval_tasks():\n",
        "            run_lighteval_job(benchmark, training_args, model_args)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown benchmark {benchmark}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zGcuLNQyiTOz"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class GRPOConfig(trl.GRPOConfig):\n",
        "    \"\"\"\n",
        "    args for callbacks, benchmarks etc\n",
        "    \"\"\"\n",
        "\n",
        "    benchmarks: list[str] = field(\n",
        "        default_factory=lambda: [],\n",
        "        metadata={\"help\": \"The benchmarks to run after training.\"},\n",
        "    )\n",
        "    callbacks: list[str] = field(\n",
        "        default_factory=lambda: [],\n",
        "        metadata={\"help\": \"The callbacks to run during training.\"},\n",
        "    )\n",
        "    system_prompt: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"The optional system prompt to use for benchmarking.\"},\n",
        "    )\n",
        "    hub_model_revision: Optional[str] = field(\n",
        "        default=\"main\", metadata={\"help\": \"The Hub model branch to push the model to.\"}\n",
        "    )\n",
        "    overwrite_hub_revision: bool = field(\n",
        "        default=False, metadata={\"help\": \"Whether to overwrite the Hub revision.\"}\n",
        "    )\n",
        "    push_to_hub_revision: bool = field(\n",
        "        default=False, metadata={\"help\": \"Whether to push to a Hub revision/branch.\"}\n",
        "    )\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SFTConfig(trl.SFTConfig):\n",
        "    \"\"\"\n",
        "    args for callbacks, benchmarks etc\n",
        "    \"\"\"\n",
        "\n",
        "    benchmarks: list[str] = field(\n",
        "        default_factory=lambda: [],\n",
        "        metadata={\"help\": \"The benchmarks to run after training.\"},\n",
        "    )\n",
        "    callbacks: list[str] = field(\n",
        "        default_factory=lambda: [],\n",
        "        metadata={\"help\": \"The callbacks to run during training.\"},\n",
        "    )\n",
        "    system_prompt: Optional[str] = field(\n",
        "        default=None,\n",
        "        metadata={\"help\": \"The optional system prompt to use for benchmarking.\"},\n",
        "    )\n",
        "    hub_model_revision: Optional[str] = field(\n",
        "        default=\"main\",\n",
        "        metadata={\"help\": \"The Hub model branch to push the model to.\"},\n",
        "    )\n",
        "    overwrite_hub_revision: bool = field(\n",
        "        default=False, metadata={\"help\": \"Whether to overwrite the Hub revision.\"}\n",
        "    )\n",
        "    push_to_hub_revision: bool = field(\n",
        "        default=False, metadata={\"help\": \"Whether to push to a Hub revision/branch.\"}\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4USTS_ADlIA1"
      },
      "outputs": [],
      "source": [
        "#from .hub import push_to_hub_revision\n",
        "def push_to_hub_revision(training_args: SFTConfig | GRPOConfig, extra_ignore_patterns=[]) -> Future:\n",
        "    \"\"\"Pushes the model to branch on a Hub repo.\"\"\"\n",
        "\n",
        "    # Create a repo if it doesn't exist yet\n",
        "    repo_url = create_repo(repo_id=training_args.hub_model_id, private=True, exist_ok=True)\n",
        "    # Get initial commit to branch from\n",
        "    initial_commit = list_repo_commits(training_args.hub_model_id)[-1]\n",
        "    # Now create the branch we'll be pushing to\n",
        "    create_branch(\n",
        "        repo_id=training_args.hub_model_id,\n",
        "        branch=training_args.hub_model_revision,\n",
        "        revision=initial_commit.commit_id,\n",
        "        exist_ok=True,\n",
        "    )\n",
        "    logger.info(f\"Created target repo at {repo_url}\")\n",
        "    logger.info(f\"Pushing to the Hub revision {training_args.hub_model_revision}...\")\n",
        "    ignore_patterns = [\"checkpoint-*\", \"*.pth\"]\n",
        "    ignore_patterns.extend(extra_ignore_patterns)\n",
        "    future = upload_folder(\n",
        "        repo_id=training_args.hub_model_id,\n",
        "        folder_path=training_args.output_dir,\n",
        "        revision=training_args.hub_model_revision,\n",
        "        commit_message=f\"Add {training_args.hub_model_revision} checkpoint\",\n",
        "        ignore_patterns=ignore_patterns,\n",
        "        run_as_future=True,\n",
        "    )\n",
        "    logger.info(f\"Pushed to {repo_url} revision {training_args.hub_model_revision} successfully!\")\n",
        "\n",
        "    return future"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RRJND9mSkUbo"
      },
      "outputs": [],
      "source": [
        "#from rewards import REWARD_FUNCS_REGISTRY\n",
        "\n",
        "def accuracy_reward(completions, solution, **kwargs):\n",
        "    \"\"\"Reward function that checks if the completion is the same as the ground truth.\"\"\"\n",
        "    contents = [completion[0][\"content\"] for completion in completions]\n",
        "    rewards = []\n",
        "    for content, sol in zip(contents, solution):\n",
        "        gold_parsed = parse(\n",
        "            sol,\n",
        "            extraction_mode=\"first_match\",\n",
        "            extraction_config=[LatexExtractionConfig()],\n",
        "        )\n",
        "        if len(gold_parsed) != 0:\n",
        "            # print('latex gold parsed')\n",
        "            # We require the answer to be provided in correct latex (no malformed operators)\n",
        "            answer_parsed = parse(\n",
        "                content,\n",
        "                extraction_config=[\n",
        "                    LatexExtractionConfig(\n",
        "                        normalization_config=NormalizationConfig(\n",
        "                            nits=False,\n",
        "                            malformed_operators=False,\n",
        "                            basic_latex=True,\n",
        "                            equations=True,\n",
        "                            boxed=\"all\",\n",
        "                            units=True,\n",
        "                        ),\n",
        "                        # Ensures that boxed is tried first\n",
        "                        boxed_match_priority=0,\n",
        "                        try_extract_without_anchor=False,\n",
        "                    )\n",
        "                ],\n",
        "                extraction_mode=\"first_match\",\n",
        "            )\n",
        "            # Reward 1 if the content is the same as the ground truth, 0 otherwise\n",
        "            reward = float(verify(answer_parsed, gold_parsed))\n",
        "            # print('\\nprompt:', prompt)\n",
        "            print(\"-\" * 100)\n",
        "            print(\n",
        "                \"\\nanswer_parsed:\",\n",
        "                answer_parsed,\n",
        "                \"\\ngold_parsed:\",\n",
        "                gold_parsed,\n",
        "                \"\\nreward:\",\n",
        "                reward,\n",
        "            )\n",
        "        else:\n",
        "            reward = 7.0\n",
        "            print(\"Failed to parse gold solution: \", sol)\n",
        "        rewards.append(reward)\n",
        "\n",
        "    print(\"\\naccuracy rewards:\", rewards)\n",
        "\n",
        "    return rewards\n",
        "\n",
        "\n",
        "\n",
        "def format_reward(completions, **kwargs):\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"^<think>.*?</think><answer>.*?</answer>$\"\n",
        "    completion_contents = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [re.match(pattern, content) for content in completion_contents]\n",
        "\n",
        "    rewards = [5.0 if match else 0.0 for match in matches]\n",
        "    print(\"-\" * 100)\n",
        "    print(\"\\nformat rewards:\", rewards)\n",
        "    return rewards\n",
        "\n",
        "\n",
        "def reasoning_steps_reward(completions, **kwargs):\n",
        "    \"\"\"Reward function that checks for clear step-by-step reasoning.\n",
        "    Regex pattern:\n",
        "        Step \\d+: - matches \"Step 1:\", \"Step 2:\", etc.\n",
        "        ^\\d+\\. - matches numbered lists like \"1.\", \"2.\", etc. at start of line\n",
        "        \\n- - matches bullet points with hyphens\n",
        "        \\n\\* - matches bullet points with asterisks\n",
        "        First,|Second,|Next,|Finally, - matches transition words\n",
        "    \"\"\"\n",
        "    pattern = r\"(Step \\d+:|^\\d+\\.|\\n-|\\n\\*|First,|Second,|Next,|Finally,)\"\n",
        "    completion_contents = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [len(re.findall(pattern, content)) for content in completion_contents]\n",
        "\n",
        "    # Magic nubmer 3 to encourage 3 steps and more, otherwise partial reward\n",
        "    return [min(6.0, count / 3) for count in matches]\n",
        "\n",
        "\n",
        "REWARD_FUNCS_REGISTRY = {\n",
        "    \"accuracy\": accuracy_reward,\n",
        "    \"format\": format_reward,\n",
        "    \"reasoning_steps\": reasoning_steps_reward,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "q-os0NYmhmP1"
      },
      "outputs": [],
      "source": [
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "l1b8IlQxmYS1"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class GRPOScriptArguments(ScriptArguments):\n",
        "    reward_funcs: list[str] = field(\n",
        "        default_factory=lambda: [\"accuracy\", \"format\", \"reasoning_steps\"],\n",
        "        metadata={\n",
        "            \"help\": f\"List of reward functions. Possible values: {', '.join(REWARD_FUNCS_REGISTRY.keys())}\"\n",
        "        },\n",
        "    )\n",
        "\n",
        "\n",
        "SYSTEM_PROMPT = (\n",
        "    \"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant \"\n",
        "    \"first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning \"\n",
        "    \"process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., \"\n",
        "    \"<think> reasoning process here </think><answer> answer here </answer>\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "AIgFJH5Omegn"
      },
      "outputs": [],
      "source": [
        "def main(script_args, training_args, model_args):\n",
        "    # Set seed for reproducibility\n",
        "    set_seed(training_args.seed)\n",
        "\n",
        "    ###############\n",
        "    # Setup logging\n",
        "    ###############\n",
        "    logging.basicConfig(\n",
        "        format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
        "        datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
        "        handlers=[logging.StreamHandler(sys.stdout)],\n",
        "    )\n",
        "    log_level = training_args.get_process_log_level()\n",
        "    logger.setLevel(log_level)\n",
        "    datasets.utils.logging.set_verbosity(log_level)\n",
        "    transformers.utils.logging.set_verbosity(log_level)\n",
        "    transformers.utils.logging.enable_default_handler()\n",
        "    transformers.utils.logging.enable_explicit_format()\n",
        "\n",
        "    # Log on each process a small summary\n",
        "    logger.warning(\n",
        "        f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"\n",
        "        + f\" distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"\n",
        "    )\n",
        "    logger.info(f\"Model parameters {model_args}\")\n",
        "    logger.info(f\"Script parameters {script_args}\")\n",
        "    logger.info(f\"Data parameters {training_args}\")\n",
        "\n",
        "    # Check for last checkpoint\n",
        "    last_checkpoint = None\n",
        "    if os.path.isdir(training_args.output_dir):\n",
        "        last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
        "    if last_checkpoint is not None and training_args.resume_from_checkpoint is None:\n",
        "        logger.info(f\"Checkpoint detected, resuming training at {last_checkpoint=}.\")\n",
        "\n",
        "    # Load the dataset\n",
        "    dataset = load_dataset(script_args.dataset_name, name=script_args.dataset_config)\n",
        "\n",
        "    # Get reward functions\n",
        "    reward_funcs = [REWARD_FUNCS_REGISTRY[func] for func in script_args.reward_funcs]\n",
        "\n",
        "\n",
        "    # Format into conversation\n",
        "    def make_conversation(example):\n",
        "        return {\n",
        "            \"prompt\": [\n",
        "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                {\"role\": \"user\", \"content\": example[\"problem\"]},\n",
        "            ],\n",
        "        }\n",
        "\n",
        "    dataset = dataset.map(make_conversation)\n",
        "    for split in dataset:\n",
        "        if \"messages\" in dataset[split].column_names:\n",
        "            dataset[split] = dataset[split].remove_columns(\"messages\")\n",
        "\n",
        "    logger.info(\"*** Initializing model kwargs ***\")\n",
        "    torch_dtype = (\n",
        "        model_args.torch_dtype\n",
        "        if model_args.torch_dtype in [\"auto\", None]\n",
        "        else getattr(torch, model_args.torch_dtype)\n",
        "    )\n",
        "\n",
        "    training_args.gradient_checkpointing = True\n",
        "    model_kwargs = dict(\n",
        "        revision=model_args.model_revision,\n",
        "        trust_remote_code=model_args.trust_remote_code,\n",
        "        attn_implementation=model_args.attn_implementation,\n",
        "        torch_dtype=torch_dtype,\n",
        "        use_cache=False if training_args.gradient_checkpointing else True,\n",
        "    )\n",
        "\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        model_args.model_name_or_path, load_in_4bit=False, **model_kwargs\n",
        "    )\n",
        "\n",
        "    print(\n",
        "        model_args.model_name_or_path,\n",
        "    )\n",
        "    #############################\n",
        "    # Initialize the GRPO trainer\n",
        "    #############################\n",
        "    trainer = GRPOTrainer(\n",
        "        # model=model_args.model_name_or_path,\n",
        "        model=model,\n",
        "        reward_funcs=reward_funcs,\n",
        "        args=training_args,\n",
        "        train_dataset=dataset[script_args.dataset_train_split],\n",
        "        eval_dataset=(\n",
        "            dataset[script_args.dataset_test_split]\n",
        "            if training_args.eval_strategy != \"no\"\n",
        "            else None\n",
        "        ),\n",
        "        callbacks=get_callbacks(training_args, model_args),\n",
        "    )\n",
        "\n",
        "    ###############\n",
        "    # Training loop\n",
        "    ###############\n",
        "    logger.info(\"*** Train ***\")\n",
        "    checkpoint = None\n",
        "    if training_args.resume_from_checkpoint is not None:\n",
        "        checkpoint = training_args.resume_from_checkpoint\n",
        "    elif last_checkpoint is not None:\n",
        "        checkpoint = last_checkpoint\n",
        "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
        "    metrics = train_result.metrics\n",
        "    metrics[\"train_samples\"] = len(dataset[script_args.dataset_train_split])\n",
        "    trainer.log_metrics(\"train\", metrics)\n",
        "    trainer.save_metrics(\"train\", metrics)\n",
        "    trainer.save_state()\n",
        "\n",
        "    ##################################\n",
        "    # Save model and create model card\n",
        "    ##################################\n",
        "    logger.info(\"*** Save model ***\")\n",
        "    trainer.save_model(training_args.output_dir)\n",
        "    logger.info(f\"Model saved to {training_args.output_dir}\")\n",
        "\n",
        "    # Save everything else on main process\n",
        "    kwargs = {\n",
        "        \"dataset_name\": script_args.dataset_name,\n",
        "        \"tags\": [\"OvO-R1\"],\n",
        "    }\n",
        "    if trainer.accelerator.is_main_process:\n",
        "        trainer.create_model_card(**kwargs)\n",
        "        # Restore k,v cache for fast inference\n",
        "        trainer.model.config.use_cache = True\n",
        "        trainer.model.config.save_pretrained(training_args.output_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GKC3z82fmlem"
      },
      "outputs": [],
      "source": [
        "sys.argv = [\n",
        "    \"notebook\",  # sys.argv[0] is the script name in a real execution\n",
        "    \"--model_name_or_path\", \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
        "    \"--model_revision\", \"main\",\n",
        "    \"--torch_dtype\", \"bfloat16\",\n",
        "    \"--attn_implementation\", \"flash_attention_2\",\n",
        "\n",
        "    \"--dataset_name\", \"xiaodongguaAIGC/X-R1-750\",\n",
        "    #\"--dataset_configs\", \"train\",\n",
        "    #\"--num_processes\", \"3\",\n",
        "\n",
        "    \"--bf16\", \"true\",\n",
        "    \"--use_vllm\", \"false\",\n",
        "    #\"--vllm_device\", \"auto\",\n",
        "    #\"--vllm_gpu_memory_utilization\", \"0.7\",\n",
        "    \"--do_eval\", \"false\",\n",
        "    \"--eval_strategy\", \"no\",\n",
        "    \"--eval_steps\", \"5\",\n",
        "    \"--gradient_accumulation_steps\", \"4\",\n",
        "    \"--gradient_checkpointing\", \"true\",\n",
        "    \"--gradient_checkpointing_kwargs\", '{\"use_reentrant\": false}',\n",
        "    \"--hub_strategy\", \"every_save\",\n",
        "    \"--learning_rate\", \"3.0e-06\",\n",
        "    \"--log_level\", \"info\",\n",
        "    \"--logging_steps\", \"5\",\n",
        "    \"--logging_strategy\", \"steps\",\n",
        "    \"--lr_scheduler_type\", \"cosine\",\n",
        "    \"--max_prompt_length\", \"256\",\n",
        "    \"--num_generations\", \"4\",\n",
        "    \"--max_completion_length\", \"1024\",\n",
        "    \"--max_steps\", \"-1\",\n",
        "    \"--num_train_epochs\", \"3\",\n",
        "    \"--output_dir\", \"output/OvO-R1_instruct\",\n",
        "    \"--overwrite_output_dir\", \"true\",\n",
        "    \"--per_device_eval_batch_size\", \"1\",\n",
        "    \"--per_device_train_batch_size\", \"2\",\n",
        "    \"--push_to_hub\", \"false\",\n",
        "    \"--report_to\", \"wandb\",\n",
        "    \"--save_strategy\", \"epoch\",\n",
        "    \"--seed\", \"42\",\n",
        "    \"--warmup_ratio\", \"0.1\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.multiprocessing as mp\n",
        "mp.set_start_method('spawn', force=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AoymiaP6mkX6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-02-16 17:59:18 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 2 distributed training: True, 16-bits training: False\n",
            "2025-02-16 17:59:18 - INFO - __main__ - Model parameters ModelConfig(model_name_or_path='Qwen/Qwen2.5-0.5B-Instruct', model_revision='main', torch_dtype='bfloat16', trust_remote_code=False, attn_implementation='flash_attention_2', use_peft=False, lora_r=16, lora_alpha=32, lora_dropout=0.05, lora_target_modules=None, lora_modules_to_save=None, lora_task_type='CAUSAL_LM', use_rslora=False, load_in_8bit=False, load_in_4bit=False, bnb_4bit_quant_type='nf4', use_bnb_nested_quant=False)\n",
            "2025-02-16 17:59:18 - INFO - __main__ - Script parameters GRPOScriptArguments(dataset_name='xiaodongguaAIGC/X-R1-750', dataset_config=None, dataset_train_split='train', dataset_test_split='test', gradient_checkpointing_use_reentrant=False, ignore_bias_buffers=False, reward_funcs=['accuracy', 'format', 'reasoning_steps'])\n",
            "2025-02-16 17:59:18 - INFO - __main__ - Data parameters GRPOConfig(\n",
            "_n_gpu=2,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "benchmarks=[],\n",
            "beta=0.04,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "callbacks=[],\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=5.0,\n",
            "eval_strategy=no,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=None,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=4,\n",
            "gradient_checkpointing=True,\n",
            "gradient_checkpointing_kwargs={'use_reentrant': False},\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_model_revision=main,\n",
            "hub_private_repo=None,\n",
            "hub_strategy=every_save,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=3e-06,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=info,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=output/OvO-R1_instruct/runs/Feb16_17-59-18_siai-4,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=5,\n",
            "logging_strategy=steps,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=cosine,\n",
            "max_completion_length=1024,\n",
            "max_grad_norm=1.0,\n",
            "max_prompt_length=256,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "model_init_kwargs=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_generations=4,\n",
            "num_train_epochs=3.0,\n",
            "optim=adamw_torch,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=output/OvO-R1_instruct,\n",
            "overwrite_hub_revision=False,\n",
            "overwrite_output_dir=True,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=1,\n",
            "per_device_train_batch_size=2,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_revision=False,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=False,\n",
            "report_to=['wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=output/OvO-R1_instruct,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=epoch,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "system_prompt=None,\n",
            "temperature=0.9,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "use_vllm=False,\n",
            "vllm_device=auto,\n",
            "vllm_gpu_memory_utilization=0.9,\n",
            "warmup_ratio=0.1,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Overwrite dataset info from restored data version if exists.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-02-16 17:59:19 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading Dataset info from /home/siai/.cache/huggingface/datasets/xiaodongguaAIGC___x-r1-750/default/0.0.0/1a2e75b1147e199697374f5decea05e3b13d42ec\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-02-16 17:59:19 - INFO - datasets.info - Loading Dataset info from /home/siai/.cache/huggingface/datasets/xiaodongguaAIGC___x-r1-750/default/0.0.0/1a2e75b1147e199697374f5decea05e3b13d42ec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset x-r1-750 (/home/siai/.cache/huggingface/datasets/xiaodongguaAIGC___x-r1-750/default/0.0.0/1a2e75b1147e199697374f5decea05e3b13d42ec)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-02-16 17:59:19 - INFO - datasets.builder - Found cached dataset x-r1-750 (/home/siai/.cache/huggingface/datasets/xiaodongguaAIGC___x-r1-750/default/0.0.0/1a2e75b1147e199697374f5decea05e3b13d42ec)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading Dataset info from /home/siai/.cache/huggingface/datasets/xiaodongguaAIGC___x-r1-750/default/0.0.0/1a2e75b1147e199697374f5decea05e3b13d42ec\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-02-16 17:59:19 - INFO - datasets.info - Loading Dataset info from /home/siai/.cache/huggingface/datasets/xiaodongguaAIGC___x-r1-750/default/0.0.0/1a2e75b1147e199697374f5decea05e3b13d42ec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /home/siai/.cache/huggingface/datasets/xiaodongguaAIGC___x-r1-750/default/0.0.0/1a2e75b1147e199697374f5decea05e3b13d42ec/cache-ccbf56eb47acd183.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-02-16 17:59:19 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/siai/.cache/huggingface/datasets/xiaodongguaAIGC___x-r1-750/default/0.0.0/1a2e75b1147e199697374f5decea05e3b13d42ec/cache-ccbf56eb47acd183.arrow\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /home/siai/.cache/huggingface/datasets/xiaodongguaAIGC___x-r1-750/default/0.0.0/1a2e75b1147e199697374f5decea05e3b13d42ec/cache-159553dc8712ce84.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-02-16 17:59:19 - INFO - datasets.arrow_dataset - Loading cached processed dataset at /home/siai/.cache/huggingface/datasets/xiaodongguaAIGC___x-r1-750/default/0.0.0/1a2e75b1147e199697374f5decea05e3b13d42ec/cache-159553dc8712ce84.arrow\n",
            "2025-02-16 17:59:19 - INFO - __main__ - *** Initializing model kwargs ***\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO|configuration_utils.py:696] 2025-02-16 17:59:19,305 >> loading configuration file config.json from cache at /home/siai/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/config.json\n",
            "[INFO|configuration_utils.py:768] 2025-02-16 17:59:19,308 >> Model config Qwen2Config {\n",
            "  \"_name_or_path\": \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
            "  \"architectures\": [\n",
            "    \"Qwen2ForCausalLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 896,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4864,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 21,\n",
            "  \"model_type\": \"qwen2\",\n",
            "  \"num_attention_heads\": 14,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": null,\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": null,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.48.3\",\n",
            "  \"use_cache\": false,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:3904] 2025-02-16 17:59:19,345 >> loading weights file model.safetensors from cache at /home/siai/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/model.safetensors\n",
            "[INFO|modeling_utils.py:1582] 2025-02-16 17:59:19,354 >> Instantiating Qwen2ForCausalLM model under default dtype torch.bfloat16.\n",
            "[WARNING|logging.py:328] 2025-02-16 17:59:19,357 >> You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
            "[INFO|configuration_utils.py:1140] 2025-02-16 17:59:19,359 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"use_cache\": false\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:4888] 2025-02-16 17:59:19,400 >> All model checkpoint weights were used when initializing Qwen2ForCausalLM.\n",
            "\n",
            "[INFO|modeling_utils.py:4896] 2025-02-16 17:59:19,400 >> All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen2.5-0.5B-Instruct.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.\n",
            "[INFO|configuration_utils.py:1095] 2025-02-16 17:59:19,484 >> loading configuration file generation_config.json from cache at /home/siai/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/generation_config.json\n",
            "[INFO|configuration_utils.py:1140] 2025-02-16 17:59:19,485 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": [\n",
            "    151645,\n",
            "    151643\n",
            "  ],\n",
            "  \"pad_token_id\": 151643,\n",
            "  \"repetition_penalty\": 1.1,\n",
            "  \"temperature\": 0.7,\n",
            "  \"top_k\": 20,\n",
            "  \"top_p\": 0.8\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-02-16 17:59:19,586 >> loading file vocab.json from cache at /home/siai/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-02-16 17:59:19,586 >> loading file merges.txt from cache at /home/siai/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-02-16 17:59:19,586 >> loading file tokenizer.json from cache at /home/siai/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-02-16 17:59:19,587 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-02-16 17:59:19,587 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-02-16 17:59:19,587 >> loading file tokenizer_config.json from cache at /home/siai/.cache/huggingface/hub/models--Qwen--Qwen2.5-0.5B-Instruct/snapshots/7ae557604adf67be50417f59c2c2f167def9a775/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2034] 2025-02-16 17:59:19,587 >> loading file chat_template.jinja from cache at None\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Qwen/Qwen2.5-0.5B-Instruct\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO|tokenization_utils_base.py:2304] 2025-02-16 17:59:19,789 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "[INFO|trainer.py:741] 2025-02-16 17:59:19,976 >> Using auto half precision backend\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-02-16 17:59:20 - INFO - __main__ - *** Train ***\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO|trainer.py:2369] 2025-02-16 17:59:20,341 >> ***** Running training *****\n",
            "[INFO|trainer.py:2370] 2025-02-16 17:59:20,342 >>   Num examples = 750\n",
            "[INFO|trainer.py:2371] 2025-02-16 17:59:20,342 >>   Num Epochs = 3\n",
            "[INFO|trainer.py:2372] 2025-02-16 17:59:20,342 >>   Instantaneous batch size per device = 2\n",
            "[INFO|trainer.py:2374] 2025-02-16 17:59:20,343 >>   Training with DataParallel so batch size has been adjusted to: 4\n",
            "[INFO|trainer.py:2375] 2025-02-16 17:59:20,343 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "[INFO|trainer.py:2376] 2025-02-16 17:59:20,344 >>   Gradient Accumulation steps = 4\n",
            "[INFO|trainer.py:2377] 2025-02-16 17:59:20,344 >>   Total optimization steps = 141\n",
            "[INFO|trainer.py:2378] 2025-02-16 17:59:20,345 >>   Number of trainable parameters = 494,032,768\n",
            "[INFO|integration_utils.py:817] 2025-02-16 17:59:20,347 >> Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbalaji-vir1997\u001b[0m (\u001b[33mbalaji-vir1997-stevens-institute-of-technology\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.5"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/home/siai/NeSy_T/wandb/run-20250216_175920-46oaaxbh</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/balaji-vir1997-stevens-institute-of-technology/huggingface/runs/46oaaxbh' target=\"_blank\">output/OvO-R1_instruct</a></strong> to <a href='https://wandb.ai/balaji-vir1997-stevens-institute-of-technology/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/balaji-vir1997-stevens-institute-of-technology/huggingface' target=\"_blank\">https://wandb.ai/balaji-vir1997-stevens-institute-of-technology/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/balaji-vir1997-stevens-institute-of-technology/huggingface/runs/46oaaxbh' target=\"_blank\">https://wandb.ai/balaji-vir1997-stevens-institute-of-technology/huggingface/runs/46oaaxbh</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[WARNING|logging.py:328] 2025-02-16 17:59:21,426 >> `use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [5, '5'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [5, '5'] \n",
            "gold_parsed: [5, '5'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [5, '5'] \n",
            "gold_parsed: [5, '5'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [5, '5'] \n",
            "gold_parsed: [5, '5'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [{6, 8*,;*10}, '6, 8\\\\text{, ; }10'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [{6, 8*,;*10}, '6, 8\\\\text{, ; }10'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [{11, 12, 16, 22, 44, 99}, '12, 99, 44, 22, 16, 11'] \n",
            "gold_parsed: [{6, 8*,;*10}, '6, 8\\\\text{, ; }10'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [40, '40'] \n",
            "gold_parsed: [{6, 8*,;*10}, '6, 8\\\\text{, ; }10'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2/3, '\\\\frac{2}{3}'] \n",
            "gold_parsed: [2/3, '\\\\frac{2}{3}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3*c**2/8, '\\\\frac{3}{8}c^2'] \n",
            "gold_parsed: [2/3, '\\\\frac{2}{3}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2/3, '\\\\frac{2}{3}'] \n",
            "gold_parsed: [2/3, '\\\\frac{2}{3}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/a, '\\\\frac{1}{a}'] \n",
            "gold_parsed: [2/3, '\\\\frac{2}{3}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [5, '5'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [5, '5'] \n",
            "gold_parsed: [5, '5'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-2, '-2'] \n",
            "gold_parsed: [5, '5'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [19, '19'] \n",
            "gold_parsed: [5, '5'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-1, '-1'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [49, '49'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [49, '49'] \n",
            "gold_parsed: [49, '49'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [49, '49'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [49, '49'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [4/3, '\\\\frac{4}{3}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4/3, '\\\\frac{4}{3}'] \n",
            "gold_parsed: [4/3, '\\\\frac{4}{3}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [4/3, '\\\\frac{4}{3}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [4/3, '\\\\frac{4}{3}'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2880, '2880'] \n",
            "gold_parsed: [720, '720'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [324, '324'] \n",
            "gold_parsed: [720, '720'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [720, '720'] \n",
            "gold_parsed: [720, '720'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [720, '720'] \n",
            "gold_parsed: [720, '720'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [30, '30'] \n",
            "gold_parsed: [30, '30'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [61, '61'] \n",
            "gold_parsed: [30, '30'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [60, '60'] \n",
            "gold_parsed: [30, '30'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [30, '30'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [14, '14'] \n",
            "gold_parsed: [18, '18'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [18, '18'] \n",
            "gold_parsed: [18, '18'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [18, '18'] \n",
            "gold_parsed: [18, '18'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [20, '20'] \n",
            "gold_parsed: [18, '18'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/9, '\\\\frac{1}{9}'] \n",
            "gold_parsed: [1/9, '\\\\frac{1}{9}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/4, '\\\\frac{1}{4}'] \n",
            "gold_parsed: [1/9, '\\\\frac{1}{9}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [1/9, '\\\\frac{1}{9}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0.500000000000000, '0.5'] \n",
            "gold_parsed: [1/9, '\\\\frac{1}{9}'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4, '4'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [sqrt(5), '\\\\sqrt{5}'] \n",
            "gold_parsed: [sqrt(5), '\\\\sqrt{5}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [sqrt(5), '\\\\sqrt{5}'] \n",
            "gold_parsed: [sqrt(5), '\\\\sqrt{5}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [sqrt(5), '\\\\sqrt{5}'] \n",
            "gold_parsed: [sqrt(5), '\\\\sqrt{5}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [sqrt(5), '\\\\sqrt{5}'] \n",
            "gold_parsed: [sqrt(5), '\\\\sqrt{5}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [15, '15'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4, '4'] \n",
            "gold_parsed: [15, '15'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [x, 'x'] \n",
            "gold_parsed: [15, '15'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-7, '-7'] \n",
            "gold_parsed: [15, '15'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [2, '2'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [2, '2'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [2, '2'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1262, '1262'] \n",
            "gold_parsed: [2, '2'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='9' max='141' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  9/141 57:39 < 18:07:15, 0.00 it/s, Epoch 0.17/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [144/5, '\\\\frac{144}{5}'] \n",
            "gold_parsed: [144/5, '\\\\frac{144}{5}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [144/5, '\\\\frac{144}{5}'] \n",
            "gold_parsed: [144/5, '\\\\frac{144}{5}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [144/5, '\\\\frac{144}{5}'] \n",
            "gold_parsed: [144/5, '\\\\frac{144}{5}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [144/5, '\\\\frac{144}{5}'] \n",
            "gold_parsed: [144/5, '\\\\frac{144}{5}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [7/5, '\\\\frac{7}{5}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [7/5, '\\\\frac{7}{5}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [7/5, '\\\\frac{7}{5}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [7/5, '\\\\frac{7}{5}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [4, '4'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4, '4'] \n",
            "gold_parsed: [4, '4'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [4, '4'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [4, '4'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [500, '500'] \n",
            "gold_parsed: [50000, '50000'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [50000, '50000'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [5000, '5000'] \n",
            "gold_parsed: [50000, '50000'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Income, '\\\\text{Income}'] \n",
            "gold_parsed: [50000, '50000'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [6, '6'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [9, '9'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [11, '11'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1022, '1022'] \n",
            "gold_parsed: [514, '514'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [514, '514'] \n",
            "gold_parsed: [514, '514'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [173738, '173738'] \n",
            "gold_parsed: [514, '514'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [514, '514'] \n",
            "gold_parsed: [514, '514'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [857, '857'] \n",
            "gold_parsed: [271, '271'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [247, '247'] \n",
            "gold_parsed: [271, '271'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [271, '271'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2295, '2295'] \n",
            "gold_parsed: [271, '271'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-67, '-67'] \n",
            "gold_parsed: [-112, '-112'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-118, '-118'] \n",
            "gold_parsed: [-112, '-112'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-112, '-112'] \n",
            "gold_parsed: [-112, '-112'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-2, '-2'] \n",
            "gold_parsed: [-112, '-112'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4, '4'] \n",
            "gold_parsed: [12, '12'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [12, '12'] \n",
            "gold_parsed: [12, '12'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [14, '14'] \n",
            "gold_parsed: [12, '12'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [12, '12'] \n",
            "gold_parsed: [12, '12'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-3/2, '-\\\\frac{3}{2}'] \n",
            "gold_parsed: [-3/2, '- \\\\frac{3}{2}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-3/2, '-\\\\frac{3}{2}'] \n",
            "gold_parsed: [-3/2, '- \\\\frac{3}{2}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [-3/2, '- \\\\frac{3}{2}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-53/6, '-\\\\frac{53}{6}'] \n",
            "gold_parsed: [-3/2, '- \\\\frac{3}{2}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [192, '192'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [192, '192'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [192, '192'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4, '4'] \n",
            "gold_parsed: [192, '192'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [48480, '48480'] \n",
            "gold_parsed: [48480, '48480'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [48480, '48480'] \n",
            "gold_parsed: [48480, '48480'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [48480, '48480'] \n",
            "gold_parsed: [48480, '48480'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [48480, '48480'] \n",
            "gold_parsed: [48480, '48480'] \n",
            "reward: 1.0\n",
            "\n",
            "accuracy rewards: [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [7/3, '\\\\frac{7}{3}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [5, '5'] \n",
            "gold_parsed: [7/3, '\\\\frac{7}{3}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [7/3, '\\\\frac{7}{3}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [7/3, '\\\\frac{7}{3}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [4/3, '\\\\frac{4}{3}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [9, '9'] \n",
            "gold_parsed: [4/3, '\\\\frac{4}{3}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4/3, '\\\\frac{4}{3}'] \n",
            "gold_parsed: [4/3, '\\\\frac{4}{3}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [4/3, '\\\\frac{4}{3}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [A, 'A'] \n",
            "gold_parsed: [5, '5'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [5, '5'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [5, '5'] \n",
            "gold_parsed: [5, '5'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [5, '5'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4, '4'] \n",
            "gold_parsed: [22, '22'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [18, '18'] \n",
            "gold_parsed: [22, '22'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [22, '22'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [6, '6'] \n",
            "gold_parsed: [22, '22'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [-1*29*x**5*(7*x**6 - 2), '-29x^5(7x^6-2)'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [-1*29*x**5*(7*x**6 - 2), '-29x^5(7x^6-2)'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [-1*29*x**5*(7*x**6 - 2), '-29x^5(7x^6-2)'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [-1*29*x**5*(7*x**6 - 2), '-29x^5(7x^6-2)'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [296, '296'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [296, '296'] \n",
            "gold_parsed: [296, '296'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [840, '840'] \n",
            "gold_parsed: [296, '296'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1576/9, '\\\\frac{1576}{9}'] \n",
            "gold_parsed: [296, '296'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [65, '65'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: ['135 ;'] \n",
            "gold_parsed: [65, '65'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [65, '65'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [65, '65'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [8/9, '\\\\frac{8}{9}'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3/2, '\\\\frac{3}{2}'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-3, '-3'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Interval(0, 25), '[0, 25]'] \n",
            "gold_parsed: [Interval(0, 25), '[0, 25]'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [5, '5'] \n",
            "gold_parsed: [Interval(0, 25), '[0, 25]'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Interval(0, 625), '[0, 625]'] \n",
            "gold_parsed: [Interval(0, 25), '[0, 25]'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Interval(0, 25), '[0, 25]'] \n",
            "gold_parsed: [Interval(0, 25), '[0, 25]'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [100, '100'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [100, '100'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [100, '100'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [100, '100'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Interval.open(1, oo), '(1, \\\\infty)'] \n",
            "gold_parsed: [Interval(1, oo), '[1,\\\\infty)'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Interval(1, oo), '[1, \\\\infty)'] \n",
            "gold_parsed: [Interval(1, oo), '[1,\\\\infty)'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Interval(1, oo), '[1, \\\\infty)'] \n",
            "gold_parsed: [Interval(1, oo), '[1,\\\\infty)'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Interval.Lopen(0, 1), '(0, 1]'] \n",
            "gold_parsed: [Interval(1, oo), '[1,\\\\infty)'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [12.1800000000000, '12.18'] \n",
            "gold_parsed: [11.2500000000000, '11.25'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [135, '135'] \n",
            "gold_parsed: [11.2500000000000, '11.25'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [11.2500000000000, '11.25'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [45, '45'] \n",
            "gold_parsed: [11.2500000000000, '11.25'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [sqrt(27), '\\\\sqrt{27}'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [sqrt(12*sqrt(3) + 108), '\\\\sqrt{108 + 12\\\\sqrt{3}}'] \n",
            "gold_parsed: [15, '15'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [15, '15'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [sqrt(193), '\\\\sqrt{193}'] \n",
            "gold_parsed: [15, '15'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [15, '15'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [6, '6'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [6, '6'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [6, '6'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [6, '6'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [6, '6'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [6, '6'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [5, '5'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-8, '-8'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [18*x**3 + 8*x**2, '18x^3 + 8x^2'] \n",
            "gold_parsed: [18*x**3 + 8*x**2, '18x^3+8x^2'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [18*x**3 + 8*x**2, '18x^3+8x^2'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [18*x**3 + 8*x**2, '18x^3 + 8x^2'] \n",
            "gold_parsed: [18*x**3 + 8*x**2, '18x^3+8x^2'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [18*x**3 + 8*x**2, '18x^3+8x^2'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [1, '1'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-1, '-1'] \n",
            "gold_parsed: [1, '1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [1, '1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [1, '1'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [-3, '-3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-1, '-1'] \n",
            "gold_parsed: [-3, '-3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [10, '10'] \n",
            "gold_parsed: [-3, '-3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [-3, '-3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [22, '22'] \n",
            "gold_parsed: [22, '22'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [19, '19'] \n",
            "gold_parsed: [22, '22'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Eq(f*f*f(2), 64), 'f(f(f(2))) = 64'] \n",
            "gold_parsed: [22, '22'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [22, '22'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-4400, '-4400'] \n",
            "gold_parsed: [-400, '-400'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [-400, '-400'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [-400, '-400'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-100, '-100'] \n",
            "gold_parsed: [-400, '-400'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [90, '90'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [90, '90'] \n",
            "gold_parsed: [90, '90'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [90, '90'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [90, '90'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [48, '48'] \n",
            "gold_parsed: [48, '48'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [48, '48'] \n",
            "gold_parsed: [48, '48'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [48, '48'] \n",
            "gold_parsed: [48, '48'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [48, '48'] \n",
            "gold_parsed: [48, '48'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [26/3, '\\\\frac{26}{3}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [26/3, '\\\\frac{26}{3}'] \n",
            "gold_parsed: [26/3, '\\\\frac{26}{3}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [26/3, '\\\\frac{26}{3}'] \n",
            "gold_parsed: [26/3, '\\\\frac{26}{3}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [26/3, '\\\\frac{26}{3}'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [210*sqrt(7)*x, '210x\\\\sqrt{7}'] \n",
            "gold_parsed: [10*x*sqrt(21*x), '10x \\\\sqrt{21x}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [10*sqrt(7)*x**(3/2), '10\\\\sqrt{7}x^{3/2}'] \n",
            "gold_parsed: [10*x*sqrt(21*x), '10x \\\\sqrt{21x}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [10*sqrt(21*x**3), '10\\\\sqrt{21x^3}'] \n",
            "gold_parsed: [10*x*sqrt(21*x), '10x \\\\sqrt{21x}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [30*sqrt(x**3), '30\\\\sqrt{x^3}'] \n",
            "gold_parsed: [10*x*sqrt(21*x), '10x \\\\sqrt{21x}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4, '4'] \n",
            "gold_parsed: [12, '12'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [9, '9'] \n",
            "gold_parsed: [12, '12'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [833.340000000000, '833.34'] \n",
            "gold_parsed: [12, '12'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0.180000000000000, '0.18'] \n",
            "gold_parsed: [12, '12'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [96, '96'] \n",
            "gold_parsed: [39, '39'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [39, '39'] \n",
            "gold_parsed: [39, '39'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [23, '23'] \n",
            "gold_parsed: [39, '39'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [39, '39'] \n",
            "gold_parsed: [39, '39'] \n",
            "reward: 1.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [36/49, '\\\\frac{36}{49}'] \n",
            "gold_parsed: [36/49, '\\\\frac{36}{49}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [36/49, '\\\\frac{36}{49}'] \n",
            "gold_parsed: [36/49, '\\\\frac{36}{49}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [11/15, '\\\\frac{11}{15}'] \n",
            "gold_parsed: [36/49, '\\\\frac{36}{49}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [8, '8'] \n",
            "gold_parsed: [36/49, '\\\\frac{36}{49}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [25, '25'] \n",
            "gold_parsed: [10, '10'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [10, '10'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [15, '15'] \n",
            "gold_parsed: [10, '10'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [6, '6'] \n",
            "gold_parsed: [10, '10'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [31/32, '\\\\frac{31}{32}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/32, '\\\\frac{1}{32}'] \n",
            "gold_parsed: [31/32, '\\\\frac{31}{32}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/32, '\\\\frac{1}{32}'] \n",
            "gold_parsed: [31/32, '\\\\frac{31}{32}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "gold_parsed: [31/32, '\\\\frac{31}{32}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [13/4, '\\\\frac{13}{4}'] \n",
            "gold_parsed: [13/4, '\\\\frac{13}{4}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/5, '\\\\frac{1}{5}'] \n",
            "gold_parsed: [13/4, '\\\\frac{13}{4}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [13/4, '\\\\frac{13}{4}'] \n",
            "gold_parsed: [13/4, '\\\\frac{13}{4}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [13/4, '\\\\frac{13}{4}'] \n",
            "gold_parsed: [13/4, '\\\\frac{13}{4}'] \n",
            "reward: 1.0\n",
            "\n",
            "accuracy rewards: [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [14, '14'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [22, '22'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [6, '6'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [400, '400'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [400, '400'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [400, '400'] \n",
            "gold_parsed: [400, '400'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [400, '400'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [70/9, '\\\\frac{70}{9}'] \n",
            "gold_parsed: [70/9, '\\\\frac{70}{9}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [70/9, '\\\\frac{70}{9}'] \n",
            "gold_parsed: [70/9, '\\\\frac{70}{9}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [70/9, '\\\\frac{70}{9}'] \n",
            "gold_parsed: [70/9, '\\\\frac{70}{9}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-14/3, '-\\\\frac{14}{3}'] \n",
            "gold_parsed: [70/9, '\\\\frac{70}{9}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [17, '17'] \n",
            "gold_parsed: [17, '17'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [17, '17'] \n",
            "gold_parsed: [17, '17'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [16, '16'] \n",
            "gold_parsed: [17, '17'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [59, '59'] \n",
            "gold_parsed: [17, '17'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Nosolution, '\\\\text{No solution}'] \n",
            "gold_parsed: [-1, '-1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-1/3, '-\\\\frac{1}{3}'] \n",
            "gold_parsed: [-1, '-1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [-1, '-1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [-1, '-1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [10, '10'] \n",
            "gold_parsed: [10, '10'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [10, '10'] \n",
            "gold_parsed: [10, '10'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [10, '10'] \n",
            "gold_parsed: [10, '10'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [10, '10'] \n",
            "gold_parsed: [10, '10'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-15, '-15'] \n",
            "gold_parsed: [-15, '-15'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-15, '-15'] \n",
            "gold_parsed: [-15, '-15'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-12, '-12'] \n",
            "gold_parsed: [-15, '-15'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-12, '-12'] \n",
            "gold_parsed: [-15, '-15'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-1, '-1'] \n",
            "gold_parsed: [-1, '-1'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-6, '-6'] \n",
            "gold_parsed: [-1, '-1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-1, '-1'] \n",
            "gold_parsed: [-1, '-1'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4, '4'] \n",
            "gold_parsed: [-1, '-1'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [2/3, '\\\\frac{2}{3}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2187**6/41943040000, '\\\\frac{2187^6}{41943040000}'] \n",
            "gold_parsed: [2/3, '\\\\frac{2}{3}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [2/3, '\\\\frac{2}{3}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [729/33554432, '\\\\frac{729}{33554432}'] \n",
            "gold_parsed: [2/3, '\\\\frac{2}{3}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Union(Interval.open(3, oo), Union(Interval.open(-oo, -27), Interval.open(-27, 3))), '(-\\\\infty, -27) \\\\cup (-27, 3) \\\\cup (3, \\\\infty)'] \n",
            "gold_parsed: [Union(Interval.open(-oo, -27), Interval.open(-27, oo)), '(-\\\\infty,-27)\\\\cup(-27,\\\\infty)'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Union(Interval.open(-oo, -27), Interval.open(-27, oo)), '(-\\\\infty, -27) \\\\cup (-27, \\\\infty)'] \n",
            "gold_parsed: [Union(Interval.open(-oo, -27), Interval.open(-27, oo)), '(-\\\\infty,-27)\\\\cup(-27,\\\\infty)'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Union(Interval.open(-oo, -27), Interval.open(-27, oo)), '(-\\\\infty, -27) \\\\cup (-27, \\\\infty)'] \n",
            "gold_parsed: [Union(Interval.open(-oo, -27), Interval.open(-27, oo)), '(-\\\\infty,-27)\\\\cup(-27,\\\\infty)'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Union(Interval.open(-oo, -27), Interval.open(-27, oo)), '(-\\\\infty, -27) \\\\cup (-27, \\\\infty)'] \n",
            "gold_parsed: [Union(Interval.open(-oo, -27), Interval.open(-27, oo)), '(-\\\\infty,-27)\\\\cup(-27,\\\\infty)'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3200, '3200'] \n",
            "gold_parsed: [5600, '5600'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [5600, '5600'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [11250, '11250'] \n",
            "gold_parsed: [5600, '5600'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4800, '4800'] \n",
            "gold_parsed: [5600, '5600'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [17/6, '\\\\frac{17}{6}'] \n",
            "gold_parsed: [17/6, '\\\\frac{17}{6}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [17/6, '\\\\frac{17}{6}'] \n",
            "gold_parsed: [17/6, '\\\\frac{17}{6}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [17/6, '\\\\frac{17}{6}'] \n",
            "gold_parsed: [17/6, '\\\\frac{17}{6}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [17/6, '\\\\frac{17}{6}'] \n",
            "gold_parsed: [17/6, '\\\\frac{17}{6}'] \n",
            "reward: 1.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [75, '75'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [75, '75'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [75, '75'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [333, '333'] \n",
            "gold_parsed: [75, '75'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [192, '192'] \n",
            "gold_parsed: [32, '32'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [32, '32'] \n",
            "gold_parsed: [32, '32'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [32, '32'] \n",
            "gold_parsed: [32, '32'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [96/7, '\\\\frac{96}{7}'] \n",
            "gold_parsed: [32, '32'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4, '4'] \n",
            "gold_parsed: [4, '4'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4, '4'] \n",
            "gold_parsed: [4, '4'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4, '4'] \n",
            "gold_parsed: [4, '4'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4, '4'] \n",
            "gold_parsed: [4, '4'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: ['5 \\\\# 11'] \n",
            "gold_parsed: [71, '71'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [11, '11'] \n",
            "gold_parsed: [71, '71'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [19, '19'] \n",
            "gold_parsed: [71, '71'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: ['5 \\\\# 5 + 5'] \n",
            "gold_parsed: [71, '71'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3.90000000000000, '3.9'] \n",
            "gold_parsed: [2, '2'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "gold_parsed: [2, '2'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [20, '20'] \n",
            "gold_parsed: [2, '2'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [8, '8'] \n",
            "gold_parsed: [2, '2'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [16*x**2 + 4*x + 5, '16x^2+4x+5'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [16*x**2 + 4*x + 5, '16x^2 + 4x + 5'] \n",
            "gold_parsed: [16*x**2 + 4*x + 5, '16x^2+4x+5'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [16*x**2 + 4*x + 5, '16x^2+4x+5'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [8*x**2 + 6*x + 5, '8x^2 + 6x + 5'] \n",
            "gold_parsed: [16*x**2 + 4*x + 5, '16x^2+4x+5'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1 + sqrt(2), '1 + \\\\sqrt{2}'] \n",
            "gold_parsed: [-1, '-1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1 + sqrt(2), '1 + \\\\sqrt{2}'] \n",
            "gold_parsed: [-1, '-1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1 - sqrt(2), '1 - \\\\sqrt{2}'] \n",
            "gold_parsed: [-1, '-1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [-1, '-1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [375, '375'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [375, '375'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [123, '123'] \n",
            "gold_parsed: [375, '375'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [375, '375'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [Eq(r, 6.2), 'r=6.2'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [{16, -6 + 12.2, -2 + 10.2, -2 + 11.2, -2 + 14.2}, '12.2 - 6, 16, 14.2 - 2, 11.2 - 2, 10.2 - 2'] \n",
            "gold_parsed: [Eq(r, 6.2), 'r=6.2'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [11.2000000000000, '11.2'] \n",
            "gold_parsed: [Eq(r, 6.2), 'r=6.2'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [{6.1, 7.1, 8.1, 9.1, 10.1, 11.1, 12.1}, '6.1, 7.1, 8.1, 9.1, 10.1, 11.1, 12.1'] \n",
            "gold_parsed: [Eq(r, 6.2), 'r=6.2'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [288, '288'] \n",
            "gold_parsed: [60, '60'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [60, '60'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [60, '60'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [60, '60'] \n",
            "gold_parsed: [60, '60'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4, '4'] \n",
            "gold_parsed: [8, '8'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [6, '6'] \n",
            "gold_parsed: [8, '8'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [7, '7'] \n",
            "gold_parsed: [8, '8'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [8, '8'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-2, '-2'] \n",
            "gold_parsed: [-2, '-2'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-2, '-2'] \n",
            "gold_parsed: [-2, '-2'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-2, '-2'] \n",
            "gold_parsed: [-2, '-2'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-10/9, '-\\\\frac{10}{9}'] \n",
            "gold_parsed: [-2, '-2'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [9999, '9999'] \n",
            "gold_parsed: [9801, '9801'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [9801, '9801'] \n",
            "gold_parsed: [9801, '9801'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [9801, '9801'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [9801, '9801'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [75, '75'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [75, '75'] \n",
            "gold_parsed: [75, '75'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [25*x**8 + 225*x**5, '25x^8 + 225x^5'] \n",
            "gold_parsed: [75, '75'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [x**9, 'x^9'] \n",
            "gold_parsed: [75, '75'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-1*3*x**4 + 5*x**2 - 1*8*x, '-3x^4 + 5x^2 - 8x'] \n",
            "gold_parsed: [-1*3*x**4 + 5*x**2 - 1*8*x, '-3x^4+5x^2-8x'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-1*3*x**4 + 5*x**2 - 1*8*x, '-3x^4 + 5x^2 - 8x'] \n",
            "gold_parsed: [-1*3*x**4 + 5*x**2 - 1*8*x, '-3x^4+5x^2-8x'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-1*3*x**4 + 5*x**2 - 1*8*x + 1, '-3x^4 + 5x^2 - 8x + 1'] \n",
            "gold_parsed: [-1*3*x**4 + 5*x**2 - 1*8*x, '-3x^4+5x^2-8x'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [-1*3*x**4 + 5*x**2 - 1*8*x, '-3x^4+5x^2-8x'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [10, '10'] \n",
            "gold_parsed: [10, '10'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [10, '10'] \n",
            "gold_parsed: [10, '10'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [10, '10'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [20, '20'] \n",
            "gold_parsed: [10, '10'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4/9, '\\\\frac{4}{9}'] \n",
            "gold_parsed: [4/9, '\\\\frac{4}{9}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [4/9, '\\\\frac{4}{9}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4/9, '\\\\frac{4}{9}'] \n",
            "gold_parsed: [4/9, '\\\\frac{4}{9}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [4/9, '\\\\frac{4}{9}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [100, '100'] \n",
            "gold_parsed: [12, '12'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [12, '12'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [10, '10'] \n",
            "gold_parsed: [12, '12'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [100, '100'] \n",
            "gold_parsed: [12, '12'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [1, '1'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [1, '1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [1, '1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [5, '5'] \n",
            "gold_parsed: [1, '1'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [(6*sqrt(210))/(sqrt(105)), '\\\\frac{6\\\\sqrt{210}}{\\\\sqrt{105}}'] \n",
            "gold_parsed: [(4*sqrt(35))/35, '\\\\frac{4\\\\sqrt{35}}{35}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [(2*sqrt(70))/35, '\\\\frac{2\\\\sqrt{70}}{35}'] \n",
            "gold_parsed: [(4*sqrt(35))/35, '\\\\frac{4\\\\sqrt{35}}{35}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [(4*sqrt(7))/7, '\\\\frac{4\\\\sqrt{7}}{7}'] \n",
            "gold_parsed: [(4*sqrt(35))/35, '\\\\frac{4\\\\sqrt{35}}{35}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [(4*sqrt(35))/35, '\\\\frac{4\\\\sqrt{35}}{35}'] \n",
            "gold_parsed: [(4*sqrt(35))/35, '\\\\frac{4\\\\sqrt{35}}{35}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [25, '25'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [91, '91'] \n",
            "gold_parsed: [25, '25'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [25, '25'] \n",
            "gold_parsed: [25, '25'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [8, '8'] \n",
            "gold_parsed: [25, '25'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [42, '42'] \n",
            "gold_parsed: [176, '176'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [176, '176'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [26, '26'] \n",
            "gold_parsed: [176, '176'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [176, '176'] \n",
            "gold_parsed: [176, '176'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [2, '2'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-2, '-2'] \n",
            "gold_parsed: [2, '2'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-2, '-2'] \n",
            "gold_parsed: [2, '2'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [2, '2'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [-3/2, '-\\\\frac{3}{2}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-2, '-2'] \n",
            "gold_parsed: [-3/2, '-\\\\frac{3}{2}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [-3/2, '-\\\\frac{3}{2}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-1, '-1'] \n",
            "gold_parsed: [-3/2, '-\\\\frac{3}{2}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [8000, '8000'] \n",
            "gold_parsed: [8000, '8000'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [995801, '995801'] \n",
            "gold_parsed: [8000, '8000'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-94656, '-94656'] \n",
            "gold_parsed: [8000, '8000'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [16000, '16000'] \n",
            "gold_parsed: [8000, '8000'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [40, '40'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [40, '40'] \n",
            "gold_parsed: [40, '40'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [40, '40'] \n",
            "gold_parsed: [40, '40'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [40, '40'] \n",
            "gold_parsed: [40, '40'] \n",
            "reward: 1.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [-1/2, '-\\\\frac{1}{2}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [-1/2, '-\\\\frac{1}{2}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-1/2, '-\\\\frac{1}{2}'] \n",
            "gold_parsed: [-1/2, '-\\\\frac{1}{2}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-1/3, '-\\\\frac{1}{3}'] \n",
            "gold_parsed: [-1/2, '-\\\\frac{1}{2}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [7, '7'] \n",
            "gold_parsed: [7, '7'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [7, '7'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [x + 1 <= 1 + 24, 'x + 1 \\\\leq 24 + 1'] \n",
            "gold_parsed: [7, '7'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [28, '28'] \n",
            "gold_parsed: [7, '7'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [12, '12'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [7, '7'] \n",
            "gold_parsed: [12, '12'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [12, '12'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [12, '12'] \n",
            "gold_parsed: [12, '12'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [300, '300'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [300, '300'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [305, '305'] \n",
            "gold_parsed: [300, '300'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [387, '387'] \n",
            "gold_parsed: [300, '300'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [6, '6'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [6, '6'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [6, '6'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [6, '6'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Interval.open(0, oo), '(0, \\\\infty)'] \n",
            "gold_parsed: [Interval.open(0, oo), '(0,\\\\infty)'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Union(Interval(-oo, 0), Interval.open(0, oo)), '(-\\\\infty, 0] \\\\cup (0, \\\\infty)'] \n",
            "gold_parsed: [Interval.open(0, oo), '(0,\\\\infty)'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [Interval.open(0, oo), '(0,\\\\infty)'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Interval.open(0, oo), '(0, \\\\infty)'] \n",
            "gold_parsed: [Interval.open(0, oo), '(0,\\\\infty)'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [15, '15'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [16, '16'] \n",
            "gold_parsed: [15, '15'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [950, '950'] \n",
            "gold_parsed: [15, '15'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [15, '15'] \n",
            "gold_parsed: [15, '15'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [-1004, '-1004'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-1001, '-1001'] \n",
            "gold_parsed: [-1004, '-1004'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [-1004, '-1004'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-1004, '-1004'] \n",
            "gold_parsed: [-1004, '-1004'] \n",
            "reward: 1.0\n",
            "\n",
            "accuracy rewards: [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-1, '-1'] \n",
            "gold_parsed: [1, '1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [1, '1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/4, '\\\\frac{1}{4}'] \n",
            "gold_parsed: [1, '1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [1, '1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [8, '8'] \n",
            "gold_parsed: [8, '8'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Interval.open(3, 8), '(3, 8)'] \n",
            "gold_parsed: [8, '8'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [8, '8'] \n",
            "gold_parsed: [8, '8'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [8, '8'] \n",
            "gold_parsed: [8, '8'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [3*x**2 - 12, '3x^2-12'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [3*x**2 - 12, '3x^2-12'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [3*x**2 - 12, '3x^2-12'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3*x**2 - 12, '3x^2 - 12'] \n",
            "gold_parsed: [3*x**2 - 12, '3x^2-12'] \n",
            "reward: 1.0\n",
            "\n",
            "accuracy rewards: [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [30, '30'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-1/29, '-\\\\frac{1}{29}'] \n",
            "gold_parsed: [30, '30'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/29, '\\\\frac{1}{29}'] \n",
            "gold_parsed: [30, '30'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [30, '30'] \n",
            "gold_parsed: [30, '30'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [90, '90'] \n",
            "gold_parsed: [89, '89'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4, '4'] \n",
            "gold_parsed: [89, '89'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [34, '34'] \n",
            "gold_parsed: [89, '89'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [89, '89'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-8, '-8'] \n",
            "gold_parsed: [-8, '-8'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-7/2, '-\\\\frac{7}{2}'] \n",
            "gold_parsed: [-8, '-8'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-8, '-8'] \n",
            "gold_parsed: [-8, '-8'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-8, '-8'] \n",
            "gold_parsed: [-8, '-8'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [20, '20'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [20, '20'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [20, '20'] \n",
            "gold_parsed: [20, '20'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [20, '20'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/6, '\\\\frac{1}{6}'] \n",
            "gold_parsed: [-1/6, '-\\\\frac{1}{6}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [6, '6'] \n",
            "gold_parsed: [-1/6, '-\\\\frac{1}{6}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [6, '6'] \n",
            "gold_parsed: [-1/6, '-\\\\frac{1}{6}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [-1/6, '-\\\\frac{1}{6}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [4, '4'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [{1, 3, 4 + 2*sqrt(24), -1*2*sqrt(24) + 4}, '3, 1, 4 - 2\\\\sqrt{24}, 4 + 2\\\\sqrt{24}'] \n",
            "gold_parsed: [4, '4'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [4, '4'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [4, '4'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [32, '32'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [49, '49'] \n",
            "gold_parsed: [32, '32'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [9, '9'] \n",
            "gold_parsed: [32, '32'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [32, '32'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [-1, '-1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [-1, '-1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [-1, '-1'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [-1, '-1'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: ['{\\\\begin{array}{c} \\\\begin{tikzpicture}'] \n",
            "gold_parsed: [4.50000000000000, '4.5'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Theplotconsistsofthelines;pointsasdescribedabove., '\\\\text{The plot consists of the lines ; points as described above.}'] \n",
            "gold_parsed: [4.50000000000000, '4.5'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: ['\\\\begin{array}{c}'] \n",
            "gold_parsed: [4.50000000000000, '4.5'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [red, '\\\\text{red}'] \n",
            "gold_parsed: [4.50000000000000, '4.5'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4, '4'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [124, '124'] \n",
            "gold_parsed: [124, '124'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [124, '124'] \n",
            "gold_parsed: [124, '124'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [124, '124'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [64, '64'] \n",
            "gold_parsed: [124, '124'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-2, '-2'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [-8, '-8'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3628800, '3628800'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [21, '21'] \n",
            "gold_parsed: [21, '21'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [21, '21'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [21, '21'] \n",
            "gold_parsed: [21, '21'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [21, '21'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [6, '6'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3, '3'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [1, '1'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [1, '1'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [1, '1'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [1, '1'] \n",
            "reward: 1.0\n",
            "\n",
            "accuracy rewards: [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Eq(-31/96/f, -31/96), 'f^{-1}(-31/96)=-31/96'] \n",
            "gold_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Eq(x, (65/96)**(1/5)), 'x = \\\\sqrt[5]{65/96}'] \n",
            "gold_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "gold_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [7, '7'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [16, '16'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [3, '3'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [15, '15'] \n",
            "gold_parsed: [15, '15'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [15, '15'] \n",
            "gold_parsed: [15, '15'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [15, '15'] \n",
            "gold_parsed: [15, '15'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [15, '15'] \n",
            "gold_parsed: [15, '15'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3/2, '\\\\frac{3}{2}'] \n",
            "gold_parsed: [3/2, '\\\\frac{3}{2}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Nosolution, '\\\\text{No solution}'] \n",
            "gold_parsed: [3/2, '\\\\frac{3}{2}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3/2, '\\\\frac{3}{2}'] \n",
            "gold_parsed: [3/2, '\\\\frac{3}{2}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [2, '2'] \n",
            "gold_parsed: [3/2, '\\\\frac{3}{2}'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [x**4 - 16, 'x^4-16'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [x**4 - 16, 'x^4-16'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [x**4 - 16, 'x^4-16'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [x**4 - 16, 'x^4-16'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "gold_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "gold_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "gold_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [306, '306'] \n",
            "gold_parsed: [304, '304'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [304, '304'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [3150, '3150'] \n",
            "gold_parsed: [304, '304'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [189, '189'] \n",
            "gold_parsed: [304, '304'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Eq(y, -1*2*x + 1), 'y = -2x + 1'] \n",
            "gold_parsed: [Eq(y, -1*2*x + 1), 'y=-2x+1'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Eq(y, -1*2*x + 1), 'y = -2x + 1'] \n",
            "gold_parsed: [Eq(y, -1*2*x + 1), 'y=-2x+1'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [Eq(y, -1*2*x + 1), 'y = -2x + 1'] \n",
            "gold_parsed: [Eq(y, -1*2*x + 1), 'y=-2x+1'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [Eq(y, -1*2*x + 1), 'y=-2x+1'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [205, '205'] \n",
            "gold_parsed: [16, '16'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [4, '4'] \n",
            "gold_parsed: [16, '16'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [] \n",
            "gold_parsed: [16, '16'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [16, '16'] \n",
            "gold_parsed: [16, '16'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1, '1'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [0, '0'] \n",
            "gold_parsed: [0, '0'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "gold_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "gold_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "gold_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "gold_parsed: [1/2, '\\\\frac{1}{2}'] \n",
            "reward: 1.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [10/567, '\\\\frac{10}{567}'] \n",
            "gold_parsed: [10/21, '\\\\frac{10}{21}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [50/63, '\\\\frac{50}{63}'] \n",
            "gold_parsed: [10/21, '\\\\frac{10}{21}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [10/27, '\\\\frac{10}{27}'] \n",
            "gold_parsed: [10/21, '\\\\frac{10}{21}'] \n",
            "reward: 0.0\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "answer_parsed: [10/63, '\\\\frac{10}{63}'] \n",
            "gold_parsed: [10/21, '\\\\frac{10}{21}'] \n",
            "reward: 0.0\n",
            "\n",
            "accuracy rewards: [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "format rewards: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_34432/4006818267.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrlParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRPOScriptArguments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGRPOConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mscript_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args_and_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscript_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_34432/4071804043.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(script_args, training_args, model_args)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlast_checkpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtrain_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_samples\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscript_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_train_split\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2169\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2171\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   2172\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2173\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2529\u001b[0m                     )\n\u001b[1;32m   2530\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2531\u001b[0;31m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2533\u001b[0m                     if (\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3674\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3675\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3677\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipykernel_34432/1267390160.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 )\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 prompt_completion_ids = unwrapped_model.generate(\n\u001b[0m\u001b[1;32m    114\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mprompt_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneration_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 )\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2255\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2256\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2257\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3255\u001b[0m                 \u001b[0mis_prefill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3257\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3259\u001b[0m             \u001b[0;31m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;31m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         outputs = self.model(\n\u001b[0m\u001b[1;32m    820\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_checkpointing\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m                 layer_outputs = self._gradient_checkpointing_func(\n\u001b[0m\u001b[1;32m    566\u001b[0m                     \u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0mprior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/checkpoint.py\u001b[0m in \u001b[0;36mcheckpoint\u001b[0;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;31m# Runs pre-forward logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0;31m# Runs post-forward logic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         hidden_states, self_attn_weights = self.self_attn(\n\u001b[0m\u001b[1;32m    260\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0mattention_interface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mALL_ATTENTION_FUNCTIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn_implementation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         attn_output, attn_weights = attention_interface(\n\u001b[0m\u001b[1;32m    192\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/integrations/flash_attention.py\u001b[0m in \u001b[0;36mflash_attention_forward\u001b[0;34m(module, query, key, value, attention_mask, dropout, scaling, sliding_window, softcap, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"is_causal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     attn_output = _flash_attention_forward(\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_flash_attention_utils.py\u001b[0m in \u001b[0;36m_flash_attention_forward\u001b[0;34m(query_states, key_states, value_states, attention_mask, query_length, is_causal, dropout, position_ids, softmax_scale, sliding_window, use_top_left_mask, softcap, deterministic, cu_seq_lens_q, cu_seq_lens_k, max_length_q, max_length_k, target_dtype, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         query_states, key_states, value_states, indices_q, cu_seq_lens, max_seq_lens = _upad_input(\n\u001b[0m\u001b[1;32m    306\u001b[0m             \u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         )\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_flash_attention_utils.py\u001b[0m in \u001b[0;36m_upad_input\u001b[0;34m(query_layer, key_layer, value_layer, attention_mask, query_length)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mMaximum\u001b[0m \u001b[0msequence\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmax_seqlen_in_batch_q\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0msequence\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mmax_seqlen_in_batch_k\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msource\u001b[0m \u001b[0msequence\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mindices_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcu_seqlens_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seqlen_in_batch_k\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_unpad_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkv_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_key_value_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_flash_attention_utils.py\u001b[0m in \u001b[0;36m_get_unpad_data\u001b[0;34m(attention_mask)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \"\"\"\n\u001b[1;32m     52\u001b[0m     \u001b[0mseqlens_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_tuple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mmax_seqlen_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseqlens_in_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mcu_seqlens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqlens_in_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "#def training_func():\n",
        "if __name__ == \"__main__\":\n",
        "    parser = TrlParser((GRPOScriptArguments, GRPOConfig, ModelConfig))\n",
        "    script_args, training_args, model_args = parser.parse_args_and_config()\n",
        "    main(script_args, training_args, model_args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
